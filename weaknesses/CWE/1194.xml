<?xml version="1.0" encoding="UTF-8"?>
<Weakness_Catalog xmlns="http://cwe.mitre.org/cwe-6" xmlns:xhtml="http://www.w3.org/1999/xhtml" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" Name="VIEW LIST: CWE-1194: Hardware Design" Version="4.6" Date="2021-10-28" xsi:schemaLocation="http://cwe.mitre.org/cwe-6 http://cwe.mitre.org/data/xsd/cwe_schema_v6.6.xsd">
   <Weaknesses>
      <Weakness ID="1053" Name="Missing Documentation for Design" Abstraction="Base" Structure="Simple" Status="Incomplete">
         <Description>The product does not have documentation that represents how it is designed.</Description>
         <Extended_Description><xhtml:p>This issue can make it more difficult to understand and maintain the product. It can make it more difficult and time-consuming to detect and/or fix vulnerabilities.</xhtml:p></Extended_Description>
         <Related_Weaknesses>
           <Related_Weakness Nature="ChildOf" CWE_ID="1059" View_ID="1000" Ordinal="Primary"/>
         </Related_Weaknesses>
         <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Indirect</Ordinality>
            </Weakness_Ordinality>
         </Weakness_Ordinalities>
         <References>
            <Reference External_Reference_ID="REF-963"/>
         </References>
         <Content_History>
            <Submission>
               <Submission_Name>CWE Content Team</Submission_Name>
               <Submission_Organization>MITRE</Submission_Organization>
               <Submission_Date>2018-07-02</Submission_Date>
               <Submission_Comment>Entry derived from Common Quality Enumeration (CQE) Draft 0.9.</Submission_Comment>
            </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-02-24</Modification_Date>
					<Modification_Comment>updated Description, Relationships</Modification_Comment>
				</Modification>
         </Content_History>
      </Weakness>
      <Weakness ID="1189" Name="Improper Isolation of Shared Resources on System-on-a-Chip (SoC)" Abstraction="Base" Structure="Simple" Status="Stable">
         <Description>The System-On-a-Chip (SoC) does not properly isolate shared resources between trusted and untrusted agents.</Description>
         <Extended_Description>
            <xhtml:p>A System-On-a-Chip (SoC) has a lot of functionality, but it may have a limited number of pins or pads. A pin can only perform one function at a time. However, it can be configured to perform multiple different functions. This technique is called pin multiplexing. Similarly, several resources on the chip may be shared to multiplex and support different features or functions. When such resources are shared between trusted and untrusted agents, untrusted agents may be able to access the assets intended to be accessed only by the trusted agents.</xhtml:p>
         </Extended_Description>
         <Related_Weaknesses>
	   <Related_Weakness Nature="ChildOf" CWE_ID="653" View_ID="1000" Ordinal="Primary"/>
           <Related_Weakness Nature="ChildOf" CWE_ID="668" View_ID="1000"/>
	   <Related_Weakness Nature="PeerOf" CWE_ID="1331" View_ID="1000"/>
         </Related_Weaknesses>
	 <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Primary</Ordinality>
            </Weakness_Ordinality>
		 </Weakness_Ordinalities>
         <Applicable_Platforms>
            <Language Class="Language-Independent" Prevalence="Undetermined"/>
            <Technology Class="System on Chip" Prevalence="Undetermined"/>
         </Applicable_Platforms>
         <Modes_Of_Introduction>
            <Introduction>
               <Phase>Architecture and Design</Phase>
            </Introduction>
            <Introduction>
               <Phase>Implementation</Phase>
            </Introduction>
         </Modes_Of_Introduction>
         <Common_Consequences>
            <Consequence>
               <Scope>Access Control</Scope>
               <Impact>Bypass Protection Mechanism</Impact>
               <Note>If resources being used by a trusted user are shared with an untrusted user, the untrusted user may be able to modify the functionality of the shared resource of the trusted user.</Note>
            </Consequence>
            <Consequence>
               <Scope>Integrity</Scope>
               <Impact>Quality Degradation</Impact>
               <Note>The functionality of the shared resource may be intentionally degraded.</Note>
            </Consequence>
         </Common_Consequences>
         <Detection_Methods>
            <Detection_Method>
               <Method>Automated Static Analysis - Binary or Bytecode</Method>
               <Description>
                  <xhtml:p>Kernel integrity verification can help identify when shared resource configuration settings have been modified.</xhtml:p>
               </Description>
               <Effectiveness>High</Effectiveness>
            </Detection_Method>
         </Detection_Methods>
         <Potential_Mitigations>
            <Mitigation>
               <Phase>Architecture and Design</Phase>
               <Strategy>Separation of Privilege</Strategy>
               <Description>
                 <xhtml:p>When sharing resources, avoid mixing agents of varying trust levels.</xhtml:p>
                 <xhtml:p>Untrusted agents should not share resources with trusted agents.</xhtml:p>
               </Description>
            </Mitigation>
         </Potential_Mitigations>
         <Demonstrative_Examples>
            <Demonstrative_Example>
	      <Intro_Text>Consider the following SoC
	      design. The Hardware Root of Trust (HRoT) local SRAM is memory mapped in the core{0-N}
	      address space. The HRoT allows or disallows access to private memory ranges, thus
	      allowing the sram to function as a mailbox for communication between untrusted and
	      trusted HRoT partitions.</Intro_Text>
	    <Body_Text>
	    <xhtml:img src="https://cwe.mitre.org/data/images/HRoT-CWE.png" alt="Hardware Root of Trust"/>
	    <xhtml:p>
	      We assume that the threat is from malicious software in
	      the untrusted domain. We assume this software has access
	      to the core{0-N} memory map and can be running at any
	      privilege level on the untrusted cores. The capability
	      of this threat in this example is communication to and
	      from the mailbox region of SRAM modulated by the
	      hrot_iface. To address this threat, information must not
	      enter or exit the shared region of SRAM through
	      hrot_iface when in secure or privileged mode.
	      </xhtml:p>
	    </Body_Text>
            </Demonstrative_Example>
          </Demonstrative_Examples>
	  <Observed_Examples>
	    <Observed_Example>
	      <Reference>CVE-2019-6260</Reference>
	      <Description>Baseboard Management Controller (BMC) device implements Advanced High-performance Bus (AHB) bridges that do not require authentication for arbitrary read and write access to the BMC's physical address space from the host, and possibly the network [REF-1138].</Description>
	      <Link>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-6260</Link>
	    </Observed_Example>
	  </Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="124"/>
         </Related_Attack_Patterns>
         <References>
            <Reference External_Reference_ID="REF-1036"/>
	    <Reference External_Reference_ID="REF-1138"/>
         </References>
         <Content_History>
            <Submission>
			   <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
               <Submission_Organization>Intel Corporation</Submission_Organization>
               <Submission_Date>2019-10-15</Submission_Date>
            </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Common_Consequences, Description, Name, Potential_Mitigations, Related_Attack_Patterns, Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-12-10</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples</Modification_Comment>
				</Modification>
            <Contribution Type="Content">
               <Contribution_Organization>Tortuga Logic</Contribution_Organization>
               <Contribution_Date>2021-07-16</Contribution_Date>
               <Contribution_Comment>Provided Demonstrative Example for Hardware Root of Trust</Contribution_Comment>
            </Contribution>
	    <Contribution Type="Content">
	      <Contribution_Name>Hareesh Khattri</Contribution_Name>
	      <Contribution_Organization>Intel Corporation</Contribution_Organization>
	      <Contribution_Date>2021-10-22</Contribution_Date>
	      <Contribution_Comment>provided observed example</Contribution_Comment>
	    </Contribution>
			<Previous_Entry_Name Date="2020-08-20">Improper Isolation of Shared Resources on System-on-Chip (SoC)</Previous_Entry_Name>
         </Content_History>
      </Weakness>
      <Weakness ID="1190" Name="DMA Device Enabled Too Early in Boot Phase" Abstraction="Base" Structure="Simple" Status="Draft">
         <Description>The product enables a Direct Memory Access (DMA) capable device before the security configuration settings are established, which allows an attacker to extract data from or gain privileges on the product.</Description>
         <Extended_Description>
            <xhtml:p>DMA is included in a number of devices because it allows
              data transfer between the computer and the connected device, using
              direct hardware access to read or write directly to main memory
              without any OS interaction. An attacker could exploit this to
              access secrets. Several virtualization-based mitigations have been introduced to thwart DMA attacks. These are usually
              configured/setup during boot time. However, certain IPs that are
              powered up before boot is complete (known as early boot IPs) may
              be DMA capable. Such IPs, if not trusted, could launch DMA
              attacks and gain access to assets that should otherwise be
              protected.</xhtml:p>
         </Extended_Description>
         <Related_Weaknesses>
            <Related_Weakness Nature="ChildOf" CWE_ID="696" View_ID="1000" Ordinal="Primary"/>
         </Related_Weaknesses>
         <Applicable_Platforms>
            <Language Class="Language-Independent" Prevalence="Undetermined"/>
            <Technology Class="System on Chip" Prevalence="Undetermined"/>
         </Applicable_Platforms>
         <Modes_Of_Introduction>
            <Introduction>
               <Phase>Architecture and Design</Phase>
            </Introduction>
         </Modes_Of_Introduction>
		 <Common_Consequences>
            <Consequence>
               <Scope>Access Control</Scope>
               <Impact>Bypass Protection Mechanism</Impact>
			   <Impact>Modify Memory</Impact>
			   <Likelihood>High</Likelihood>
               <Note>DMA devices have direct write access to main memory and
                 due to time of attack will be able to bypass OS or Bootloader
                 access control.</Note>
            </Consequence>
         </Common_Consequences>
         <Potential_Mitigations>
            <Mitigation>
               <Phase>Architecture and Design</Phase>
               <Description>Utilize an IOMMU to orchestrate IO access from
                 the start of the boot process.</Description>
            </Mitigation>
          </Potential_Mitigations>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <References>
            <Reference External_Reference_ID="REF-1038"/>
            <Reference External_Reference_ID="REF-1039"/>
            <Reference External_Reference_ID="REF-1040"/>
            <Reference External_Reference_ID="REF-1041"/>
            <Reference External_Reference_ID="REF-1042"/>
            <Reference External_Reference_ID="REF-1044"/>
            <Reference External_Reference_ID="REF-1046"/>
         </References>
         <Content_History>
            <Submission>
			   <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
               <Submission_Organization>Intel Corporation</Submission_Organization>
               <Submission_Date>2019-10-15</Submission_Date>
            </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
         </Content_History>
      </Weakness>
      <Weakness ID="1191" Name="On-Chip Debug and Test Interface With Improper Access Control" Abstraction="Base" Structure="Simple" Status="Stable">
     <Description>The chip does not implement or does not correctly perform access control to check whether users are authorized to access internal registers and test modes through the physical debug/test interface.</Description>
     <Extended_Description>
      <xhtml:p>A device's internal information may be accessed through a scan chain of interconnected internal registers, usually through a JTAG interface. The JTAG interface provides access to these registers in a serial fashion in the form of a scan chain for the purposes of debugging programs running on a device. Since almost all information contained within a device may be accessed over this interface, device manufacturers typically insert some form of authentication and authorization to prevent unintended use of this sensitive information. This mechanism is implemented in addition to on-chip protections that are already present.</xhtml:p>
      <xhtml:p>If authorization, authentication, or some other form of access control is not implemented or not implemented correctly, a user may be able to bypass on-chip protection mechanisms through the debug interface.</xhtml:p>
     </Extended_Description>
     <Related_Weaknesses>
      <Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
     </Related_Weaknesses>
		 <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Primary</Ordinality>
            </Weakness_Ordinality>
		 </Weakness_Ordinalities>
     <Applicable_Platforms>
      <Language Class="Language-Independent" Prevalence="Undetermined"/>
      <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
      <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
      <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
     </Applicable_Platforms>
     <Modes_Of_Introduction>
      <Introduction>
        <Phase>Architecture and Design</Phase>
      </Introduction>
      <Introduction>
        <Phase>Implementation</Phase>
      </Introduction>
     </Modes_Of_Introduction>
     <Common_Consequences>
      <Consequence>
        <Scope>Confidentiality</Scope>
        <Impact>Read Application Data</Impact>
			  <Likelihood>High</Likelihood>
      </Consequence>
      <Consequence>
        <Scope>Confidentiality</Scope>
        <Impact>Read Memory</Impact>
			  <Likelihood>High</Likelihood>
      </Consequence>
      <Consequence>
        <Scope>Authorization</Scope>
        <Impact>Execute Unauthorized Code or Commands</Impact>
			  <Likelihood>High</Likelihood>
      </Consequence>
      <Consequence>
        <Scope>Integrity</Scope>
        <Impact>Modify Memory</Impact>
			  <Likelihood>High</Likelihood>
      </Consequence>
      <Consequence>
        <Scope>Integrity</Scope>
        <Impact>Modify Application Data</Impact>
			  <Likelihood>High</Likelihood>
      </Consequence>
      <Consequence>
        <Scope>Access Control</Scope>
        <Impact>Bypass Protection Mechanism</Impact>
			  <Likelihood>High</Likelihood>
      </Consequence>
     </Common_Consequences>
     <Detection_Methods>
       <Detection_Method>
	 <Method>Dynamic Analysis with Manual Results Interpretation</Method>
	 <Description><xhtml:p>Authentication and authorization of debug and test interfaces should be part of the architecture and design review process. Withholding of private register documentation from the debug and test interface public specification ("Security by obscurity") should not be considered as sufficient security.</xhtml:p></Description>
       </Detection_Method>
       <Detection_Method>
	 <Method>Dynamic Analysis with Manual Results Interpretation</Method>
	 <Description><xhtml:p>Dynamic tests should be done in the pre-silicon and post-silicon stages to verify that the debug and test interfaces are not open by default.</xhtml:p></Description>
       </Detection_Method>
       <Detection_Method>
	 <Method>Fuzzing</Method>
	 <Description>Tests that fuzz Debug and Test Interfaces should ensure that no access without appropriate authentication and authorization is possible.</Description>
	 <Effectiveness>Moderate</Effectiveness>
       </Detection_Method>
     </Detection_Methods>
     <Potential_Mitigations>
       <Mitigation>
	 <Phase>Architecture and Design</Phase>
	 <Strategy>Separation of Privilege</Strategy>
	 <Description>
	   If feasible, the manufacturer should disable the JTAG interface or implement authentication and authorization for the JTAG interface. If authentication logic is added, it should be resistant to timing attacks. Security-sensitive data stored in registers, such as keys, etc. should be cleared when entering debug mode.
	 </Description>
	 <Effectiveness>High</Effectiveness>
       </Mitigation>
     </Potential_Mitigations>
    <Demonstrative_Examples>
<Demonstrative_Example>
        <Intro_Text>A home, WiFi-router device implements a login prompt which prevents an unauthorized user from issuing any commands on the device until appropriate credentials are provided. The credentials are protected on the device and are checked for strength against attack.</Intro_Text>
        <Example_Code Nature="bad" Language="Other">
	  <xhtml:p>If the JTAG interface on this device is not hidden by the manufacturer, the interface may be identified using tools such as JTAGulator. If it is hidden but not disabled, it can be exposed by physically wiring to the board.</xhtml:p>
	  <xhtml:p>By issuing a <xhtml:b>halt</xhtml:b> command before the OS starts, the unauthorized user pauses the watchdog timer and prevents the router from restarting (once the watchdog timer would have expired). Having paused the router, an unauthorized user is able to execute code and inspect and modify data in the device, even extracting all of the router's firmware. This allows the user to examine the router and potentially exploit it.</xhtml:p>
	</Example_Code>
	<Body_Text>JTAG is useful to chip and device manufacturers during design, testing, and production and is included in nearly every product. Without proper authentication and authorization, the interface may allow tampering with a product.</Body_Text>
	<Example_Code Nature="good" Language="Other">In order to prevent exposing the debugging interface, manufacturers might try to obfuscate the JTAG interface or blow device internal fuses to disable the JTAG interface. Adding authentication and authorization to this interface makes use by unauthorized individuals much more difficult.</Example_Code>
    </Demonstrative_Example>
    </Demonstrative_Examples>
     <Observed_Examples>
      <Observed_Example>
       <Reference>CVE-2019-18827</Reference>
       <Description>chain: JTAG interface is not disabled (CWE-1191) during ROM code execution, introducing a race condition (CWE-362) to extract encryption keys</Description>
       <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-18827</Link>
      </Observed_Example>
     </Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <References>
      <Reference External_Reference_ID="REF-1037"/>
      <Reference External_Reference_ID="REF-1043"/>
      <Reference External_Reference_ID="REF-1084"/>
      <Reference External_Reference_ID="REF-1085"/>
     </References>
      <Notes>
	<Note Type="Relationship">
	  CWE-1191 and CWE-1244 both involve physical debug access,
	  but the weaknesses are different. CWE-1191 is effectively
	  about missing authorization for a debug interface,
	  i.e. JTAG.  CWE-1244 is about providing internal assets with
	  the wrong debug access level, exposing the asset to
	  untrusted debug agents.</Note>
      </Notes>
     <Content_History>
      <Submission>
			  <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
        <Submission_Organization>Intel Corporation</Submission_Organization>
        <Submission_Date>2019-10-15</Submission_Date>
      </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-06-25</Modification_Date>
					<Modification_Comment>updated Applicable_Platforms, Common_Consequences, Demonstrative_Examples, Description, Name, References, Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Applicable_Platforms, Demonstrative_Examples, Description, Name, Potential_Mitigations, Related_Attack_Patterns, Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Maintenance_Notes</Modification_Comment>
				</Modification>
				<Contribution Type="Content">
				  <Contribution_Name>Parbati K. Manna</Contribution_Name>
				  <Contribution_Organization>Intel Corporation</Contribution_Organization>
				  <Contribution_Date>2021-10-18</Contribution_Date>
				  <Contribution_Comment>provided detection methods</Contribution_Comment>
				</Contribution>
				<Contribution Type="Feedback">
				  <Contribution_Name>Narasimha Kumar V Mangipudi</Contribution_Name>
				  <Contribution_Organization>Lattice Semiconductor</Contribution_Organization>
				  <Contribution_Date>2021-10-20</Contribution_Date>
				  <Contribution_Comment>reviewed content changes</Contribution_Comment>
				</Contribution>
				<Contribution Type="Content">
				  <Contribution_Name>Hareesh Khattri</Contribution_Name>
				  <Contribution_Organization>Intel Corporation</Contribution_Organization>
				  <Contribution_Date>2021-10-22</Contribution_Date>
				  <Contribution_Comment>clarified differences between CWE-1191 and CWE-1244</Contribution_Comment>
				</Contribution>
			<Previous_Entry_Name Date="2020-02-26">Exposed Chip Debug Interface With Insufficient Access Control</Previous_Entry_Name>
			<Previous_Entry_Name Date="2020-08-20">Exposed Chip Debug and or Test Interface With Insufficient Access Control</Previous_Entry_Name>
     </Content_History>
   </Weakness>
      <Weakness ID="1192" Name="System-on-Chip (SoC) Using Components without Unique, Immutable Identifiers" Abstraction="Base" Structure="Simple" Status="Draft">
         <Description>The System-on-Chip (SoC) does not have unique, immutable identifiers for each of its components.</Description>
         <Extended_Description>
	   <xhtml:p>A System-on-Chip (SoC) comprises several components (IP) with varied
           trust requirements. It is required that each IP is identified
           uniquely and should distinguish itself from other entities in
           the SoC without any ambiguity. The unique secured identity is
           required for various purposes. Most of the time the identity is used
           to route a transaction or perform certain actions, including 
           resetting, retrieving a sensitive information, and acting upon or on
           behalf of something else.</xhtml:p>
           <xhtml:p>There are several variants of this weakness:</xhtml:p>
            <xhtml:ul>
	      <xhtml:li>A "missing" identifier is when the SoC does not define
	      any mechanism to uniquely identify the IP.</xhtml:li>
	      <xhtml:li>An "insufficient" identifier might provide
	      some defenses - for example, against the most common
	      attacks - but it does not protect against everything
	      that is intended.</xhtml:li>
	      <xhtml:li>A "misconfigured" mechanism occurs when a mechanism
              is available but not implemented correctly.</xhtml:li>
	      <xhtml:li>An "ignored" identifier occurs when the SoC/IP has not applied
	      any policies or does not act upon the identifier securely.</xhtml:li>
            </xhtml:ul>
         </Extended_Description>
          <Related_Weaknesses>
            <Related_Weakness Nature="ChildOf" CWE_ID="657" View_ID="1000" Ordinal="Primary"/>
         </Related_Weaknesses>
        <Applicable_Platforms>
            <Language Class="Language-Independent" Prevalence="Undetermined"/>
            <Technology Class="System on Chip" Prevalence="Undetermined"/>
         </Applicable_Platforms>
         <Modes_Of_Introduction>
            <Introduction>
               <Phase>Architecture and Design</Phase>
            </Introduction>
            <Introduction>
               <Phase>Implementation</Phase>
            </Introduction>
            <Introduction>
               <Phase>Operation</Phase>
            </Introduction>
         </Modes_Of_Introduction>
         <Common_Consequences>
            <Consequence>
               <Scope>Access Control</Scope>
               <Impact>Bypass Protection Mechanism</Impact>
			   <Likelihood>High</Likelihood>
            </Consequence>
         </Common_Consequences>
         <Potential_Mitigations>
            <Mitigation>
                <Phase>Architecture and Design</Phase>
                <Strategy>Separation of Privilege</Strategy>
                <Description>
                  <xhtml:p>
                    Every identity generated in the SoC should be unique and
                    immutable in hardware. The actions that an IP is trusted or
                    not trusted should be clearly defined, implemented,
                    configured, and tested. If the definition is implemented via a
                    policy, then the policy should be immutable or protected with
                    clear authentication and authorization.
                  </xhtml:p>
                </Description>
            </Mitigation>
         </Potential_Mitigations>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="113"/>
         </Related_Attack_Patterns>
         <Content_History>
            <Submission>
               <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
               <Submission_Organization>Intel Corporation</Submission_Organization>
               <Submission_Date>2019-10-15</Submission_Date>
            </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Description</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-12-10</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
         </Content_History>
      </Weakness>
      <Weakness ID="1193" Name="Power-On of Untrusted Execution Core Before Enabling Fabric Access Control" Abstraction="Base" Structure="Simple" Status="Draft">
        <Description>The product enables components that contain untrusted firmware before memory and fabric access controls have been enabled.</Description>
	<Extended_Description>
	  <xhtml:p>
	   After initial reset, System-on-Chip (SoC) fabric access controls and other
           security features need to be programmed by trusted firmware as part
           of the boot sequence. If untrusted IPs or peripheral microcontrollers
	   are enabled first, then the untrusted component can master
           transactions on the hardware bus and target memory or other assets to
           compromise the SoC boot firmware.</xhtml:p></Extended_Description>
         <Related_Weaknesses>
            <Related_Weakness Nature="ChildOf" CWE_ID="696" View_ID="1000" Ordinal="Primary"/>
         </Related_Weaknesses>
		 <Common_Consequences>
            <Consequence>
               <Scope>Access Control</Scope>
               <Impact>Bypass Protection Mechanism</Impact>
			   <Likelihood>High</Likelihood>
               <Note>An untrusted component can master transactions on the HW bus and target memory or other assets to compromise the SoC boot firmware.</Note>
            </Consequence>
         </Common_Consequences>
         <Potential_Mitigations>
            <Mitigation>
                <Phase>Architecture and Design</Phase>
                <Description>
                  <xhtml:p>The boot sequence should enable fabric access controls and memory protections before enabling third-party hardware IPs and peripheral microcontrollers that use untrusted firmware.</xhtml:p>
                </Description>
            </Mitigation>
         </Potential_Mitigations>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <References>
            <Reference External_Reference_ID="REF-1130"/>
            <Reference External_Reference_ID="REF-1042"/>
         </References>
         <Content_History>
            <Submission>
               <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
               <Submission_Organization>Intel Corporation</Submission_Organization>
               <Submission_Date>2019-10-15</Submission_Date>
            </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated References, Related_Attack_Patterns</Modification_Comment>
				</Modification>
         </Content_History>
      </Weakness>
      <Weakness ID="1209" Name="Failure to Disable Reserved Bits" Abstraction="Base" Structure="Simple" Status="Incomplete">
            <Description>The reserved bits in a hardware design are not disabled prior to production. Typically, reserved bits are used for future capabilities and should not support any functional logic in the design.   However, designers might covertly use these bits to debug or further develop new capabilities in production hardware. Adversaries with access to these bits will write to them in hopes of compromising hardware state.</Description>
            <Extended_Description>
                <xhtml:p>Reserved bits are labeled as such so they can be allocated for a later purpose. They are not to do anything in the current design.  However, designers might want to use these bits to debug or control/configure a future capability to help minimize time to market (TTM). If the logic being controlled by these bits is still enabled in production, an adversary could use the logic to induce unwanted/unsupported behavior in the hardware.</xhtml:p>
            </Extended_Description>
         <Related_Weaknesses>
            <Related_Weakness Nature="ChildOf" CWE_ID="710" View_ID="1000" Ordinal="Primary"/>
         </Related_Weaknesses>
            <Applicable_Platforms>
                <Language Class="Language-Independent" Prevalence="Undetermined"/>
                <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
                <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
                <Technology Class="System on Chip" Prevalence="Undetermined"/>
            </Applicable_Platforms>
            <Modes_Of_Introduction>
                <Introduction>
                    <Phase>Architecture and Design</Phase>
                    <Note>The Designer and Implementer have to make a conscious choice to do this</Note>
                </Introduction>
                <Introduction>
                    <Phase>Implementation</Phase>
                    <Note>The Designer and Implementer have to make a conscious choice to do this</Note>
                </Introduction>
                <Introduction>
                    <Phase>Documentation</Phase>
                    <Note>If documentation labels anything "for future use", "reserved", or the like, such labeling could indicate to an attacker a potential attack point</Note>
                </Introduction>
            </Modes_Of_Introduction>
            <Common_Consequences>
                <Consequence>
                    <Scope>Confidentiality</Scope>
                    <Scope>Integrity</Scope>
                    <Scope>Availability</Scope>
                    <Scope>Access Control</Scope>
                    <Scope>Accountability</Scope>
                    <Scope>Authentication</Scope>
                    <Scope>Authorization</Scope>
                    <Scope>Non-Repudiation</Scope>
                    <Impact>Varies by Context</Impact>
                    <Note>This type of weakness all depends on the capabilities of the logic being controlled or configured by the reserved bits</Note>
                </Consequence>
            </Common_Consequences>
            <Potential_Mitigations>
                <Mitigation>
                    <Phase>Architecture and Design</Phase>
                    <Phase>Implementation</Phase>
                    <Description>
                        <xhtml:p>Include a feature to disable reserved bits.</xhtml:p>                     
                    </Description>
                </Mitigation>
                <Mitigation>
                    <Phase>Integration</Phase>
                    <Description>
                    	<xhtml:p>Any writes to these reserve bits are blocked (e.g., ignored, access-protected, etc.), or an exception can be asserted.</xhtml:p>
                    </Description>
                </Mitigation>
            </Potential_Mitigations>
            <Demonstrative_Examples>
                <Demonstrative_Example>
                    <Intro_Text>An adversary may perform writes to reserve space in hopes to change the behavior of the hardware.</Intro_Text>
                    <Example_Code Nature="bad" Language="Other">
                        <xhtml:div>// Assume an IP has address space 0x0-0x0F for its configuration registers, with the last one labeled reserved (i.e. 0x0F).  Therefore inside the Finite State Machine (FSM), the code is as follows:
                        <xhtml:br/>
                        <xhtml:br/>reg gpio_out = 0;  //gpio should remain low for normal operation
                        <xhtml:br/>
                        <xhtml:br/>case (register_address)
                        <xhtml:br/>		4'b1111 : //0x0F
                        <xhtml:br/>			begin
                        <xhtml:br/>				gpio_out = 1;  
                        <xhtml:br/>			end</xhtml:div>
                    </Example_Code>
                    <Body_Text>In the code above, the GPIO pin should remain low for normal operation.  However, it can be asserted by accessing the reserved address space (0x0F).  This may be a concern if the GPIO state is being used as an indicator of health (e.g. if asserted the hardware may respond by shutting down or resetting the system which may not be the correct action the system should perform).</Body_Text>
                	<Example_Code Nature="informative">
                  		<xhtml:div>reg gpio_out = 0;  //gpio should remain low for normal operation
                  		<xhtml:br/>case (register_address)
                  		<xhtml:br/>		//4'b1111 : //0x0F
                  		<xhtml:br/>		default: gpio_out = gpio_out;</xhtml:div>
               		</Example_Code>
            	</Demonstrative_Example>
            </Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="121"/>
         </Related_Attack_Patterns>
         <Content_History>
                <Submission>
                    <Submission_Name>Brent Sherman</Submission_Name>
                    <Submission_Organization>Intel Corporation</Submission_Organization>
                    <Submission_Date>2020-02-06</Submission_Date>
                </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
            </Content_History>
        </Weakness>
      <Weakness ID="1220" Name="Insufficient Granularity of Access Control" Abstraction="Base" Structure="Simple" Status="Incomplete">
            <Description>The product implements access controls via a policy or other feature with the intention to disable or restrict accesses (reads and/or writes) to assets in a system from untrusted agents. However, implemented access controls lack required granularity, which renders the control policy too broad because it allows accesses from unauthorized agents to the security-sensitive assets.</Description>
            <Extended_Description>
                <xhtml:p>Integrated circuits and hardware engines can expose accesses to assets (device configuration, keys, etc.) to trusted firmware or a software module (commonly set by BIOS/bootloader). This access is typically access-controlled. Upon a power reset, the hardware or system usually starts with default values in registers, and the trusted firmware (Boot firmware) configures the necessary access-control protection.</xhtml:p>
                <xhtml:p>A common weakness that can exist in such protection schemes is that access controls or policies are not granular enough. This condition allows agents beyond trusted agents to access assets and could lead to a loss of functionality or the ability to set up the device securely. This further results in security risks from leaked, sensitive, key material to modification of device configuration.</xhtml:p>
            </Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
            <Applicable_Platforms>
                <Language Class="Language-Independent" Prevalence="Undetermined"/>
                <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
                <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
                <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
            </Applicable_Platforms>
            <Modes_Of_Introduction>
                <Introduction>
                    <Phase>Architecture and Design</Phase>
                    <Note>Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.</Note>
                </Introduction>
                <Introduction>
                    <Phase>Implementation</Phase>
                    <Note>Such issues could be introduced during hardware implementation and identified later during Testing or System Configuration phases.</Note>
                </Introduction>
            </Modes_Of_Introduction>
            <Common_Consequences>
                <Consequence>
                    <Scope>Confidentiality</Scope>
                    <Scope>Integrity</Scope>
                    <Scope>Availability</Scope>
                    <Scope>Access Control</Scope>
                    <Impact>Modify Memory</Impact>
                    <Impact>Read Memory</Impact>
                    <Impact>Execute Unauthorized Code or Commands</Impact>
                    <Impact>Gain Privileges or Assume Identity</Impact>
                    <Impact>Bypass Protection Mechanism</Impact>
                    <Impact>Other</Impact>
                    <Likelihood>High</Likelihood>
                </Consequence>
            </Common_Consequences>
            <Potential_Mitigations>
                <Mitigation>
                    <Phase>Architecture and Design</Phase>
                    <Phase>Implementation</Phase>
                    <Phase>Testing</Phase>
                    <Description>
                        <xhtml:ul>
                            <xhtml:li>Access-control-policy protections must be reviewed for design inconsistency and common weaknesses.</xhtml:li>
                            <xhtml:li>Access-control-policy definition and programming flow must be tested in pre-silicon, post-silicon testing.</xhtml:li>
                        </xhtml:ul>
                    </Description>
                    <Effectiveness>High</Effectiveness>
                </Mitigation>
            </Potential_Mitigations>
            <Demonstrative_Examples>
                <Demonstrative_Example>
                    <Intro_Text>
                        <xhtml:p>Consider a system with a register for storing AES key for encryption or decryption. The key is 128 bits, implemented as a set of four 32-bit registers. The key registers are assets and registers, AES_KEY_READ_POLICY and AES_KEY_WRITE_POLICY, and are defined to provide necessary access controls.</xhtml:p>
                        <xhtml:p>The read-policy register defines which agents can read the AES-key registers, and write-policy register defines which agents can program or write to those registers. Each register is a 32-bit register, and it can support access control for a maximum of 32 agents. The number of the bit when set (i.e., "1") allows respective action from an agent whose identity matches the number of the bit and, if "0" (i.e., Clear), disallows the respective action to that corresponding agent.</xhtml:p>
                    </Intro_Text>
                    <Example_Code Nature="bad" Language="Other">
                        <xhtml:table>
                            <xhtml:tr>
                                <xhtml:th>Register</xhtml:th>
                                <xhtml:th>Field description</xhtml:th>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>AES_ENC_DEC_KEY_0</xhtml:td>
                                <xhtml:td>AES key [0:31] for encryption or decryption<xhtml:br/>Default 0x00000000</xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>AES_ENC_DEC_KEY_1</xhtml:td>
                                <xhtml:td>AES key [32:63] for encryption or decryption<xhtml:br/>Default 0x00000000</xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>AES_ENC_DEC_KEY_2</xhtml:td>
                                <xhtml:td>AES key [64:95] for encryption or decryption<xhtml:br/>Default 0x00000000</xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>AES_ENC_DEC_KEY_4</xhtml:td>
                                <xhtml:td>AES key [96:127] for encryption or decryption<xhtml:br/>Default 0x00000000</xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>AES_KEY_READ_WRITE_POLICY</xhtml:td>
                                <xhtml:td>[31:0] Default 0x00000006 - meaning agent with identities "1" and "2" can both read from and write to key registers</xhtml:td>
                            </xhtml:tr>
                        </xhtml:table>
                    </Example_Code>
                    <Body_Text>In the above example, there is only one policy register that controls access to both read and write accesses to the AES-key registers, and thus the design is not granular enough to separate read and writes access for different agents. Here, agent with identities "1" and "2" can both read and write.</Body_Text>
                    <Body_Text>A good design should be granular enough to provide separate access controls to separate actions. Access control for reads should be separate from writes. Below is an example of such implementation where two policy registers are defined for each of these actions. The policy is defined such that: the AES-key registers can only be read or used by a crypto agent with identity "1" when bit #1 is set. The AES-key registers can only be programmed by a trusted firmware with identity "2" when bit #2 is set.</Body_Text>
                    <Example_Code Nature="mitigation">
                        <xhtml:table>
                            <xhtml:tr>
                                <xhtml:td>AES_KEY_READ_POLICY</xhtml:td>
                                <xhtml:td>[31:0] Default 0x00000002 - meaning only Crypto engine with identity "1" can read registers: AES_ENC_DEC_KEY_0, AES_ENC_DEC_KEY_1, AES_ENC_DEC_KEY_2, AES_ENC_DEC_KEY_3</xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>AES_KEY_WRITE_POLICY</xhtml:td>
                                <xhtml:td>[31:0] Default 0x00000004 - meaning only trusted firmware with identity "2" can program registers: AES_ENC_DEC_KEY_0, AES_ENC_DEC_KEY_1, AES_ENC_DEC_KEY_2, AES_ENC_DEC_KEY_3</xhtml:td>
                            </xhtml:tr>
                        </xhtml:table>
                    </Example_Code>
                </Demonstrative_Example>
            <Demonstrative_Example>
	      <Intro_Text>Consider the following SoC
	      design. The sram in HRoT has an address range that is readable and writable by unprivileged
	      software and it has an area that is only readable by unprivileged software. The tbus
	      interconnect enforces access control for slaves on the bus but uses only one bit to control
	      both read and write access. Address 0xA0000000 - 0xA000FFFF is readable and writable
	      by the untrusted cores core{0-N} and address 0xA0010000 - 0xA001FFFF is only
	      readable by the untrusted cores core{0-N}.</Intro_Text>
	    <Body_Text>
	    <xhtml:img src="https://cwe.mitre.org/data/images/HRoT-CWE.png" alt="Hardware Root of Trust"/>
	    <xhtml:p>
	      The security policy access control is not granular enough, as it uses one bit to enable both
	      read and write access. This gives write access to an area that should only be readable
	      by unprivileged agents.
	      </xhtml:p>
	    <xhtml:p>
	      Access control logic should differentiate between read and write access and to have
	      sufficient address granularity.
	    </xhtml:p>
	    </Body_Text>
            </Demonstrative_Example>
            </Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <Content_History>
                <Submission>
                    <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
                    <Submission_Organization>Intel Corporation</Submission_Organization>
                    <Submission_Date>2020-02-05</Submission_Date>
                </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-06-25</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples</Modification_Comment>
				</Modification>
            <Contribution Type="Content">
               <Contribution_Organization>Tortuga Logic</Contribution_Organization>
               <Contribution_Date>2021-07-16</Contribution_Date>
               <Contribution_Comment>Provided Demonstrative Example for Hardware Root of Trust</Contribution_Comment>
            </Contribution>
            </Content_History>
        </Weakness>
      <Weakness ID="1221" Name="Incorrect Register Defaults or Module Parameters" Abstraction="Base" Structure="Simple" Status="Incomplete">
            <Description>Hardware description language code incorrectly defines register defaults or hardware IP parameters to insecure values.</Description>
            <Extended_Description>
                <xhtml:p>Integrated circuits and hardware IP software programmable controls and settings are commonly stored in register circuits. These register contents have to be initialized at hardware reset to defined default values that are hard coded in the hardware description language (HDL) code of the hardware unit. Hardware descriptive languages also support definition of parameter variables, which can be defined in code during instantiation of the hardware IP module. Such parameters are generally used to configure a specific instance of a hardware IP in the design.</xhtml:p>
                <xhtml:p>The system security settings of a hardware design can be affected by incorrectly defined default values or IP parameters. The hardware IP would be in an insecure state at power reset, and this can be exposed or exploited by untrusted software running on the system. Both register defaults and parameters are hardcoded values, which cannot be changed using software or firmware patches but must be changed in hardware silicon. Thus, such security issues are considerably more difficult to address later in the lifecycle. Hardware designs can have a large number of such parameters and register defaults settings, and it is important to have design tool support to check these settings in an automated way and be able to identify which settings are security sensitive.</xhtml:p>
            </Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="665" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
            <Applicable_Platforms>
                <Language Name="Verilog" Prevalence="Undetermined"/>
                <Language Name="VHDL" Prevalence="Undetermined"/>
                <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
            </Applicable_Platforms>
            <Modes_Of_Introduction>
                <Introduction>
                    <Phase>Implementation</Phase>
                    <Note>Such issues could be introduced during implementation of hardware design, since IP parameters and defaults are defined in HDL code and identified later during Testing or System Configuration phases.</Note>
                </Introduction>
            </Modes_Of_Introduction>
            <Common_Consequences>
                <Consequence>
                    <Scope>Confidentiality</Scope>
                    <Scope>Integrity</Scope>
                    <Scope>Availability</Scope>
                    <Scope>Access Control</Scope>
                    <Impact>Varies by Context</Impact>
                    <Note>Degradation of system functionality, or loss of access control enforcement can occur.</Note>
                </Consequence>
            </Common_Consequences>
            <Potential_Mitigations>
                <Mitigation>
                    <Phase>Architecture and Design</Phase>
                    <Description>During hardware design, all the system parameters and register defaults must be reviewed to identify security sensitive settings.</Description>
                </Mitigation>
                <Mitigation>
                    <Phase>Implementation</Phase>
                    <Description>The default values of these security sensitive settings need to be defined as part of the design review phase.</Description>
                </Mitigation>
                <Mitigation>
                    <Phase>Testing</Phase>
                    <Description>Testing phase should use automated tools to test that values are configured per design specifications.</Description>
                </Mitigation>
            </Potential_Mitigations>
            <Demonstrative_Examples>
                <Demonstrative_Example>
                    <Intro_Text>Consider example design module system verilog code shown below.register_example module is an example parameterized module that defines two parameters, REGISTER_WIDTH and REGISTER_DEFAULT. Register_example module defines a Secure_mode setting, which when set makes the register content read-only and not modifiable by software writes. register_top module instantiates two registers, Insecure_Device_ID_1 and Insecure_Device_ID_2. Generally, registers containing device identifier values are required to be read only to prevent any possibility of software modifying these values. </Intro_Text>
                    <Example_Code Nature="bad" Language="Verilog">
                        <xhtml:div>// Parameterized Register module example <xhtml:br/>// Secure_mode : REGISTER_DEFAULT[0] : When set to 1 register is read only and not writable// <xhtml:br/>/module register_example <xhtml:br/>s#( <xhtml:br/> parameter REGISTER_WIDTH = 8, // Parameter defines width of register, default 8 bits <xhtml:br/> parameter [REGISTER_WIDTH-1:0] REGISTER_DEFAULT = 2**REGISTER_WIDTH -2 // Default value of register computed from Width. Sets all bits to 1s except bit 0 (Secure _mode) <xhtml:br/>) <xhtml:br/>( <xhtml:br/>input [REGISTER_WIDTH-1:0] Data_in, <xhtml:br/>input Clk, <xhtml:br/>input resetn, <xhtml:br/>input write, <xhtml:br/>output reg [REGISTER_WIDTH-1:0] Data_out <xhtml:br/>); <xhtml:br/>
                            <xhtml:br/>reg Secure_mode; <xhtml:br/>
                            <xhtml:br/>always @(posedge Clk or negedge resetn) <xhtml:br/> if (~resetn) <xhtml:br/> begin <xhtml:br/> Data_out &lt;= REGISTER_DEFAULT; // Register content set to Default at reset <xhtml:br/> Secure_mode &lt;= REGISTER_DEFAULT[0]; // Register Secure_mode set at reset <xhtml:br/>end <xhtml:br/>else if (write &amp; ~Secure_mode) <xhtml:br/>begin <xhtml:br/> Data_out &lt;= Data_in; <xhtml:br/>end <xhtml:br/>endmodule <xhtml:br/>
                            <xhtml:br/>
                            <xhtml:br/>module register_top <xhtml:br/>( <xhtml:br/>input Clk, <xhtml:br/>input resetn, <xhtml:br/>input write, <xhtml:br/>input [31:0] Data_in, <xhtml:br/>output reg [31:0] Secure_reg, <xhtml:br/>output reg [31:0] Insecure_reg <xhtml:br/>); <xhtml:br/>
                            <xhtml:br/>register_example #( <xhtml:br/> .REGISTER_WIDTH (32), <xhtml:br/> .REGISTER_DEFAULT (1224) // Incorrect Default value used bit 0 is 0. <xhtml:br/>) Insecure_Device_ID_1 ( <xhtml:br/> .Data_in (Data_in), <xhtml:br/> .Data_out (Secure_reg), <xhtml:br/> .Clk (Clk), <xhtml:br/> .resetn (resetn), <xhtml:br/> .write (write) <xhtml:br/>); <xhtml:br/>
                            <xhtml:br/>register_example #( <xhtml:br/> .REGISTER_WIDTH (32) // Default not defined 2^32-2 value will be used as default. <xhtml:br/>) Insecure_Device_ID_2 ( <xhtml:br/> .Data_in (Data_in), <xhtml:br/> .Data_out (Insecure_reg), <xhtml:br/> .Clk (Clk), <xhtml:br/> .resetn (resetn), <xhtml:br/> .write (write) <xhtml:br/>); <xhtml:br/>
                            <xhtml:br/>endmodule <xhtml:br/></xhtml:div>
                    </Example_Code>
                    <Body_Text>These example instantiations show how, in a hardware design, it would be possible to instantiate the register module with insecure defaults and parameters.</Body_Text>
                    <Body_Text>In the example design, both registers will be software writable since Secure_mode is defined as zero. </Body_Text>
                    <Example_Code Nature="informative">
                        <xhtml:div>register_example #( <xhtml:br/> .REGISTER_WIDTH (32), <xhtml:br/> .REGISTER_DEFAULT (1225) // Correct default value set, to enable Secure_mode <xhtml:br/>) Secure_Device_ID_example ( <xhtml:br/> .Data_in (Data_in), <xhtml:br/> .Data_out (Secure_reg), <xhtml:br/> .Clk (Clk), <xhtml:br/> .resetn (resetn), <xhtml:br/> .write (write) <xhtml:br/>); </xhtml:div>
                    </Example_Code>
                </Demonstrative_Example>
            </Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="166"/>
         </Related_Attack_Patterns>
         <Content_History>
                <Submission>
                    <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
                    <Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2019-12-12</Submission_Date>
                </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
            </Content_History>
        </Weakness>
      <Weakness ID="1223" Name="Race Condition for Write-Once Attributes" Abstraction="Base" Structure="Simple" Status="Incomplete">
            <Description>A write-once register in hardware design is programmable by an untrusted software component earlier than the trusted software component, resulting in a race condition issue.</Description>
            <Extended_Description>
                <xhtml:p>Integrated circuits and hardware IP software programmable controls and settings are commonly stored in register circuits. These register contents have to be initialized at hardware reset to defined default values that are hard coded in the hardware description language (HDL) code of the hardware unit. A common security protection method used to protect register settings from modification by software is to make them write-once. This means the hardware implementation only allows writing to such registers once, and they become read-only after having been written once by software. This is useful to allow initial boot software to configure systems settings to secure values while blocking runtime software from modifying such hardware settings.</xhtml:p>
                <xhtml:p>Implementation issues in hardware design of such controls can expose such registers to a race condition security flaw. For example, consider a hardware design that has two different software/firmware modules executing in parallel. One module is trusted (module A) and another is untrusted (module B). In this design it could be possible for Module B to send write cycles to the write-once register before Module A. Since the field is write-once the programmed value from Module A will be ignored and the pre-empted value programmed by Module B will be used by hardware.</xhtml:p>
            </Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="362" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
            <Applicable_Platforms>
                <Language Name="Verilog" Prevalence="Undetermined"/>
                <Language Name="VHDL" Prevalence="Undetermined"/>
                <Technology Class="System on Chip" Prevalence="Undetermined"/>
            </Applicable_Platforms>
            <Modes_Of_Introduction>
                <Introduction>
                    <Phase>Architecture and Design</Phase>
                    <Note>This weakness can appear in designs that use register write-once attributes with two or more software/firmware modules with varying levels of trust executing in parallel.</Note>
                </Introduction>
            </Modes_Of_Introduction>
            <Common_Consequences>
                <Consequence>
                    <Scope>Access Control</Scope>
                    <Impact>Bypass Protection Mechanism</Impact>
                    <Note>System configuration cannot be programmed in a secure way.</Note>
                </Consequence>
            </Common_Consequences>
            <Potential_Mitigations>
                <Mitigation>
                    <Phase>Architecture and Design</Phase>
                    <Description>During hardware design all register write-once or sticky fields must be evaluated for proper configuration.</Description>
                </Mitigation>
                <Mitigation>
                    <Phase>Testing</Phase>
                    <Description>The testing phase should use automated tools to test that values are not reprogrammable and that write-once fields lock on writing zeros.</Description>
                </Mitigation>
            </Potential_Mitigations>
            <Demonstrative_Examples>
                <Demonstrative_Example>
                    <Intro_Text>consider the example design module system verilog code shown below. register_write_once_example module is an example of register that has a write-once field defined. Bit 0 field captures the write_once_status value.</Intro_Text>
                    <Example_Code Nature="bad" Language="Verilog">
                        <xhtml:div>module register_write_once_example 
                        <xhtml:br/>( 
                        <xhtml:br/>  input [15:0] Data_in, 
                        <xhtml:br/>  input Clk, 
                        <xhtml:br/>  input ip_resetn, 
                        <xhtml:br/>  input global_resetn, 
                        <xhtml:br/>  input write, 
                        <xhtml:br/>  output reg [15:0] Data_out 
                        <xhtml:br/>); 
                        <xhtml:br/>
                        <xhtml:br/>reg Write_once_status; 
                        <xhtml:br/>
                        <xhtml:br/>always @(posedge Clk or negedge ip_resetn)<xhtml:br/>
                        <xhtml:br/>if (~ip_resetn) 
                        <xhtml:br/>  begin 
                        <xhtml:br/>    Data_out &lt;= 16'h0000; 
                        <xhtml:br/>    Write_once_status &lt;= 1'b0; 
                        <xhtml:br/>  end 
                        <xhtml:br/>else if (write &amp; ~Write_once_status) 
                        <xhtml:br/>  begin 
                        <xhtml:br/>    Data_out &lt;= Data_in &amp; 16'hFFFE; // Input data written to register after masking bit 0 
                        <xhtml:br/>    Write_once_status &lt;= 1'b1; // Write once status set after first write. 
                        <xhtml:br/>  end 
                        <xhtml:br/>else if (~write) 
                        <xhtml:br/>  begin 
                        <xhtml:br/>    Data_out[15:1] &lt;= Data_out[15:1]; 
                        <xhtml:br/>    Data_out[0] &lt;= Write_once_status; 
                        <xhtml:br/>  end 
                        <xhtml:br/>
                        <xhtml:br/>endmodule </xhtml:div>
                    </Example_Code>
                    <Body_Text>The first system component that sends a write cycle to this register can program the value. This could result in a race condition security issue in SoC design, if an untrusted agent is running in the system in parallel with the trusted component that is expected to program the register.</Body_Text>
                    <Example_Code Nature="informative">
                        <xhtml:div>Trusted firmware or software trying to set the write-once field. <xhtml:br/> - Must confirm the Write_once_status (bit 0) value is zero, before programming register. If another agent has programmed the register before, then Write_once_status value will be one. <xhtml:br/> - After writing to the register, the trusted software can issue a read to confirm that the valid setting has been programmed. </xhtml:div>
                    </Example_Code>
                </Demonstrative_Example>
            </Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="26"/>
         </Related_Attack_Patterns>
         <Content_History>
                <Submission>
                    <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
                    <Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2019-12-12</Submission_Date>
                </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
            </Content_History>
        </Weakness>
      <Weakness ID="1224" Name="Improper Restriction of Write-Once Bit Fields" Abstraction="Base" Structure="Simple" Status="Incomplete">
            <Description>The hardware design control register "sticky bits" or write-once bit fields are improperly implemented, such that they can be reprogrammed by software.</Description>
            <Extended_Description>
                <xhtml:p>Integrated circuits and hardware IP software programmable controls and settings are commonly stored in register circuits. These register contents have to be initialized at hardware reset to define default values that are hard coded in the hardware description language (HDL) code of the hardware unit. A common security protection method used to protect register settings from modification by software is to make the settings write-once or "sticky." This allows writing to such registers only once, whereupon they become read-only. This is useful to allow initial boot software to configure systems settings to secure values while blocking runtime software from modifying such hardware settings.</xhtml:p>
                <xhtml:p>Failure to implement write-once restrictions in hardware design can expose such registers to being re-programmed by software and written multiple times. For example, write-once fields could be implemented to only be write-protected if they have been set to value "1", wherein they would work as "write-1-once" and not "write-once".</xhtml:p>
            </Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
            <Applicable_Platforms>
                <Language Name="Verilog" Prevalence="Undetermined"/>
                <Language Name="VHDL" Prevalence="Undetermined"/>
                <Technology Class="System on Chip" Prevalence="Undetermined"/>
            </Applicable_Platforms>
            <Modes_Of_Introduction>
                <Introduction>
                    <Phase>Architecture and Design</Phase>
                </Introduction>
                <Introduction>
                    <Phase>Implementation</Phase>
                    <Note>Such issues could be introduced during implementation of hardware design, since IP parameters and defaults are defined in HDL code and identified later during Testing or System Configuration phases.</Note>
                </Introduction>
            </Modes_Of_Introduction>
            <Common_Consequences>
                <Consequence>
                    <Scope>Confidentiality</Scope>
                    <Scope>Integrity</Scope>
                    <Scope>Availability</Scope>
                    <Scope>Access Control</Scope>
                    <Impact>Varies by Context</Impact>
                    <Note>System configuration cannot be programmed in a secure way.</Note>
                </Consequence>
            </Common_Consequences>
            <Potential_Mitigations>
                <Mitigation>
                    <Phase>Architecture and Design</Phase>
                    <Description>During hardware design all register write-once or sticky fields must be evaluated for proper configuration.</Description>
                </Mitigation>
                <Mitigation>
                    <Phase>Testing</Phase>
                    <Description>The testing phase should use automated tools to test that values are not reprogrammable and that write-once fields lock on writing zeros.</Description>
                </Mitigation>
            </Potential_Mitigations>
            <Demonstrative_Examples>
                <Demonstrative_Example>
                    <Intro_Text>Consider the example design module system verilog code shown below. register_write_once_example module is an example of register that has a write-once field defined. Bit 0 field captures the write_once_status value. This implementation can be for a register that is defined by specification to be a write-once register, since the write_once_status field gets written by input data bit 0 on first write. </Intro_Text>
                    <Example_Code Nature="bad" Language="Verilog">
                        <xhtml:div>module register_write_once_example <xhtml:br/>( <xhtml:br/>input [15:0] Data_in, <xhtml:br/>input Clk, <xhtml:br/>input ip_resetn, <xhtml:br/>input global_resetn, <xhtml:br/>input write, <xhtml:br/>output reg [15:0] Data_out <xhtml:br/>); <xhtml:br/>
                            <xhtml:br/>reg Write_once_status; <xhtml:br/>
                            <xhtml:br/>always @(posedge Clk or negedge ip_resetn) <xhtml:br/> if (~ip_resetn) <xhtml:br/> begin <xhtml:br/> Data_out &lt;= 16'h0000; <xhtml:br/> Write_once_status &lt;= 1'b0; <xhtml:br/> end <xhtml:br/> else if (write &amp; ~Write_once_status) <xhtml:br/> begin <xhtml:br/> Data_out &lt;= Data_in &amp; 16'hFFFE; <xhtml:br/> Write_once_status &lt;= Data_in[0]; // Input bit 0 sets Write_once_status <xhtml:br/> end <xhtml:br/> else if (~write) <xhtml:br/> begin <xhtml:br/> Data_out[15:1] &lt;= Data_out[15:1]; <xhtml:br/> Data_out[0] &lt;= Write_once_status; <xhtml:br/> end <xhtml:br/>
                            <xhtml:br/>endmodule </xhtml:div>
                    </Example_Code>
                    <Body_Text>The above example only locks further writes if write_once_status bit is written to one. So it acts as write_1-Once instead of the write-once attribute.</Body_Text>
                    <Example_Code Nature="informative">
                        <xhtml:div>module register_write_once_example <xhtml:br/>( <xhtml:br/>input [15:0] Data_in, <xhtml:br/>input Clk, <xhtml:br/>input ip_resetn, <xhtml:br/>input global_resetn, <xhtml:br/>input write, <xhtml:br/>output reg [15:0] Data_out <xhtml:br/>); <xhtml:br/>
                            <xhtml:br/>reg Write_once_status; <xhtml:br/>
                            <xhtml:br/>always @(posedge Clk or negedge ip_resetn) <xhtml:br/> if (~ip_resetn) <xhtml:br/> begin <xhtml:br/> Data_out &lt;= 16'h0000; <xhtml:br/> Write_once_status &lt;= 1'b0; <xhtml:br/> end <xhtml:br/> else if (write &amp; ~Write_once_status) <xhtml:br/> begin <xhtml:br/> Data_out &lt;= Data_in &amp; 16'hFFFE; <xhtml:br/> Write_once_status &lt;= 1'b1; // Write once status set on first write, independent of input <xhtml:br/> end <xhtml:br/> else if (~write) <xhtml:br/> begin <xhtml:br/> Data_out[15:1] &lt;= Data_out[15:1]; <xhtml:br/> Data_out[0] &lt;= Write_once_status; <xhtml:br/> end <xhtml:br/>
                            <xhtml:br/>endmodule </xhtml:div>
                    </Example_Code>
                </Demonstrative_Example>
            </Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <Content_History>
                <Submission>
                    <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
                    <Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2019-12-12</Submission_Date>
                </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
            </Content_History>
        </Weakness>
      <Weakness ID="1231" Name="Improper Prevention of Lock Bit Modification" Abstraction="Base" Structure="Simple" Status="Stable">
            <Description>The product uses a trusted lock bit for restricting access to registers, address regions, or other resources, but the product does not prevent the value of the lock bit from being modified after it has been set.</Description>
			<Extended_Description>
			  <xhtml:p>In integrated circuits and hardware
			  intellectual property (IP) cores, device configuration
			  controls are commonly programmed after a device power
			  reset by a trusted firmware or software module (e.g.,
			  BIOS/bootloader) and then locked from any further
			  modification.</xhtml:p>

			  <xhtml:p>This behavior is commonly implemented using a trusted lock bit. 
			  When set, the lock bit disables writes to a protected set of
			  registers or address regions. Design or coding errors in
			  the implementation of the lock bit protection feature
			  may allow the lock bit to be modified or cleared by
			  software after it has been set. Attackers might be able to unlock the system and
			  features that the bit is intended to protect.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
		 <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Primary</Ordinality>
            </Weakness_Ordinality>
		 </Weakness_Ordinalities>
            <Applicable_Platforms>
                <Language Class="Language-Independent" Prevalence="Undetermined"/>
                <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
                <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
                <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
            </Applicable_Platforms>
            <Modes_Of_Introduction>
                <Introduction>
                    <Phase>Architecture and Design</Phase>
                    <Note>Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.</Note>
                </Introduction>
                <Introduction>
                    <Phase>Implementation</Phase>
                    <Note>Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.</Note>
                </Introduction>
            </Modes_Of_Introduction>
            <Common_Consequences>
                <Consequence>
                    <Scope>Access Control</Scope>
                    <Impact>Modify Memory</Impact>
                    <Likelihood>High</Likelihood>
                    <Note>Registers protected by lock bit can be modified even when lock is set.</Note>
                </Consequence>
            </Common_Consequences>
	 <Detection_Methods>
	   <Detection_Method>
	     <Method>Manual Analysis</Method>
	     <Description>Set the lock bit. Power cycle the
	     device. Attempt to clear the lock bit.  If the
	     information is changed, implement a design
	     fix. Retest. Also, attempt to indirectly clear the lock
	     bit or bypass it.</Description>
	     <Effectiveness>High</Effectiveness>
	   </Detection_Method>
	 </Detection_Methods>
            <Potential_Mitigations>
                <Mitigation>
                    <Phase>Architecture and Design</Phase>
                    <Phase>Implementation</Phase>
                    <Phase>Testing</Phase>
                    <Description>
                        <xhtml:ul>
                            <xhtml:li>Security lock bit protections must be reviewed for design inconsistency and common weaknesses.</xhtml:li>
                            <xhtml:li>Security lock programming flow and lock properties must be tested in pre-silicon and post-silicon testing.</xhtml:li>
                        </xhtml:ul>
                    </Description>
                    <Effectiveness>High</Effectiveness>
                </Mitigation>
            </Potential_Mitigations>
            <Demonstrative_Examples>
                <Demonstrative_Example>
                    <Intro_Text>Consider the example design below for a digital thermal sensor that detects overheating of the silicon and triggers system shutdown. The system critical temperature limit (CRITICAL_TEMP_LIMIT) and thermal sensor calibration (TEMP_SENSOR_CALIB) data have to be programmed by firmware, and then the register needs to be locked (TEMP_SENSOR_LOCK).</Intro_Text>
                    <Example_Code Nature="bad" Language="Other">
                        <xhtml:table>
                            <xhtml:tr>
                                <xhtml:th>Register</xhtml:th>
                                <xhtml:th>Field description</xhtml:th>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>CRITICAL_TEMP_LIMIT</xhtml:td>
                                <xhtml:td>[31:8] Reserved field; Read only; Default 0<xhtml:p/>[7:0] Critical temp 0-255 Centigrade; Read-write-lock; Default 125</xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>TEMP_SENSOR_CALIB</xhtml:td>
                                <xhtml:td>[31:0] Thermal sensor calibration data. Slope value used to map sensor reading to degrees Centigrade.</xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>TEMP_SENSOR_LOCK</xhtml:td>
                                <xhtml:td>[31:1] Reserved field; Read only; Default 0<xhtml:p/>[0] Lock bit, locks CRITICAL_TEMP_LIMIT and TEMP_SENSOR_CALIB registers; Write-1-once; Default 0</xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>TEMP_HW_SHUTDOWN</xhtml:td>
                                <xhtml:td>[31:2] Reserved field; Read only; Default 0<xhtml:p/>[1] Enable hardware shutdown on critical temperature detection; Read-write; Default 0</xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>CURRENT_TEMP</xhtml:td>
                                <xhtml:td> [31:8] Reserved field; Read only; Default 0<xhtml:p/>[7:0] Current Temp 0-255 Centigrade; Read-only; Default 0</xhtml:td>
                            </xhtml:tr>
                        </xhtml:table>
                    </Example_Code>
                    <Body_Text>In this example, note that if the system heats to critical temperature, the response of the system is controlled by the TEMP_HW_SHUTDOWN bit [1], which is not lockable. Thus, the intended security property of the critical temperature sensor cannot be fully protected, since software can misconfigure the TEMP_HW_SHUTDOWN register even after the lock bit is set to disable the shutdown response.</Body_Text>
                    <Example_Code Nature="good">
                        <xhtml:p>To fix this weakness, one could change the TEMP_HW_SHUTDOWN field to be locked by TEMP_SENSOR_LOCK.</xhtml:p>
                        <xhtml:table>
                            <xhtml:tr>
                                <xhtml:td>TEMP_HW_SHUTDOWN</xhtml:td>
                                <xhtml:td>[31:2] Reserved field; Read only; Default 0 <xhtml:p/>[1] Enable hardware shutdown on critical temperature detection; Read-write-Lock; Default 0<xhtml:p/>[0] Locked by TEMP_SENSOR_LOCK</xhtml:td>
                            </xhtml:tr>
                        </xhtml:table>
                    </Example_Code>
                </Demonstrative_Example>
            </Demonstrative_Examples>
	    <Observed_Examples>
	      <Observed_Example>
		<Reference>CVE-2017-6283</Reference>
		<Description>chip reset clears critical read/write lock permissions for RSA function</Description>
		<Link>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-6283</Link>
	      </Observed_Example>
	    </Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <Content_History>
                <Submission>
                    <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
                    <Submission_Organization>Intel Corporation</Submission_Organization>
                    <Submission_Date>2020-01-15</Submission_Date>
                </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-06-25</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
				<Contribution Type="Feedback">
				  <Contribution_Name>Narasimha Kumar V Mangipudi</Contribution_Name>
				  <Contribution_Organization>Lattice Semiconductor</Contribution_Organization>
				  <Contribution_Date>2021-10-20</Contribution_Date>
				  <Contribution_Comment>reviewed content changes</Contribution_Comment>
				</Contribution>
				<Contribution Type="Content">
				  <Contribution_Name>Hareesh Khattri</Contribution_Name>
				  <Contribution_Organization>Intel Corporation</Contribution_Organization>
				  <Contribution_Date>2021-10-22</Contribution_Date>
				  <Contribution_Comment>provided observed example</Contribution_Comment>
				</Contribution>
            </Content_History>
        </Weakness>
      <Weakness ID="1232" Name="Improper Lock Behavior After Power State Transition" Abstraction="Base" Structure="Simple" Status="Incomplete">
      <Description>Register lock bit protection disables changes to system configuration once the bit is set. Some of the protected registers or lock bits become programmable after power state transitions (e.g., Entry and wake from low power sleep modes) causing the system configuration to be changeable.</Description>
      <Extended_Description>
        <xhtml:p>Devices may allow device configuration controls which need to be programmed after device power reset via a trusted firmware or software module (commonly set by BIOS/bootloader) and then locked from any further modification. This action is commonly implemented using a programmable lock bit, which, when set, disables writes to a protected set of registers or address regions.</xhtml:p>
        <xhtml:p>After a power state transition, the lock bit is set to unlocked. Some common weaknesses that can exist in such a protection scheme are that the lock gets cleared, the values of the protected registers get reset, or the lock become programmable.</xhtml:p>
      </Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="667" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
      <Applicable_Platforms>
        <Language Class="Language-Independent" Prevalence="Undetermined"/>
        <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
        <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
        <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
      </Applicable_Platforms>
      <Modes_Of_Introduction>
        <Introduction>
          <Phase>Architecture and Design</Phase>
        </Introduction>
        <Introduction>
          <Phase>Implementation</Phase>
        </Introduction>
      </Modes_Of_Introduction>
      <Common_Consequences>
        <Consequence>
          <Scope>Access Control</Scope>
          <Impact>Modify Memory</Impact>
          <Likelihood>High</Likelihood>
        </Consequence>
      </Common_Consequences>
      <Potential_Mitigations>
        <Mitigation>
          <Phase>Architecture and Design</Phase>
          <Phase>Implementation</Phase>
          <Phase>Testing</Phase>
          <Description>
            <xhtml:ul>
              <xhtml:li>Security Lock bit protections should be reviewed for behavior across supported power state transitions.</xhtml:li>
              <xhtml:li>Security lock programming flow and lock properties should be tested in pre-silicon and post-silicon testing including testing across power transitions.</xhtml:li>
            </xhtml:ul>
          </Description>
          <Effectiveness>High</Effectiveness>
        </Mitigation>
      </Potential_Mitigations>
      <Demonstrative_Examples>
        <Demonstrative_Example>
          <Intro_Text>
            <xhtml:p>Consider the memory configuration settings of a system that uses DDR3 DRAM memory. Protecting the DRAM memory configuration from modification by software is required to ensure that system memory access control protections cannot be bypassed. This can be done by using lock bit protection that locks all of the memory configuration registers. The memory configuration lock can be set by the BIOS during the boot process.</xhtml:p>
            <xhtml:p>If such a system also supports a rapid power on mode like hibernate, the DRAM data must be saved to a disk before power is removed and restored back to the DRAM once the system powers back up and before the OS resumes operation after returning from hibernate.</xhtml:p>
          </Intro_Text>
          <Body_Text>To support the hibernate transition back to the operating state, the DRAM memory configuration must be reprogrammed even though it was locked previously. As the hibernate resume does a partial reboot, the memory configuration could be altered before the memory lock is set. Functionally the hibernate resume flow requires a bypass of the lock-based protection. The memory configuration must be securely stored and restored by trusted system firmware. Lock settings and system configuration must be restored to the same state it was in before the device entered into the hibernate mode.</Body_Text>
        </Demonstrative_Example>
      </Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="166"/>
         </Related_Attack_Patterns>
         <Content_History>
        <Submission>
          <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
          <Submission_Organization>Intel Corporation</Submission_Organization>
          <Submission_Date>2020-01-15</Submission_Date>
        </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Common_Consequences, Demonstrative_Examples, Description, Modes_of_Introduction, Potential_Mitigations, Related_Attack_Patterns</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Description</Modification_Comment>
				</Modification>
      </Content_History>
    </Weakness>
      <Weakness ID="1233" Name="Security-Sensitive Hardware Controls with Missing Lock Bit Protection" Abstraction="Base" Structure="Simple" Status="Stable">
         <Description>The product uses a register lock bit protection mechanism, but it does not ensure that the lock bit prevents modification of system registers or controls that perform changes to important hardware system configuration.</Description>
         <Extended_Description>
         	<xhtml:p>Integrated circuits and hardware intellectual properties (IPs) might provide device configuration controls that need to be programmed after device power reset by a trusted firmware or software module, commonly set by BIOS/bootloader. After reset, there can be an expectation that the controls cannot be used to perform any further modification. This behavior is commonly implemented using a trusted lock bit, which can be set to disable writes to a protected set of registers or address regions. The lock protection is intended to prevent modification of certain system configuration (e.g., memory/memory protection unit configuration).</xhtml:p>
		<xhtml:p>However, if the lock bit does not effectively write-protect all system registers or controls that could modify the protected system configuration, then an adversary may be able to use software to access the registers/controls and modify the protected hardware configuration.</xhtml:p>
		</Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			  <Related_Weakness Nature="ChildOf" CWE_ID="667" View_ID="1000"/>
			</Related_Weaknesses>
		 <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Primary</Ordinality>
            </Weakness_Ordinality>
		 </Weakness_Ordinalities>
         <Applicable_Platforms>
            <Language Class="Language-Independent" Prevalence="Undetermined"/>
			<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
			<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
			<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
         </Applicable_Platforms>
         <Modes_Of_Introduction>
            <Introduction>
               <Phase>Architecture and Design</Phase>
               <Note>Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.</Note>
            </Introduction>
            <Introduction>
               <Phase>Implementation</Phase>
               <Note>Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.</Note>
            </Introduction>
         </Modes_Of_Introduction>
         <Common_Consequences>
            <Consequence>
               <Scope>Access Control</Scope>
			   <Impact>Modify Memory</Impact>
               <Note>System Configuration protected by the lock bit can be modified even when the lock is set.</Note>
            </Consequence>
         </Common_Consequences>
	 <Detection_Methods>
	   <Detection_Method>
	     <Method>Manual Analysis</Method>
	     <Description>Set the lock bit. Attempt to modify the
	     information protected by the lock bit. If the information
	     is changed, implement a design fix. Retest. Also, attempt
	     to indirectly clear the lock bit or bypass
	     it.</Description>
	     <Effectiveness>High</Effectiveness>
	   </Detection_Method>
	 </Detection_Methods>
         <Potential_Mitigations>
            <Mitigation>
               <Phase>Architecture and Design</Phase>
                    <Phase>Implementation</Phase>
                    <Phase>Testing</Phase>
                    <Description>
                        <xhtml:ul>
                            <xhtml:li>Security lock bit protections must be reviewed for design inconsistency and common weaknesses.</xhtml:li>
			    <xhtml:li>Security lock programming flow and lock properties must be tested in pre-silicon and post-silicon testing.</xhtml:li>
                        </xhtml:ul>
                    </Description>
            </Mitigation>
         </Potential_Mitigations>
         <Demonstrative_Examples>
            <Demonstrative_Example>
               <Intro_Text>Consider the example design below for a digital thermal sensor that detects overheating of the silicon and triggers system shutdown. The system critical temperature limit (CRITICAL_TEMP_LIMIT) and thermal sensor calibration (TEMP_SENSOR_CALIB) data have to be programmed by the firmware. 
               </Intro_Text>
               <Example_Code Nature="bad" Language="Other">
				<xhtml:table>
				    <xhtml:tr>
				        <xhtml:th>Register</xhtml:th>
				        <xhtml:th>Field description</xhtml:th>
				    </xhtml:tr>
				<xhtml:tr>
				  <xhtml:td>CRITICAL_TEMP_LIMIT
				  </xhtml:td>
				  <xhtml:td>[31:8] Reserved field; Read only; Default 0<xhtml:p/>[7:0] Critical temp 0-255 Centigrade; Read-write-lock; Default 125
				  </xhtml:td>
				  </xhtml:tr>
				  <xhtml:tr>
				  <xhtml:td>TEMP_SENSOR_CALIB
				  </xhtml:td>
				  <xhtml:td>[31:0] Thermal sensor calibration data. A slope value used to map sensor reading to a degree Centigrade. Read-write; Default 25
				  </xhtml:td>
				  </xhtml:tr>
				  <xhtml:tr>
				  <xhtml:td>TEMP_SENSOR_LOCK
				  </xhtml:td>
				  <xhtml:td>[31:1] Reserved field; Read only; Default 0<xhtml:p/>[0] Lock bit, locks CRITICAL_TEMP_LIMIT register; Write-1-once; Default 0
				  </xhtml:td>
				  </xhtml:tr>
				  <xhtml:tr>
				  <xhtml:td>TEMP_HW_SHUTDOWN
				  </xhtml:td>
				  <xhtml:td>[31:2] Reserved field; Read only; Default 0<xhtml:p/>[1] Enable hardware shutdown on a critical temperature detection; Read-write; Default 0
				  </xhtml:td>
				  </xhtml:tr>
				  <xhtml:tr>
				  <xhtml:td>CURRENT_TEMP
				  </xhtml:td>
				  <xhtml:td> [31:8] Reserved field; Read only; Default 0<xhtml:p/>[7:0]   Current Temp 0-255 Centigrade; Read-only; Default 0 
				  </xhtml:td>
				  </xhtml:tr>
				  </xhtml:table>
               </Example_Code>				  
			   <Body_Text>
			   <xhtml:p>In this example note that only the CRITICAL_TEMP_LIMIT register is protected by the TEMP_SENSOR_LOCK bit, while the security design intent is to protect any modification of the critical temperature detection and response. 
			   </xhtml:p>
			   <xhtml:p>The response of the system, if the system heats to a critical temperature, is controlled by TEMP_HW_SHUTDOWN bit [1], which is not lockable. Also, the TEMP_SENSOR_CALIB register is not protected by the lock bit.
			   </xhtml:p>
			   <xhtml:p>By modifying the temperature sensor calibration, the conversion of the sensor data to a degree centigrade can be changed, such that the current temperature will never be detected to exceed critical temperature value programmed by the protected lock.
			   </xhtml:p>
			   <xhtml:p>Similarly, by modifying the TEMP_HW_SHUTDOWN.Enable bit, the system response detection of the current temperature exceeding critical temperature can be disabled.
			   </xhtml:p>
			   </Body_Text>
			   <Example_Code Nature="good"><xhtml:p>Change TEMP_HW_SHUTDOWN and TEMP_SENSOR_CALIB controls to be locked by TEMP_SENSOR_LOCK.
			   </xhtml:p>
			   <xhtml:table>
				<xhtml:tr>
				  <xhtml:td>TEMP_SENSOR_CALIB
				  </xhtml:td>
				  <xhtml:td>[31:0] Thermal sensor calibration data. A slope value used to map sensor reading to a degree Centigrade. Read-write-Lock; Default 25; Locked by TEMP_SENSOR_LOCK bit[0]
				  </xhtml:td>
				  </xhtml:tr>
				  <xhtml:tr>
				  <xhtml:td>TEMP_HW_SHUTDOWN
				  </xhtml:td>
				  <xhtml:td>[31:2] Reserved field; Read only; Default 0<xhtml:p/>[1] Enable hardware shutdown on critical temperature detection; Read-write-Lock; Default 0; Locked by TEMP_SENSOR_LOCK bit[0]
				  </xhtml:td>
				  </xhtml:tr>
				  </xhtml:table>
               </Example_Code>
            </Demonstrative_Example>
         </Demonstrative_Examples>
	    <Observed_Examples>
	      <Observed_Example>
		<Reference>CVE-2018-9085</Reference>
		<Description>Certain servers leave a write protection lock bit
		unset after boot, potentially allowing modification of
		parts of flash memory.</Description>
		<Link>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-9085</Link>
	      </Observed_Example>
		<Observed_Example>
		  <Reference>CVE-2014-8273</Reference>
		  <Description>Chain: chipset has a race condition (CWE-362) between when an interrupt handler detects an attempt to write-enable the BIOS (in violation of the lock bit), and when the handler resets the write-enable bit back to 0, allowing attackers to issue BIOS writes during the timing window [REF-1237].</Description>
		  <Link>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-8273</Link>
		</Observed_Example>
	      </Observed_Examples>
	      <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="176"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <References>
		<Reference External_Reference_ID="REF-1237"/>
	      </References>
         <Content_History>
            <Submission>
                <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
                <Submission_Organization>Intel Corporation</Submission_Organization>
                <Submission_Date>2020-01-15</Submission_Date>
            </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Maintenance_Notes</Modification_Comment>
				</Modification>
				<Contribution Type="Feedback">
				  <Contribution_Name>Narasimha Kumar V Mangipudi</Contribution_Name>
				  <Contribution_Organization>Lattice Semiconductor</Contribution_Organization>
				  <Contribution_Date>2021-10-20</Contribution_Date>
				  <Contribution_Comment>reviewed content changes</Contribution_Comment>
				</Contribution>
         </Content_History>
      </Weakness>
      <Weakness ID="1234" Name="Hardware Internal or Debug Modes Allow Override of Locks" Abstraction="Base" Structure="Simple" Status="Incomplete">
     <Description>System configuration protection may be bypassed during debug mode.</Description>
     <Extended_Description>
     	<xhtml:p>Device configuration controls are commonly programmed after a device power reset by a trusted firmware or software module (e.g., BIOS/bootloader) and then locked from any further modification. This is commonly implemented using a trusted lock bit, which when set, disables writes to a protected set of registers or address regions. The lock protection is intended to prevent modification of certain system configuration (e.g., memory/memory protection unit configuration). If debug features supported by hardware or internal modes/system states are supported in the hardware design, modification of the lock protection may be allowed allowing access and modification of configuration information.</xhtml:p>
		</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="667" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
     <Applicable_Platforms>
      <Language Class="Language-Independent" Prevalence="Undetermined"/>
		  <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
      <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
      <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
    </Applicable_Platforms>
     <Modes_Of_Introduction>
      <Introduction>
        <Phase>Architecture and Design</Phase>
     </Introduction>
			<Introduction>
        <Phase>Implementation</Phase>
     </Introduction>
    </Modes_Of_Introduction>
     <Common_Consequences>
      <Consequence>
        <Scope>Access Control</Scope>
        <Impact>Bypass Protection Mechanism</Impact>
        <Likelihood>High</Likelihood>
        <Note>Bypass of lock bit allows access and modification of system configuration even when the lock bit is set.</Note>
     </Consequence>
    </Common_Consequences>
     <Potential_Mitigations>
      <Mitigation>
       <Phase>Architecture and Design</Phase>
       <Phase>Implementation</Phase>
       <Phase>Testing</Phase>
        <Description>
         <xhtml:ul>
          <xhtml:li>Security Lock bit protections should be reviewed for any bypass/override modes supported.</xhtml:li>
          <xhtml:li>Any supported override modes either should be removed or protected using authenticated debug modes.</xhtml:li>
          <xhtml:li>Security lock programming flow and lock properties should be tested in pre-silicon and post-silicon testing.</xhtml:li>
        </xhtml:ul>
       </Description>
        <Effectiveness>High</Effectiveness>
     </Mitigation>
    </Potential_Mitigations>
     <Demonstrative_Examples>
      <Demonstrative_Example>
       <Intro_Text>
         For example, consider the example Locked_override_register example. This register module supports a lock mode that blocks any writes after lock is set to 1.
        <xhtml:br/>
         However, it also allows override of the lock protection when scan_mode or debug_unlocked modes are active.
       </Intro_Text>
        <Example_Code Nature="bad" Language="Verilog">
          <xhtml:p>module Locked_register_example</xhtml:p>
          <xhtml:p>(</xhtml:p>
          <xhtml:p style="text-indent: 15px;">input [15:0] Data_in,</xhtml:p>
          <xhtml:p style="text-indent: 15px;">input Clk,</xhtml:p>
          <xhtml:p style="text-indent: 15px;">input resetn,</xhtml:p>
          <xhtml:p style="text-indent: 15px;">input write,</xhtml:p>
          <xhtml:p style="text-indent: 15px;">input Lock,</xhtml:p>
          <xhtml:p style="text-indent: 15px;">input scan_mode,</xhtml:p>
          <xhtml:p style="text-indent: 15px;">input debug_unlocked,</xhtml:p>
          <xhtml:p style="text-indent: 15px;">output reg [15:0] Data_out</xhtml:p>
          <xhtml:p>);</xhtml:p>
          <xhtml:p/>
          <xhtml:p>reg lock_status;</xhtml:p>
          <xhtml:p/>
          <xhtml:p>always @(posedge Clk or negedge resetn)</xhtml:p>
          <xhtml:p>if (~resetn) // Register is reset resetn</xhtml:p>
          <xhtml:p style="text-indent: 15px;">begin</xhtml:p>
          <xhtml:p style="text-indent: 30px;">lock_status &lt;= 1'b0;</xhtml:p>
          <xhtml:p style="text-indent: 15px;">end</xhtml:p>
          <xhtml:p style="text-indent: 15px;">else if (Lock)</xhtml:p>
          <xhtml:p style="text-indent: 15px;">begin</xhtml:p>
          <xhtml:p style="text-indent: 30px;">lock_status &lt;= 1'b1;</xhtml:p>
          <xhtml:p style="text-indent: 15px;">end</xhtml:p>
          <xhtml:p style="text-indent: 15px;">else if (~Lock)</xhtml:p>
          <xhtml:p style="text-indent: 15px;">begin</xhtml:p>
          <xhtml:p style="text-indent: 30px;">lock_status &lt;= lock_status</xhtml:p>
          <xhtml:p style="text-indent: 15px;">end</xhtml:p>
          <xhtml:p/>
          <xhtml:p>always @(posedge Clk or negedge resetn)</xhtml:p>
          <xhtml:p style="text-indent: 15px;">if (~resetn) // Register is reset resetn</xhtml:p>
          <xhtml:p style="text-indent: 15px;">begin</xhtml:p>
          <xhtml:p style="text-indent: 30px;">Data_out &lt;= 16'h0000;</xhtml:p>
          <xhtml:p style="text-indent: 15px;">end</xhtml:p>
          <xhtml:p style="text-indent: 15px;">else if (write &amp; (~lock_status | scan_mode | debug_unlocked) ) // Register protected by Lock bit input, overrides supported for scan_mode &amp; debug_unlocked</xhtml:p>
          <xhtml:p style="text-indent: 15px;">begin</xhtml:p>
          <xhtml:p style="text-indent: 30px;">Data_out &lt;= Data_in;</xhtml:p>
          <xhtml:p style="text-indent: 15px;">end</xhtml:p>
          <xhtml:p style="text-indent: 15px;">else if (~write)</xhtml:p>
          <xhtml:p style="text-indent: 15px;">begin</xhtml:p>
          <xhtml:p style="text-indent: 30px;">Data_out &lt;= Data_out;</xhtml:p>
          <xhtml:p style="text-indent: 15px;">end</xhtml:p>
          <xhtml:p/>
          <xhtml:p>endmodule</xhtml:p>
       </Example_Code>
        <Body_Text>If either the scan_mode or the debug_unlocked modes can be triggered by software, then the lock protection may be bypassed.</Body_Text>
        <Example_Code Nature="good">
          Either remove the debug and scan mode overrides or protect enabling of these modes so that only trusted and authorized users may enable these modes.
       </Example_Code>
     </Demonstrative_Example>
    </Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="176"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <Content_History>
      <Submission>
        <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
        <Submission_Organization>Intel Corporation</Submission_Organization>
				<Submission_Date>2020-01-15</Submission_Date>
     </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Common_Consequences, Demonstrative_Examples, Description, Modes_of_Introduction, Potential_Mitigations, Related_Attack_Patterns</Modification_Comment>
				</Modification>
    </Content_History>
  </Weakness>
      <Weakness ID="1239" Name="Improper Zeroization of Hardware Register" Abstraction="Variant" Structure="Simple" Status="Draft">
            <Description>The hardware product does not properly clear sensitive information from built-in registers when the user of the hardware block changes.</Description>
            <Extended_Description>Hardware logic operates on data stored in registers local to the hardware block. Most hardware IPs, including cryptographic accelerators, rely on registers to buffer I/O, store intermediate values, and interface with software. The result of this is that sensitive information, such as passwords or encryption keys, can exist in locations not transparent to the user of the hardware logic. When a different entity obtains access to the IP due to a change in operating mode or conditions, the new entity can extract information belonging to the previous user if no mechanisms are in place to clear register contents. It is important to clear information stored in the hardware if a physical attack on the product is detected, or if the user of the hardware block changes. The process of clearing register contents in a hardware IP is referred to as zeroization in standards for cryptographic hardware modules such as FIPS-140-2 [REF-267].</Extended_Description>
            <Related_Weaknesses>
              <Related_Weakness Nature="ChildOf" CWE_ID="226" View_ID="1000" Ordinal="Primary"/>
              <Related_Weakness Nature="ChildOf" CWE_ID="226" View_ID="1194" Ordinal="Primary"/>
            </Related_Weaknesses>
            <Applicable_Platforms>
                <Language Class="Language-Independent" Prevalence="Undetermined"/>
                <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
                <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
                <Technology Class="System on Chip" Prevalence="Undetermined"/>
            </Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
					<Note>Lack of hardware mechanisms to zeroize or clear registers in the design or specification.</Note>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>Mechanisms to zeroize and clear registers are in the design but implemented incorrectly.</Note>
				</Introduction>
				<Introduction>
					<Phase>Operation</Phase>
					<Note>Hardware-provided zeroization mechanisms are not used appropriately by the IP user (ex. firmware), or data remanence issues are not taken into account.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Impact>Varies by Context</Impact>
					<Note>The consequences will depend on the information disclosed due to the vulnerability.</Note>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Every register potentially containing sensitive information must have a policy specifying how and when information is cleared, in addition to clarifying if it is the responsibility of the hardware logic or IP user to initiate the zeroization procedure at the appropriate time.</Description>
					<Effectiveness_Notes>Unfortunately, data disclosure can occur even after information has been overwritten/zeroized from the digital perspective. Physical characteristics of the memory can reveal the history of previously written data.  For example, if the same value is written repeatedly to a memory location, the corresponding memory cells can become physically altered to a degree that even if the original data is erased it can still be recovered through physical characterization of the memory cells [REF-1055].</Effectiveness_Notes>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>Suppose a hardware IP for implementing an encryption routine works as expected, but it leaves the intermediate results in some registers that can be accessed. Exactly why this access happens is immaterial - it might be unintentional or intentional, where the designer wanted a "quick fix" for something.  </Intro_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="150"/>
            <Related_Attack_Pattern CAPEC_ID="204"/>
            <Related_Attack_Pattern CAPEC_ID="37"/>
            <Related_Attack_Pattern CAPEC_ID="545"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-267"/>
				<Reference External_Reference_ID="REF-1055"/>
			</References>
            <Content_History>
                <Submission>
					<Submission_Name>Nicole Fern</Submission_Name>
					<Submission_Organization>Tortuga Logic</Submission_Organization>
					<Submission_Date>2020-02-08</Submission_Date>
                </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
            </Content_History>
        </Weakness>
      <Weakness ID="1240" Name="Use of a Cryptographic Primitive with a Risky Implementation" Abstraction="Base" Structure="Simple" Status="Draft">
            <Description>To fulfill the need for a cryptographic primitive, the product implements a cryptographic algorithm using a non-standard, unproven, or disallowed/non-compliant cryptographic implementation.</Description>
            <Extended_Description>
	      <xhtml:p>Cryptographic protocols and systems depend on cryptographic primitives (and associated algorithms) as their basic building blocks. Some common examples of primitives are digital signatures, one-way hash functions, ciphers, and public key cryptography; however, the notion of "primitive" can vary depending on point of view. See "Terminology Notes" for further explanation of some concepts.</xhtml:p>
	      <xhtml:p>Cryptographic primitives are defined to accomplish one very specific task in a precisely defined and mathematically reliable fashion. For example, suppose that for a specific cryptographic primitive (such as an encryption routine), the consensus is that the primitive can only be broken after trying out N different inputs (where the larger the value of N, the stronger the cryptography). For an encryption scheme like AES-256, one would expect N to be so large as to be infeasible to execute in a reasonable amount of time.</xhtml:p>
	      <xhtml:p>If a vulnerability is ever found that shows that one can break a cryptographic primitive in significantly less than the expected number of attempts, then that primitive is considered weakened (or sometimes in extreme cases, colloquially it is "broken"). As a result, anything using this cryptographic primitive would now be considered insecure or risky. Thus, even breaking or weakening a seemingly small cryptographic primitive has the potential to render the whole system vulnerable, due to its reliance on the primitive. A historical example can be found in TLS when using DES. One would colloquially call DES the cryptographic primitive for transport encryption in this version of TLS. In the past, DES was considered strong, because no weaknesses were found in it; importantly, DES has a key length of 56 bits. Trying N=2^56 keys was considered impractical for most actors. Unfortunately, attacking a system with 56-bit keys is now practical via brute force, which makes defeating DES encryption practical. It is now practical for an adversary to read any information sent under this version of TLS and use this information to attack the system. As a result, it can be claimed that this use of TLS is weak, and that any system depending on TLS with DES could potentially render the entire system vulnerable to attack.</xhtml:p>

	      <xhtml:p>Cryptographic primitives and associated algorithms are only considered safe after extensive research and review from experienced cryptographers from academia, industry, and government entities looking for any possible flaws. Furthermore, cryptographic primitives and associated algorithms are frequently reevaluated for safety when new mathematical and attack techniques are discovered.  As a result and over time, even well-known cryptographic primitives can lose their compliance status with the discovery of novel attacks that might either defeat the algorithm or reduce its robustness significantly.</xhtml:p>
	      <xhtml:p>If ad-hoc cryptographic primitives are implemented, it is almost certain that the implementation will be vulnerable to attacks that are well understood by cryptographers, resulting in the exposure of sensitive information and other consequences.</xhtml:p>
	      <xhtml:p>This weakness is even more difficult to manage for hardware-implemented deployment of cryptographic algorithms. First, because hardware is not patchable as easily as software, any flaw discovered after release and production typically cannot be fixed without a recall of the product. Secondly, the hardware product is often expected to work for years, during which time computation power available to the attacker only increases. Therefore, for hardware implementations of cryptographic primitives, it is absolutely essential that only strong, proven cryptographic primitives are used.</xhtml:p>
	    </Extended_Description>
            <Related_Weaknesses>
              <Related_Weakness Nature="ChildOf" CWE_ID="327" View_ID="1000" Ordinal="Primary"/>
            </Related_Weaknesses>
		 <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Primary</Ordinality>
            </Weakness_Ordinality>
		 </Weakness_Ordinalities>
            <Applicable_Platforms>
                <Language Class="Language-Independent" Prevalence="Undetermined"/>
                <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
                <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
                <Technology Class="System on Chip" Prevalence="Undetermined"/>
            </Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
					<Note>This weakness is primarily introduced during the architecture and design phase as risky primitives are included.</Note>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>Even in cases where the Architectural phase properly specifies a cryptographically secure design, the design may be changed during implementation due to unforeseen constraints.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Impact>Read Application Data</Impact>
					<Likelihood>High</Likelihood>
					<Note>Incorrect usage of crypto primitives could render the supposedly encrypted data as unencrypted plaintext in the worst case.</Note>
				</Consequence>
			</Common_Consequences>
	    <Detection_Methods>
	      <Detection_Method>
		<Method>Architecture or Design Review</Method>
		<Description>Review requirements, documentation, and product design to ensure that primitives are consistent with the strongest-available recommendations from trusted parties. If the product appears to be using custom or proprietary implementations that have not had sufficient public review and approval, then this is a significant concern.</Description>
		<Effectiveness>High</Effectiveness>
	      </Detection_Method>
	      <Detection_Method>
		<Method>Manual Analysis</Method>
		<Description>Analyze the product to ensure that implementations for each primitive do not contain any known vulnerabilities and are not using any known-weak algorithms, including MD4, MD5, SHA1, DES, etc.</Description>
		<Effectiveness>Moderate</Effectiveness>
	      </Detection_Method>
	      <Detection_Method>
		<Method>Dynamic Analysis with Manual Results Interpretation</Method>
		<Description>For hardware, during the implementation (pre-Silicon / post-Silicon) phase, dynamic tests should be done to ensure that outputs from cryptographic routines are indeed working properly, such as test vectors provided by NIST [REF-1236].</Description>
		<Effectiveness>Moderate</Effectiveness>
	      </Detection_Method>
	      <Detection_Method>
		<Method>Dynamic Analysis with Manual Results Interpretation</Method>
		<Description>
		It needs to be determined if the output of a cryptographic primitive is lacking entropy, which is one clear sign that something went wrong with the crypto implementation. There exist many methods of measuring the entropy of a bytestream, from sophisticated ones (like calculating Shannon's entropy of a sequence of characters) to crude ones (by compressing it and comparing the size of the original bytestream vs. the compressed - a truly random byte stream should not be compressible and hence the uncompressed and compressed bytestreams should be nearly identical in size).</Description>
		<Effectiveness>Moderate</Effectiveness>
	      </Detection_Method>
	    </Detection_Methods>
	    <Potential_Mitigations>
		<Mitigation Mitigation_ID="MIT-55">
		  <Phase>Requirements</Phase>
		  <Description>
		      Require compliance with the strongest-available recommendations from trusted parties, and require that compliance must be kept up-to-date, since recommendations evolve over time. For example, US government systems require FIPS 140-3 certification, which supersedes FIPS 140-2 [REF-1192] [REF-1226].
		  </Description>
		  <Effectiveness>High</Effectiveness>
		</Mitigation>
		<Mitigation>
		  <Phase>Architecture and Design</Phase>
		  <Description>
		      Ensure that the architecture/design uses the strongest-available primitives and algorithms from trusted parties. For example, US government systems require FIPS 140-3 certification, which supersedes FIPS 140-2 [REF-1192] [REF-1226].
		  </Description>
		  <Effectiveness>High</Effectiveness>
		</Mitigation>
		<Mitigation Mitigation_ID="MIT-54">
		  <Phase>Architecture and Design</Phase>
		  <Description>
		      Do not develop custom or private cryptographic algorithms. They will likely be exposed to attacks that are well-understood by cryptographers. As with all cryptographic mechanisms, the source code should be available for analysis. If the algorithm may be compromised when attackers find out how it works, then it is especially weak.
		  </Description>
		  <Effectiveness>Discouraged Common Practice</Effectiveness>
		</Mitigation>
		<Mitigation>
		  <Phase>Architecture and Design</Phase>
		  <Description>
		      Try not to use cryptographic algorithms in novel ways or with new modes of operation even when you "know" it is secure. For example, using SHA-2 chaining to create a 1-time pad for encryption might sound like a good idea, but one should not do this.
		  </Description>
		  <Effectiveness>Discouraged Common Practice</Effectiveness>
		</Mitigation>
        <Mitigation Mitigation_ID="MIT-52">
          <Phase>Architecture and Design</Phase>
          <Description>Ensure that the design can replace one cryptographic primitive or algorithm with another in the next generation ("cryptographic agility"). Where possible, use wrappers to make the interfaces uniform. This will make it easier to upgrade to stronger algorithms. This is especially important for hardware, which can be more difficult to upgrade quickly than software; design the hardware at a replaceable block level.</Description>
		  <Effectiveness>Defense in Depth</Effectiveness>
        </Mitigation>
		<Mitigation>
		  <Phase>Architecture and Design</Phase>
		  <Description>
		      Do not use outdated or non-compliant cryptography algorithms. Some older algorithms, once thought to require a billion years of computing time, can now be broken in days or hours. This includes MD4, MD5, SHA1, DES, and other algorithms that were once regarded as strong [REF-267].
		  </Description>
		  <Effectiveness>Discouraged Common Practice</Effectiveness>
		</Mitigation>
		<Mitigation>
		  <Phase>Architecture and Design</Phase>
		  <Phase>Implementation</Phase>
		  <Description>
		      Do not use a linear-feedback shift register (LFSR) or other legacy methods as a substitute for an accepted and standard Random Number Generator.
		  </Description>
		  <Effectiveness>Discouraged Common Practice</Effectiveness>
		</Mitigation>
		<Mitigation>
		  <Phase>Architecture and Design</Phase>
		  <Phase>Implementation</Phase>
		  <Description>
		      Do not use a checksum as a substitute for a cryptographically generated hash.
		  </Description>
		  <Effectiveness>Discouraged Common Practice</Effectiveness>
		</Mitigation>
		<Mitigation>
		  <Phase>Architecture and Design</Phase>
		  <Strategy>Libraries or Frameworks</Strategy>
		  <Description>
		      Use a vetted cryptographic library or framework. Industry-standard implementations will save development time and are more likely to avoid errors that can occur during implementation of cryptographic algorithms. However, the library/framework could be used incorrectly during implementation.
		  </Description>
		  <Effectiveness>High</Effectiveness>
		</Mitigation>
		<Mitigation>
		  <Phase>Architecture and Design</Phase>
		  <Phase>Implementation</Phase>
		  <Description>
		      When using industry-approved techniques, use them correctly. Don't cut corners by skipping resource-intensive steps (CWE-325). These steps are often essential for the prevention of common attacks.
		  </Description>
		  <Effectiveness>Moderate</Effectiveness>
		</Mitigation>
		<Mitigation>
		  <Phase>Architecture and Design</Phase>
		  <Phase>Implementation</Phase>
		  <Description>
		      Do not store keys in areas accessible to untrusted agents. Carefully manage and protect the cryptographic keys (see CWE-320). If the keys can be guessed or stolen, then the strength of the cryptography algorithm is irrelevant.
		  </Description>
		  <Effectiveness>Moderate</Effectiveness>
		</Mitigation>
	      </Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>Re-using random values may compromise security.</Intro_Text>
					<Example_Code Nature="bad">Suppose an Encryption algorithm needs a random value for a key. Instead of using a DRNG (Deterministic Random Number Generator), the designer uses a linear-feedback shift register (LFSR) to generate the value.</Example_Code>
					<Body_Text>While an LFSR may provide pseudo-random number generation service, the entropy (measure of randomness) of the resulting output may be less than that of an accepted DRNG (like that used in dev/urandom). Thus, using an LFSR weakens the strength of the cryptographic system, because it may be possible for an attacker to guess the LFSR output and subsequently the encryption key.</Body_Text>
					<Example_Code Nature="good">If a cryptographic algorithm expects a random number as its input, provide one. Do not provide a pseudo-random value.</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
      <Observed_Examples>
      	<Observed_Example>
          <Reference>CVE-2020-4778</Reference>
          <Description>software uses MD5, which is less safe than the default SHA-256 used by related products</Description>
          <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-4778</Link>
      	</Observed_Example>
            <Observed_Example>
               <Reference>CVE-2005-2946</Reference>
               <Description>Default configuration of product uses MD5 instead of stronger algorithms that are available, simplifying forgery of certificates.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2005-2946</Link>
            </Observed_Example>
		<Observed_Example>
		  <Reference>CVE-2019-3907</Reference>
		  <Description>identity card uses MD5 hash of a salt and password</Description>
		  <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-3907</Link>
		</Observed_Example>
		<Observed_Example>
		  <Reference>CVE-2021-34687</Reference>
		  <Description>personal key is transmitted over the network using a substitution cipher</Description>
		  <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-34687</Link>
		</Observed_Example>
		<Observed_Example>
		  <Reference>CVE-2020-14254</Reference>
		  <Description>product does not disable TLS-RSA cipher suites, allowing decryption of traffic if TLS 2.0 and secure ciphers are not enabled.</Description>
		  <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-14254</Link>
		</Observed_Example>
		<Observed_Example>
		  <Reference>CVE-2019-1543</Reference>
		  <Description>SSL/TLS library generates 16-byte nonces but reduces them to 12 byte nonces for the ChaCha20-Poly1305 cipher, converting them in a way that violates the cipher's requirements for unique nonces.</Description>
		  <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-1543</Link>
		</Observed_Example>
		<Observed_Example>
		  <Reference>CVE-2017-9267</Reference>
		  <Description>LDAP interface allows use of weak ciphers</Description>
		  <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-9267</Link>
		</Observed_Example>
		<Observed_Example>
		  <Reference>CVE-2017-7971</Reference>
		  <Description>SCADA product allows "use of outdated cipher suites"</Description>
		  <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-7971</Link>
		</Observed_Example>
		<Observed_Example>
		  <Reference>CVE-2020-6616</Reference>
		  <Description>Chip implementing Bluetooth uses a low-entropy PRNG instead of a hardware RNG, allowing spoofing.</Description>
		  <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-6616</Link>
		</Observed_Example>
		<Observed_Example>
		  <Reference>CVE-2019-1715</Reference>
		  <Description>security product has insufficient entropy in the DRBG, allowing collisions and private key discovery</Description>
		  <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-1715</Link>
		</Observed_Example>
		<Observed_Example>
		  <Reference>CVE-2014-4192</Reference>
		  <Description>Dual_EC_DRBG implementation in RSA toolkit does not correctly handle certain byte requests, simplifying plaintext recovery</Description>
		  <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-4192</Link>
		</Observed_Example>
		<Observed_Example>
		  <Reference>CVE-2007-6755</Reference>
		  <Description>Recommendation for Dual_EC_DRBG algorithm contains point Q constants that could simplify decryption</Description>
		  <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2007-6755</Link>
		</Observed_Example>
      </Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="97"/>
         </Related_Attack_Patterns>
         <References>
	   <Reference External_Reference_ID="REF-267"/>
	   <Reference External_Reference_ID="REF-1227"/>
	   <Reference External_Reference_ID="REF-1226"/>
	   <Reference External_Reference_ID="REF-1192"/>
	   <Reference External_Reference_ID="REF-1236" Section="Test Vectors"/>
         </References>
         <Notes>
	   <Note Type="Terminology">
	     <xhtml:p>
	     Terminology for cryptography varies widely, from informal and colloquial to mathematically-defined, with different precision and formalism depending on whether the stakeholder is a developer, cryptologist, etc. Yet there is a need for CWE to be self-consistent while remaining understandable and acceptable to multiple audiences.</xhtml:p>
	     <xhtml:p>As of CWE 4.6, CWE terminology around "primitives" and "algorithms" is emerging as shown by the following example, subject to future consultation and agreement within the CWE and cryptography communities. Suppose one wishes to send encrypted data using a CLI tool such as OpenSSL. One might choose to use AES with a 256-bit key and require tamper protection (GCM mode, for instance). For compatibility's sake, one might also choose the ciphertext to be formatted to the PKCS#5 standard. In this case, the "cryptographic system" would be AES-256-GCM with PKCS#5 formatting. The "cryptographic function" would be AES-256 in the GCM mode of operation, and the "algorithm" would be AES. Colloquially, one would say that AES (and sometimes AES-256) is the "cryptographic primitive," because it is the algorithm that realizes the concept of symmetric encryption (without modes of operation or other protocol related modifications). In practice, developers and architects typically refer to base cryptographic algorithms (AES, SHA, etc.) as cryptographic primitives.</xhtml:p>
	   </Note>
           <Note Type="Maintenance">Since CWE 4.4, various cryptography-related entries, including CWE-327 and CWE-1240, have been slated for extensive research, analysis, and community consultation to define consistent terminology, improve relationships, and reduce overlap or duplication. As of CWE 4.6, this work is still ongoing.</Note>
         </Notes>
			<Content_History>
                <Submission>
                    <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
                    <Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-02-10</Submission_Date>
                </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Background_Details, Common_Consequences, Demonstrative_Examples, Description, Maintenance_Notes, Modes_of_Introduction, Potential_Mitigations, Related_Attack_Patterns, Research_Gaps</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Maintenance_Notes, Research_Gaps</Modification_Comment>
				</Modification>
				<Contribution Type="Content">
				  <Contribution_Name>Parbati K. Manna</Contribution_Name>
				  <Contribution_Organization>Intel Corporation</Contribution_Organization>
				  <Contribution_Date>2021-10-18</Contribution_Date>
				  <Contribution_Comment>provided detection methods and observed examples</Contribution_Comment>
				</Contribution>
            </Content_History>
        </Weakness>
      <Weakness ID="1241" Name="Use of Predictable Algorithm in Random Number Generator" Abstraction="Base" Structure="Simple" Status="Draft">
            <Description>The device uses an algorithm that is predictable and generates a pseudo-random number.</Description>
            <Related_Weaknesses>
              <Related_Weakness Nature="ChildOf" CWE_ID="330" View_ID="1000" Ordinal="Primary"/>
            </Related_Weaknesses>
            <Applicable_Platforms>
                <Technology Class="System on Chip" Prevalence="Undetermined"/>
            </Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>In many cases, the design originally defines a cryptographically secure random number generator, but is then changed during implementation due to unforeseen constraints.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Impact>Read Application Data</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>A true random number generator should be specified for cryptographic algorithms.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>A true random number generator should be implemented for cryptographic algorithms.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>Suppose a cryptographic function expects random value to be supplied for the crypto algorithm.</Intro_Text>
					<Body_Text>During the implementation phase, due to space constraint, a cryptographically secure random-number-generator could not be used, and instead  of using a TRNG (True Random Number Generator), a LFSR (Linear Feedback Shift Register) is used to generate a random value. While an LFSR will provide a pseudo-random number, its entropy (measure of randomness) is insufficient for a cryptographic algorithm.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="97"/>
         </Related_Attack_Patterns>
         <Notes>
	   <Note Type="Maintenance">As of CWE 4.5, terminology related to randomness, entropy, and
	   predictability can vary widely. Within the developer and other
	   communities, "randomness" is used heavily. However, within
	   cryptography, "entropy" is distinct, typically implied as a
	   measurement. There are no commonly-used definitions, even within
	   standards documents and cryptography papers. Future versions of
	   CWE will attempt to define these terms and, if necessary,
	   distinguish between them in ways that are appropriate for
	   different communities but do not reduce the usability of CWE for
	   mapping, understanding, or other scenarios.</Note>
	 </Notes>
         <Content_History>
                <Submission>
                    <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
                    <Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-02-10</Submission_Date>
                </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-06-25</Modification_Date>
					<Modification_Comment>updated Common_Consequences, Demonstrative_Examples, Modes_of_Introduction</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Common_Consequences, Demonstrative_Examples, Description, Maintenance_Notes, Modes_of_Introduction, Potential_Mitigations, Related_Attack_Patterns, Research_Gaps</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Maintenance_Notes, Research_Gaps</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Maintenance_Notes</Modification_Comment>
				</Modification>
            </Content_History>
        </Weakness>
      <Weakness ID="1242" Name="Inclusion of Undocumented Features or Chicken Bits" Abstraction="Base" Structure="Simple" Status="Incomplete">
            <Description>The device includes chicken bits or undocumented features that can create entry points for unauthorized actors.</Description>
            <Extended_Description>
                <xhtml:p>A common design practice is to use undocumented bits on a device that can be used to disable certain functional security features. These bits are commonly referred to as "chicken bits". They can facilitate quick identification and isolation of faulty components, features that negatively affect performance, or features that do not provide the required controllability for debug and test. Another way to achieve this is through implementation of undocumented features. An attacker might exploit these interfaces for unauthorized access.</xhtml:p>
            </Extended_Description>
			<Related_Weaknesses>
              <Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
            <Applicable_Platforms>
                <Language Class="Language-Independent" Prevalence="Undetermined"/>
                <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
                <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
                <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
            </Applicable_Platforms>
            <Modes_Of_Introduction>
                <Introduction>
                    <Phase>Architecture and Design</Phase>
                </Introduction>
                <Introduction>
                    <Phase>Implementation</Phase>
                </Introduction>
                <Introduction>
                    <Phase>Documentation</Phase>
                </Introduction>
            </Modes_Of_Introduction>
            <Common_Consequences>
                <Consequence>
                    <Scope>Confidentiality</Scope>
                    <Scope>Integrity</Scope>
                    <Scope>Availability</Scope>
                    <Scope>Access Control</Scope>
                    <Impact>Modify Memory</Impact>
                    <Impact>Read Memory</Impact>
                    <Impact>Execute Unauthorized Code or Commands</Impact>
                    <Impact>Gain Privileges or Assume Identity</Impact>
                    <Impact>Bypass Protection Mechanism</Impact>
                </Consequence>
            </Common_Consequences>
            <Potential_Mitigations>
                <Mitigation>
                    <Phase>Architecture and Design</Phase>
                    <Phase>Implementation</Phase>
                    <Description>
                        <xhtml:p>The implementation of chicken bits in a released product is highly discouraged. If implemented at all, ensure that they are disabled in production devices. All interfaces to a device should be documented.</xhtml:p>                     
                    </Description>
                    <Effectiveness>High</Effectiveness>
                </Mitigation>
            </Potential_Mitigations>
            <Demonstrative_Examples>
                <Demonstrative_Example>
                    <Intro_Text>Consider a device that comes with various security measures, such as secure boot. The secure-boot process performs firmware-integrity verification at boot time, and this code is stored in a separate SPI-flash device. However, this code contains undocumented "special access features" intended to be used only for performing failure analysis and intended to only be unlocked by the device designer.</Intro_Text>
                    <Example_Code Nature="bad" Language="Other">
                        <xhtml:div>Attackers dump the code from the device and then perform reverse engineering to analyze the code. The undocumented, special-access features are identified, and attackers can activate them by sending specific commands via UART before secure-boot phase completes. Using these hidden features, attackers can perform reads and writes to memory via the UART interface. At runtime, the attackers can also execute arbitrary code and dump the entire memory contents.</xhtml:div>
                    </Example_Code>
                    <Body_Text>Remove all chicken bits and hidden features that are exposed to attackers. Add authorization schemes that rely on cryptographic primitives to access any features that the manufacturer does not want to expose. Clearly document all interfaces.</Body_Text>
            	</Demonstrative_Example>
            </Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="212"/>
            <Related_Attack_Pattern CAPEC_ID="36"/>
         </Related_Attack_Patterns>
         <References>
                <Reference External_Reference_ID="REF-1071"/>
                <Reference External_Reference_ID="REF-1072"/>
                <Reference External_Reference_ID="REF-1073"/>
                <Reference External_Reference_ID="REF-1074"/>
                <Reference External_Reference_ID="REF-1075"/>
            </References>
            <Content_History>
                <Submission>
                    <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
                    <Submission_Organization>Intel Corporation</Submission_Organization>
                    <Submission_Date>2020-02-13</Submission_Date>
                </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Applicable_Platforms, Demonstrative_Examples, Description, Potential_Mitigations, Related_Attack_Patterns</Modification_Comment>
				</Modification>
            </Content_History>
        </Weakness>
      <Weakness ID="1243" Name="Sensitive Non-Volatile Information Not Protected During Debug" Abstraction="Base" Structure="Simple" Status="Incomplete">
            <Description>Access to security-sensitive information stored in fuses is not limited during debug.</Description>
            <Extended_Description>
                <xhtml:p>Several security-sensitive values are programmed into fuses to be used during early-boot flows or later at runtime. Examples of these security-sensitive values include root keys, encryption keys, manufacturing-specific information, chip-manufacturer-specific information, and original-equipment-manufacturer (OEM) data. After the chip is powered on, these values are sensed from fuses and stored in temporary locations such as registers and local memories. These locations are typically access-control protected from untrusted agents capable of accessing them. Even to trusted agents, only read-access is provided. However, these locations are not blocked during debug operations, allowing a user to access this sensitive information.</xhtml:p>
            </Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="1263" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
            <Applicable_Platforms>
                <Language Class="Language-Independent" Prevalence="Undetermined"/>
                <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
                <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
                <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
            </Applicable_Platforms>
            <Modes_Of_Introduction>
                <Introduction>
                    <Phase>Architecture and Design</Phase>
                </Introduction>
                <Introduction>
                    <Phase>Implementation</Phase>
                </Introduction>
            </Modes_Of_Introduction>
            <Common_Consequences>
                <Consequence>
                    <Scope>Confidentiality</Scope>
                    <Scope>Access Control</Scope>
                    <Impact>Modify Memory</Impact>
                    <Impact>Bypass Protection Mechanism</Impact>
                </Consequence>
            </Common_Consequences>
            <Potential_Mitigations>
                <Mitigation>
                    <Phase>Architecture and Design</Phase>
                    <Phase>Implementation</Phase>
                    <Description>
                        <xhtml:p>Disable access to security-sensitive information stored in fuses directly and also reflected from  temporary storage locations when in debug mode.</xhtml:p>                     
                    </Description>
                </Mitigation>
            </Potential_Mitigations>
            <Demonstrative_Examples>
                <Demonstrative_Example>
                    <Intro_Text>Sensitive manufacturing data (such as die information) are stored in fuses. When the chip powers on, these values are read from the fuses and stored in microarchitectural registers. These registers are only given read access to trusted software running on the core. Untrusted software running on the core is not allowed to access these registers.</Intro_Text>
                    <Example_Code Nature="bad" Language="Other">
                        <xhtml:div>All microarchitectural registers in this chip can be accessed through the debug interface. As a result, even an untrusted debugger can access this data and retrieve sensitive manufacturing data.</xhtml:div>
                    </Example_Code>
                	<Example_Code Nature="informative">
                  		<xhtml:div>Registers used to store sensitive values read from fuses should be blocked during debug. These registers should be disconnected from the debug interface.</xhtml:div>
               		</Example_Code>
            	</Demonstrative_Example>
            </Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="116"/>
            <Related_Attack_Pattern CAPEC_ID="545"/>
         </Related_Attack_Patterns>
         <Content_History>
                <Submission>
                    <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
                    <Submission_Organization>Intel Corporation</Submission_Organization>
                    <Submission_Date>2020-02-12</Submission_Date>
                </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-06-25</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Applicable_Platforms, Demonstrative_Examples, Description, Name, Potential_Mitigations, Related_Attack_Patterns</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Description</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
			<Previous_Entry_Name Date="2020-08-20">Exposure of Security-Sensitive Fuse Values During Debug</Previous_Entry_Name>
            </Content_History>
        </Weakness>
      <Weakness ID="1244" Name="Internal Asset Exposed to Unsafe Debug Access Level or State" Abstraction="Base" Structure="Simple" Status="Stable">

        <Description>The product uses physical debug or test
        interfaces with support for multiple access levels, but it
        assigns the wrong debug access level to an internal asset,
        providing unintended access to the asset from untrusted debug
        agents.</Description>

        <Extended_Description>
	  <xhtml:p>Debug authorization can have multiple levels of
	  access, defined such that different system internal assets
	  are accessible based on the current authorized debug
	  level. Other than debugger authentication (e.g., using
	  passwords or challenges), the authorization can also be
	  based on the system state or boot stage. For example, full
	  system debug access might only be allowed early in boot
	  after a system reset to ensure that previous session data is
	  not accessible to the authenticated debugger.</xhtml:p>

          <xhtml:p>If this protection mechanism does not ensure that
          internal assets have the correct debug access level during
          each boot stage or change in system state, an attacker could
          obtain sensitive information from the internal asset using a
          debugger.</xhtml:p>
        </Extended_Description>
	<Related_Weaknesses>
	  <Related_Weakness Nature="ChildOf" CWE_ID="863" View_ID="1000" Ordinal="Primary"/>
	</Related_Weaknesses>
		 <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Primary</Ordinality>
            </Weakness_Ordinality>
		 </Weakness_Ordinalities>
            <Applicable_Platforms>
                <Language Class="Language-Independent" Prevalence="Undetermined"/>
                <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
                <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
                <Technology Class="System on Chip" Prevalence="Undetermined"/>
            </Applicable_Platforms>
            <Modes_Of_Introduction>
                <Introduction>
                    <Phase>Architecture and Design</Phase>
                </Introduction>
                <Introduction>
                    <Phase>Implementation</Phase>
                </Introduction>
            </Modes_Of_Introduction>
            <Common_Consequences>
                <Consequence>
                    <Scope>Confidentiality</Scope>
                    <Impact>Read Memory</Impact>
                </Consequence>
                <Consequence>
                    <Scope>Integrity</Scope>
                    <Impact>Modify Memory</Impact>
                </Consequence>
                <Consequence>
                    <Scope>Authorization</Scope>
                    <Scope>Access Control</Scope>
                    <Impact>Gain Privileges or Assume Identity</Impact>
                    <Impact>Bypass Protection Mechanism</Impact>
                </Consequence>
            </Common_Consequences>
	    <Detection_Methods>
	      <Detection_Method>
		<Method>Manual Analysis</Method>
		<Description>Check 2 devices for their passcode to authenticate access to JTAG/debugging ports. If the passcodes are missing or the same, update the design to fix and retest. Check communications over JTAG/debugging ports for encryption. If the communications are not encrypted, fix the design and retest.</Description>
		<Effectiveness>Moderate</Effectiveness>
	      </Detection_Method>
	    </Detection_Methods>
            <Potential_Mitigations>
                <Mitigation>
                  <Phase>Architecture and Design</Phase>
                  <Phase>Implementation</Phase>
                  <Description>
                    <xhtml:p>For security-sensitive assets accessible over debug/test interfaces, only allow trusted agents.</xhtml:p>
                  </Description>
		  <Effectiveness>High</Effectiveness>
		</Mitigation>
		<Mitigation>
		  <Phase>Architecture and Design</Phase>
		  <Description>Apply blinding [REF-1219] or masking techniques in strategic areas.</Description>
		  <Effectiveness>Limited</Effectiveness>
		</Mitigation>
		<Mitigation>
		  <Phase>Implementation</Phase>
		  <Description>Add shielding or tamper-resistant protections to the device, which increases the difficulty and cost for accessing debug/test interfaces.</Description>
		  <Effectiveness>Limited</Effectiveness>
                </Mitigation>
            </Potential_Mitigations>
            <Demonstrative_Examples>
                <Demonstrative_Example>
                    <Intro_Text>The JTAG interface is used to perform debugging and provide CPU core access for developers. JTAG-access protection is implemented as part of the JTAG_SHIELD bit in the hw_digctl_ctrl register. This register has no default value at power up and is set only after the system boots from ROM and control is transferred to the user software.</Intro_Text>
                    <Example_Code Nature="bad" Language="Other">
                        <xhtml:table>
                            <xhtml:tbody>
                                <xhtml:tr>
                                    <xhtml:td>1 bit</xhtml:td>
                                    <xhtml:td>0x0 = JTAG debugger is enabled (default)</xhtml:td>
                                </xhtml:tr>
                                <xhtml:tr>
                                    <xhtml:td>JTAG_SHIELD</xhtml:td>
                                    <xhtml:td>0x1 = JTAG debugger is disabled</xhtml:td>
                                </xhtml:tr>
                            </xhtml:tbody>
                        </xhtml:table>
                    </Example_Code>
                    <Body_Text>This means that since the end user has access to JTAG at system reset and during ROM code execution before control is transferred to user software, a JTAG user can modify the boot flow and subsequently disclose all CPU information, including data-encryption keys.</Body_Text>
                	<Example_Code Nature="informative">
                  		<xhtml:div>The default value of this register bit should be set to 1 to prevent the JTAG from being enabled at system reset.</xhtml:div>
               		</Example_Code> 
            	</Demonstrative_Example>
            </Demonstrative_Examples>
            <Observed_Examples>
            	<Observed_Example>
               		<Reference>CVE-2019-18827</Reference>
               		<Description>After ROM code execution, JTAG access is disabled. But before the ROM code is executed, JTAG access is possible, allowing a user full system access.  This allows a user to modify the boot flow and successfully bypass the secure-boot process.</Description>
               		<Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-18827</Link>
           		 </Observed_Example>
           	</Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="114"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <References>
                <Reference External_Reference_ID="REF-1056"/>
                <Reference External_Reference_ID="REF-1057"/>
                <Reference External_Reference_ID="REF-1219"/>
            </References>
      <Notes>
	<Note Type="Relationship">
	  CWE-1191 and CWE-1244 both involve physical debug access,
	  but the weaknesses are different. CWE-1191 is effectively
	  about missing authorization for a debug interface,
	  i.e. JTAG.  CWE-1244 is about providing internal assets with
	  the wrong debug access level, exposing the asset to
	  untrusted debug agents.</Note>
      </Notes>
            <Content_History>
                <Submission>
                    <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
                    <Submission_Organization>Intel Corporation</Submission_Organization>
                    <Submission_Date>2020-02-12</Submission_Date>
                </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Name, Observed_Examples, Related_Attack_Patterns</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Maintenance_Notes</Modification_Comment>
				</Modification>
	    <Contribution Type="Content">
	      <Contribution_Name>Hareesh Khattri</Contribution_Name>
	      <Contribution_Organization>Intel Corporation</Contribution_Organization>
	      <Contribution_Date>2021-10-22</Contribution_Date>
	      <Contribution_Comment>clarified differences between CWE-1191 and CWE-1244, and suggested rephrasing of descriptions and names.</Contribution_Comment>
	    </Contribution>
			<Previous_Entry_Name Date="2020-08-20">Improper Authorization on Physical Debug and Test Interfaces</Previous_Entry_Name>
            </Content_History>
        </Weakness>
      <Weakness ID="1245" Name="Improper Finite State Machines (FSMs) in Hardware Logic" Abstraction="Base" Structure="Simple" Status="Incomplete">
            <Description>Faulty finite state machines (FSMs) in the hardware logic allow an attacker to put the system in an undefined state, to cause a denial of service (DoS) or gain privileges on the victim's system.</Description>
            <Extended_Description>
                <xhtml:p>The functionality and security of the system heavily depend on the implementation of FSMs. FSMs can be used to indicate the current security state of the system. Lots of secure data operations and data transfers rely on the state reported by the FSM. Faulty FSM designs that do not account for all states, either through undefined states (left as don't cares) or through incorrect implementation, might lead an attacker to drive the system into an unstable state from which the system cannot recover without a reset, thus causing a DoS. Depending on what the FSM is used for, an attacker might also gain additional privileges to launch further attacks and compromise the security guarantees.</xhtml:p>
            </Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="684" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
            <Applicable_Platforms>
                <Language Class="Language-Independent" Prevalence="Undetermined"/>
                <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
                <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
                <Technology Class="System on Chip" Prevalence="Undetermined"/>
            </Applicable_Platforms>
            <Modes_Of_Introduction>
                <Introduction>
                    <Phase>Architecture and Design</Phase>
                </Introduction>
                <Introduction>
                    <Phase>Implementation</Phase>
                </Introduction>
            </Modes_Of_Introduction>
            <Common_Consequences>
                <Consequence>
                    <Scope>Availability</Scope>
                    <Scope>Access Control</Scope>
                    <Impact>Unexpected State</Impact>
                    <Impact>DoS: Crash, Exit, or Restart</Impact>
                    <Impact>DoS: Instability</Impact>
                    <Impact>Gain Privileges or Assume Identity</Impact>
                </Consequence>
            </Common_Consequences>
            <Potential_Mitigations>
                <Mitigation>
                    <Phase>Architecture and Design</Phase>
                    <Phase>Implementation</Phase>
                    <Description>Define all possible states and handle all unused states through default statements. Ensure that system defaults to a secure state.</Description>
                    <Effectiveness>High</Effectiveness>
                </Mitigation>
            </Potential_Mitigations>
            <Demonstrative_Examples>
                <Demonstrative_Example>
                    <Intro_Text>The FSM shown in the "bad" code snippet below assigns the output out based on the value of state, which is determined based on the user provided input, user_input.</Intro_Text>
                    <Example_Code Nature="bad" Language="Verilog">
                        <xhtml:div>module fsm_1(out, user_input, clk, rst_n);
                            <xhtml:br/>input [2:0] user_input; 
                            <xhtml:br/>input clk, rst_n;
                            <xhtml:br/>output reg [2:0] out;
                            <xhtml:br/>reg [1:0] state;
                            <xhtml:br/>always @ (posedge clk or negedge rst_n )
                            <xhtml:br/>
                            <xhtml:div style="margin-left:10px;">begin
                                <xhtml:br/>
                                <xhtml:div style="margin-left:10px;">if (!rst_n)
                                    <xhtml:br/>state = 3'h0;
                                    <xhtml:br/>else
                                    <xhtml:br/>case (user_input)
                                    <xhtml:div style="margin-left:10px;">
                                        <xhtml:br/>3'h0:
                                        <xhtml:br/>3'h1:
                                        <xhtml:br/>3'h2:
                                        <xhtml:br/>3'h3: state = 2'h3;
                                        <xhtml:br/>3'h4: state = 2'h2;
                                        <xhtml:br/>3'h5: state = 2'h1;
                                    </xhtml:div>
                                    <xhtml:br/>endcase
                                </xhtml:div>
                                <xhtml:br/>end
                                <xhtml:br/>out &lt;= {1'h1, state};
                            </xhtml:div>
                            <xhtml:br/>endmodule
                        </xhtml:div>
                    </Example_Code>
                    <Body_Text>
                        <xhtml:p>The case statement does not handle the scenario when user provides inputs of 3'h6 and 3'h7 using a default statement.  Those inputs push the system to an undefined state and might cause a crash (denial of service) or any other unanticipated outcome.</xhtml:p>
                        <xhtml:p>Adding a default statement to handle undefined inputs mitigates this issue.  This is shown in the "Good" code snippet below.  The default statement is in bold.</xhtml:p>
                    </Body_Text>
                    <Example_Code Nature="good" Language="Other">
                        <xhtml:div>case (user_input)
                            <xhtml:br/><xhtml:div style="margin-left:10px;">3'h0:
                                <xhtml:br/>3'h1:
                                <xhtml:br/>3'h2:
                                <xhtml:br/>3'h3: state = 2'h3;
                                <xhtml:br/>3'h4: state = 2'h2;
                                <xhtml:br/>3'h5: state = 2'h1;
                                <xhtml:br/><xhtml:b>default: state = 2'h0;</xhtml:b>
                            </xhtml:div>
                            <xhtml:br/>endcase</xhtml:div>
                    </Example_Code>
            	</Demonstrative_Example>
            </Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="74"/>
         </Related_Attack_Patterns>
         <References>
                <Reference External_Reference_ID="REF-1060"/>
            </References>
            <Content_History>
                <Submission>
                    <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
                    <Submission_Organization>The Intel Corporation</Submission_Organization>
                    <Submission_Date>2020-02-12</Submission_Date>
                </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
            </Content_History>
        </Weakness>
      <Weakness ID="1246" Name="Improper Write Handling in Limited-write Non-Volatile Memories" Abstraction="Base" Structure="Simple" Status="Incomplete">
            <Description>The product does not implement or incorrectly implements wear leveling operations in limited-write non-volatile memories.</Description>
            <Extended_Description>
                <xhtml:p>Non-volatile memories such as NAND Flash, EEPROM, etc. have individually erasable segments, each of which can be put through a limited number of program/erase or write cycles. For example, the device can only endure a limited number of writes, after which the device becomes unreliable. In order to wear out the cells in a uniform manner, non-volatile memory and storage products based on the above-mentioned technologies implement a technique called wear leveling. Once a set threshold is reached, wear leveling maps writes of a logical block to a different physical block. This prevents a single physical block from prematurely failing due to a high concentration of writes. If wear leveling is improperly implemented, attackers may be able to programmatically cause the storage to become unreliable within a much shorter time than would normally be expected.</xhtml:p>
            </Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="664" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
            <Applicable_Platforms>
                <Language Class="Language-Independent" Prevalence="Undetermined"/>
                <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
                <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
                <Technology Class="System on Chip" Prevalence="Undetermined"/>
								<Technology Name="Memory IP" Prevalence="Undetermined"/>
								<Technology Name="Storage IP" Prevalence="Undetermined"/>
            </Applicable_Platforms>
            <Modes_Of_Introduction>
                <Introduction>
                    <Phase>Architecture and Design</Phase>
                </Introduction>
                <Introduction>
                    <Phase>Implementation</Phase>
                </Introduction>
            </Modes_Of_Introduction>
            <Common_Consequences>
                <Consequence>
                    <Scope>Availability</Scope>
                    <Impact>DoS: Instability</Impact>
                </Consequence>
            </Common_Consequences>
            <Potential_Mitigations>
                <Mitigation>
                    <Phase>Architecture and Design</Phase>
                    <Phase>Implementation</Phase>
					<Phase>Testing</Phase>
                    <Description>
                        Include secure wear leveling algorithms and ensure they may not be bypassed.                     
                    </Description>
					<Effectiveness>High</Effectiveness>
                </Mitigation>
            </Potential_Mitigations>
            <Demonstrative_Examples>
                <Demonstrative_Example>
                    <Intro_Text>An attacker can render a memory line unusable by repeatedly causing a write to the memory line.</Intro_Text>
                    <Body_Text>Below is example code from [REF-1058] that the user can execute repeatedly to cause line failure. W is the maximum associativity of any cache in the system; S is the size of the largest cache in the system.</Body_Text>
                    <Example_Code Nature="bad" Language="Other">
					<xhtml:div>Do aligned alloc of (W+1) arrays each of size S
					<xhtml:br/>
					<xhtml:div>while(1) {
					<xhtml:br/>
						<xhtml:div>for (ii = 0; i &lt; W + 1; ii++)
						<xhtml:div style="margin-left:10px;">
						  array[ii].element[0]++;
						  <xhtml:br/>
						</xhtml:div>
						</xhtml:div>
					</xhtml:div>
					}
					</xhtml:div>					
               </Example_Code>
                    <Body_Text>Without wear leveling, the above attack will be successful. Simple randomization of blocks will not suffice as instead of the original physical block, the randomized physical block will be worn out.</Body_Text>
                	<Example_Code Nature="informative">
                  		<xhtml:div>Wear leveling must be used to even out writes to the device.</xhtml:div>
               		</Example_Code>
            	</Demonstrative_Example>
            </Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="212"/>
         </Related_Attack_Patterns>
         <References>
                <Reference External_Reference_ID="REF-1058"/>
                <Reference External_Reference_ID="REF-1059"/>
            </References>
						<Notes>
						<Note Type="Research Gap">The Technology-Class should be Memory.
						</Note></Notes>
            <Content_History>
                <Submission>
                    <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
                    <Submission_Organization>Intel Corporation</Submission_Organization>
                    <Submission_Date>2020-02-10</Submission_Date>
                </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Description, Potential_Mitigations, Research_Gaps</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
            </Content_History>
        </Weakness>
      <Weakness ID="1247" Name="Improper Protection Against Voltage and Clock Glitches" Abstraction="Base" Structure="Simple" Status="Stable">
      <Description>The device does not contain or contains incorrectly implemented circuitry or sensors to detect and mitigate voltage and clock glitches and protect sensitive information or software contained on the device.</Description>
      <Extended_Description>
        <xhtml:p>A device might support features such as secure boot which are supplemented with hardware and firmware support. This involves establishing a chain of trust, starting with an immutable root of trust by checking the signature of the next stage (culminating with the OS and runtime software) against a golden value before transferring control. The intermediate stages typically set up the system in a secure state by configuring several access control settings. Similarly, security logic for exercising a debug or testing interface may be implemented in hardware, firmware, or both. A device needs to guard against fault attacks such as voltage glitches and clock glitches that an attacker may employ in an attempt to compromise the system.</xhtml:p>
      </Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="703" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
		 <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Primary</Ordinality>
            </Weakness_Ordinality>
		 </Weakness_Ordinalities>
      <Applicable_Platforms>
        <Language Class="Language-Independent" Prevalence="Undetermined"/>
        <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
        <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
        <Technology Class="System on Chip" Prevalence="Undetermined"/>
				<Technology Name="Power Management IP" Prevalence="Undetermined"/>
				<Technology Name="Clock/Counter IP" Prevalence="Undetermined"/>
				<Technology Name="Sensor IP" Prevalence="Undetermined"/>
      </Applicable_Platforms>
      <Modes_Of_Introduction>
        <Introduction>
          <Phase>Operation</Phase>
        </Introduction>
      </Modes_Of_Introduction>
      <Common_Consequences>
        <Consequence>
          <Scope>Confidentiality</Scope>
          <Scope>Integrity</Scope>
          <Scope>Availability</Scope>
          <Scope>Access Control</Scope>
          <Impact>Gain Privileges or Assume Identity</Impact>
          <Impact>Bypass Protection Mechanism</Impact>
          <Impact>Read Memory</Impact>
          <Impact>Modify Memory</Impact>
          <Impact>Execute Unauthorized Code or Commands</Impact>
        </Consequence>
      </Common_Consequences>
	  <Detection_Methods>
		<Detection_Method>
		  <Method>Manual Analysis</Method>
		  <Description>
			
			<xhtml:p>Put the processor in an infinite
			loop, which is then followed by instructions
			that should not ever be executed, since the
			loop is not expected to exit.  After the loop,
			toggle an I/O bit (for oscilloscope monitoring
			purposes), print a console message, and
			reenter the loop.  Note that to ensure that
			the loop exit is actually captured, many NOP
			instructions should be coded after the loop
			branch instruction and before the I/O bit
			toggle and the print statement.</xhtml:p>

			<xhtml:p>Margining the clock consists of varying the clock
			frequency until an anomaly occurs. This could be a
			continuous frequency change or it could be a single
			cycle. The single cycle method is described here. For
			every 1000th clock pulse, the clock cycle is shortened by
			10 percent. If no effect is observed, the width is
			shortened by 20%. This process is continued in 10%
			increments up to and including 50%. Note that the cycle
			time may be increased as well, down to seconds per
			cycle.</xhtml:p>

			<xhtml:p>Separately, the voltage is margined. Note that
			the voltage could be increased or decreased. Increasing
			the voltage has limits, as the circuitry may not be able
			to withstand a drastically increased voltage. This process
			starts with a 5% reduction of the DC supply to the CPU
			chip for 5 millisecond repeated at 1KHz. If this has no
			effect, the process is repeated, but a 10% reduction is
			used. This process is repeated at 10% increments down to a
			50% reduction. If no effects are observed at 5
			millisecond, the whole process is repeated using a 10
			millisecond pulse. If no effects are observed, the process
			is repeated in 10 millisecond increments out to 100
			millisecond pulses.</xhtml:p>

			<xhtml:p>While these are suggested starting points for
			testing circuitry for weaknesses, the limits may need to
			be pushed further at the risk of device damage. See
			[REF-1217] for descriptions of Smart Card attacks against
			a clock (section 14.6.2) and using a voltage glitch
			(section 15.5.3).</xhtml:p>
		  </Description>
		  <Effectiveness>Moderate</Effectiveness>
		</Detection_Method>
		<Detection_Method>
		  <Method>Dynamic Analysis with Manual Results Interpretation</Method>
		  <Description>
		    During the implementation phase where actual hardware is available, specialized hardware tools and apparatus such as ChipWhisperer may be used to check if the platform is indeed susceptible to voltage and clock glitching attacks.
		  </Description>
		</Detection_Method>
		<Detection_Method>
		  <Method>Architecture or Design Review</Method>
		  <Description>
		    Review if the protections against glitching merely transfer the attack target. For example, suppose a critical authentication routine that an attacker would want to bypass is given the protection of modifying certain artifacts from within that specific routine (so that if the routine is bypassed, one can examine the artifacts and figure out that an attack must have happened). However, if the attacker has the ability to bypass the critical authentication routine, they might also have the ability to bypass the other protection routine that checks the artifacts. Basically, depending on these kind of protections is akin to resorting to "Security by Obscurity".
		  </Description>
		</Detection_Method>
		<Detection_Method>
		  <Method>Architecture or Design Review</Method>
		  <Description>
		    Many SoCs come equipped with a built-in Dynamic Voltage and Frequency Scaling (DVFS) that can control the voltage and clocks via software alone. However, there have been demonstrated attacks (like Plundervolt and CLKSCREW) that target this DVFS [REF-1081] [REF-1082]. During the design and implementation phases, one needs to check if the interface to this power management feature is available from unprivileged SW (CWE-1256), which would make the attack very easy.
		  </Description>
		</Detection_Method>
	  </Detection_Methods>
      <Potential_Mitigations>
        <Mitigation>
          <Phase>Architecture and Design</Phase>
          <Phase>Implementation</Phase>
          <Description>
            <xhtml:p>At the circuit-level, using Tunable Replica Circuits (TRCs) or special flip-flops such as Razor flip-flops helps mitigate glitch attacks. Working at the SoC or platform base, level sensors may be implemented to detect glitches. Implementing redundancy in security-sensitive code (e.g., where checks are performed)also can help with mitigation of glitch attacks.</xhtml:p>           
          </Description>
        </Mitigation>
      </Potential_Mitigations>
      <Demonstrative_Examples>
        <Demonstrative_Example>
          <Intro_Text>Below is a representative snippet of C code that is part of the secure-boot flow. A signature of the runtime-firmware image is calculated and compared against a golden value. If the signatures match, the bootloader loads runtime firmware. If there is no match, an error halt occurs. If the underlying hardware executing this code does not contain any circuitry or sensors to detect voltage or clock glitches, an attacker might launch a fault-injection attack right when the signature check is happening (at the location marked with the comment), causing a bypass of the signature-checking process.</Intro_Text>
          <Example_Code Nature="bad" Language="Other">
            <xhtml:p>...</xhtml:p>
            <xhtml:br/>
            <xhtml:p>if (signature_matches)  // &lt;-Glitch Here</xhtml:p>
            <xhtml:p>{</xhtml:p>
            <xhtml:p style="text-indent: 15px;">		load_runtime_firmware();</xhtml:p>
            <xhtml:p>}</xhtml:p>
            <xhtml:p>else</xhtml:p>
            <xhtml:p>{</xhtml:p>
            <xhtml:p style="text-indent: 15px;">		do_not_load_runtime_firmware();</xhtml:p>
            <xhtml:p>}</xhtml:p>
            <xhtml:br/>	
            <xhtml:p>...</xhtml:p>
          </Example_Code>
          <Body_Text>After bypassing secure boot, an attacker can gain access to system assets to which the attacker should not have access.</Body_Text>
        	<Example_Code Nature="informative">
         		<xhtml:div>If the underlying hardware detects a voltage or clock glitch, the information can be used to prevent the glitch from being successful.</xhtml:div>
        		</Example_Code>
      	</Demonstrative_Example>
      </Demonstrative_Examples>
      <Observed_Examples>
      	<Observed_Example>
        		<Reference>CVE-2019-17391</Reference>
        		<Description>Lack of anti-glitch protections allows an attacker to launch a physical attack to bypass the secure boot and read protected eFuses.</Description>
        		<Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-17391</Link>
      		 </Observed_Example>
      	</Observed_Examples>
        <Functional_Areas>
            <Functional_Area>Power</Functional_Area>
            <Functional_Area>Clock</Functional_Area>
        </Functional_Areas>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="624"/>
         </Related_Attack_Patterns>
         <References>
        <Reference External_Reference_ID="REF-1061"/>
        <Reference External_Reference_ID="REF-1062"/>
        <Reference External_Reference_ID="REF-1063"/>
        <Reference External_Reference_ID="REF-1064"/>
        <Reference External_Reference_ID="REF-1065"/>
        <Reference External_Reference_ID="REF-1066"/>
		<Reference External_Reference_ID="REF-1217" Section="14.6.2 Security Evolution, page 291"/>
		<Reference External_Reference_ID="REF-1217" Section="15.5.3 Glitching, page 317"/>
		<Reference External_Reference_ID="REF-1081"/>
		<Reference External_Reference_ID="REF-1082"/>
      </References>
      <Content_History>
        <Submission>
          <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
          <Submission_Organization>Intel Corporation</Submission_Organization>
          <Submission_Date>2020-02-12</Submission_Date>
        </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Description, Name, Observed_Examples, Potential_Mitigations, Related_Attack_Patterns</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-12-10</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Functional_Areas</Modification_Comment>
				</Modification>
				<Contribution Type="Content">
				  <Contribution_Name>Parbati K. Manna</Contribution_Name>
				  <Contribution_Organization>Intel Corporation</Contribution_Organization>
				  <Contribution_Date>2021-10-18</Contribution_Date>
				  <Contribution_Comment>provided detection methods</Contribution_Comment>
				</Contribution>
			<Previous_Entry_Name Date="2020-08-20">Missing Protection Against Voltage and Clock Glitches</Previous_Entry_Name>
      </Content_History>
    </Weakness>
      <Weakness ID="1248" Name="Semiconductor Defects in Hardware Logic with Security-Sensitive Implications" Abstraction="Base" Structure="Simple" Status="Incomplete">
            <Description>The security-sensitive hardware module contains semiconductor defects. </Description>
            <Extended_Description>
                <xhtml:p>A semiconductor device can fail for various reasons. While some are manufacturing and packaging defects, the rest are due to prolonged use or usage under extreme conditions. Some mechanisms that lead to semiconductor defects include encapsulation failure, die-attach failure, wire-bond failure, bulk-silicon defects, oxide-layer faults, aluminum-metal faults (including electromigration, corrosion of aluminum, etc.), and thermal/electrical stress. These defects manifest as faults on chip-internal signals or registers, have the effect of inputs, outputs, or intermediate signals being always 0 or always 1, and do not switch as expected. If such faults occur in security-sensitive hardware modules, security guarantees offered by the device will be compromised.</xhtml:p>
            </Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="693" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
            <Applicable_Platforms>
                <Language Class="Language-Independent" Prevalence="Undetermined"/>
                <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
                <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
                <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
            </Applicable_Platforms>
            <Modes_Of_Introduction>
                <Introduction>
                    <Phase>Manufacturing</Phase>
                    <Note>May be introduced due to issues in the manufacturing environment or improper handling of components, for example.</Note>
                </Introduction>
                <Introduction>
                    <Phase>Operation</Phase>
                    <Note>May be introduced by improper handling or usage outside of rated operating environments (temperature, humidity, etc.)</Note>
                </Introduction>
            </Modes_Of_Introduction>
            <Common_Consequences>
                <Consequence>
                    <Scope>Availability</Scope>
                    <Scope>Access Control</Scope>
                    <Impact>DoS: Instability</Impact>
                </Consequence>
            </Common_Consequences>
            <Potential_Mitigations>
                <Mitigation>
                    <Phase>Testing</Phase>
                    <Description>
                        <xhtml:p>While semiconductor-manufacturing companies implement several mechanisms to continuously improve the semiconductor manufacturing process to ensure reduction of defects, some defects can only be fixed after manufacturing. Post-manufacturing testing of silicon die is critical. Fault models such as stuck-at-0 or stuck-at-1 must be used to develop post-manufacturing test cases and achieve good coverage. Once the silicon packaging is done, extensive post-silicon testing must be performed to ensure that hardware logic implementing security functionalities is defect-free.</xhtml:p>                     
                    </Description>
                </Mitigation>
                <Mitigation>
                    <Phase>Operation</Phase>
                    <Description>
                        <xhtml:p>Operating the hardware outside device specification, such as at extremely high temperatures, voltage, etc., accelerates semiconductor degradation and results in defects.  When these defects manifest as faults in security-critical, hardware modules, it results in compromise of security guarantees. Thus, operating the device within the specification is important.</xhtml:p>                     
                    </Description>
                </Mitigation>
            </Potential_Mitigations>
            <Demonstrative_Examples>
                <Demonstrative_Example>
                    <Intro_Text>The network-on-chip implements a firewall for access control to peripherals from all IP cores capable of mastering transactions.</Intro_Text>
                    <Example_Code Nature="bad" Language="Other">
                        <xhtml:div>A manufacturing defect in this logic manifests itself as a logical fault, which always sets the output of the filter to "allow" access.</xhtml:div>
                    </Example_Code>
                    <Body_Text>Post-manufacture testing must be performed to ensure that hardware logic implementing security functionalities is defect-free.</Body_Text>
            	</Demonstrative_Example>
            </Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="624"/>
         </Related_Attack_Patterns>
         <References>
                <Reference External_Reference_ID="REF-1067"/>
                <Reference External_Reference_ID="REF-1068"/>
            </References>
            <Content_History>
                <Submission>
                    <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
                    <Submission_Organization>Intel Corporation</Submission_Organization>
                    <Submission_Date>2020-02-12</Submission_Date>
                </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Modes_of_Introduction, Related_Attack_Patterns</Modification_Comment>
				</Modification>
            </Content_History>
        </Weakness>
      <Weakness ID="1251" Name="Mirrored Regions with Different Values" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>The product's architecture mirrors regions without ensuring that their contents always stay in sync.</Description>
			<Extended_Description>
				<xhtml:p>Having mirrored regions with different values might result in the exposure of sensitive information or possibly system compromise.</xhtml:p>
				<xhtml:p>In the interest of increased performance, one might need to duplicate a resource. A cache memory is a common example of this concept, which keeps a "local" copy of a data element in the high speed cache memory. Unfortunately, this speed improvement comes with a downside, since the product needs to ensure that the local copy always mirrors the original copy truthfully. If they get out of sync, the computational result is no longer true.</xhtml:p>
				<xhtml:p>During hardware design, memory is not the only item which gets mirrored. There are many other entities that get mirrored, as well: registers, memory regions, and, in some cases, even whole computational units. For example, within a multi-core processor, if all memory accesses for each and every core goes through a single Memory-Management Unit (MMU) then the MMU will become a performance bottleneck. In such cases, duplicating local MMUs that will serve only a subset of the cores rather than all of them may resolve the performance issue. These local copies are also called "shadow copies" or "mirrored copies."</xhtml:p>
				<xhtml:p>If the original resource never changed, local duplicate copies getting out of sync would never be an issue. However, the values of the original copy will sometimes change. When the original copy changes, the mirrored copies must also change, and change fast.</xhtml:p>
				<xhtml:p>This situation of shadow-copy-possibly-out-of-sync-with-original-copy might occur as a result of multiple scenarios, including the following:
				</xhtml:p>
				<xhtml:div style="margin-left:10px;">
					<xhtml:div style="margin-left:10px;">
						<xhtml:ul>
							<xhtml:li>After the values in the original copy change, due to some reason the original copy does not send the "update" request to its shadow copies.</xhtml:li>
							<xhtml:li>After the values in the original copy change, the original copy dutifully sends the "update" request to its shadow copies, but due to some reason the shadow copy does not "execute" this update request.</xhtml:li>
							<xhtml:li>After the values in the original copy change, the original copy sends the "update" request to its shadow copies, and the shadow copy executes this update request faithfully. However, during the small time period when the original copy has "new" values and the shadow copy is still holding the "old" values, an attacker can exploit the old values. Then it becomes a race condition between the attacker and the update process of who can reach the target, shadow copy first, and, if the attacker reaches first, the attacker wins.</xhtml:li>
							<xhtml:li>The attacker might send a "spoofed" update request to the target shadow copy, pretending that this update request is coming from the original copy. This spoofed request might cause the targeted shadow copy to update its values to some attacker-friendly values, while the original copies remain unchanged by the attacker.</xhtml:li>
							<xhtml:li>Suppose a situation where the original copy has a system of reverting back to its original value if it does not hear back from all the shadow copies that such copies have successfully completed the update request. In such a case, an attack might occur as follows: (1) the original copy might send an update request; (2) the shadow copy updates it; (3) the shadow copy sends back the successful completion message; (4) through a separate issue, the attacker is able to intercept the shadow copy's completion message. In this case, the original copy thinks that the update did not succeed, hence it reverts to its original value. Now there is a situation where the original copy has the "old" value, and the shadow copy has the "new" value.</xhtml:li>
						</xhtml:ul>
					</xhtml:div>
				</xhtml:div>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="1250" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Name="VHDL" Prevalence="Undetermined"/>
				<Language Name="Verilog" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="System on Chip" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Scope>Access Control</Scope>
					<Scope>Accountability</Scope>
					<Scope>Authentication</Scope>
					<Scope>Authorization</Scope>
					<Scope>Non-Repudiation</Scope>
					<Impact>Varies by Context</Impact>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>
						<xhtml:p>Whenever there are multiple, physically different copies of the same value that might change and the process to update them is not instantaneous and atomic, it is impossible to assert that the original and shadow copies will always be in sync - there will always be a time period when they are out of sync. To mitigate the consequential risk, the recommendations essentially are:</xhtml:p>
						<xhtml:div style="margin-left:10px;">
							<xhtml:div style="margin-left:10px;">
								<xhtml:ul>
									<xhtml:li>Make this out-of-sync time period as small as possible, and</xhtml:li>
									<xhtml:li>Make the update process as robust as possible.</xhtml:li>
								</xhtml:ul>
							</xhtml:div>
						</xhtml:div>
					</Description>
					<Effectiveness>Moderate</Effectiveness>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example Demonstrative_Example_ID="DX-132">
					<Intro_Text>Suppose a processor's Memory Management Unit (MMU) has 5 other shadow MMUs to distribute its workload for its various cores. Each MMU has the start address and end address of "accessible" memory. Any time this accessible range changes (as per the processor's boot status), the main MMU sends an update message to all the shadow MMUs.</Intro_Text>
					<Body_Text>Suppose the interconnect fabric does not prioritize such "update" packets over other general traffic packets. This introduces a race condition. If an attacker can flood the target with enough messages so that some of those attack packets reach the target before the new access ranges gets updated, then the attacker can leverage this scenario.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
			<Notes>
				<Note Type="Research Gap">Issues related to state and cache - creation, preservation, and update - are a significant gap in CWE that is expected to be addressed in future versions. It has relationships to concurrency and synchronization, incorrect behavior order, and other areas that already have some coverage in CWE, although the focus has typically been on independent processes on the same operating system - not on independent systems that are all a part of a larger system-of-systems.
				</Note>
			</Notes>
			<Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-02-10</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Applicable_Platforms, Demonstrative_Examples, Description, Research_Gaps</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-12-10</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1252" Name="CPU Hardware Not Configured to Support Exclusivity of Write and Execute Operations" Abstraction="Base" Structure="Simple" Status="Incomplete">
            <Description>The CPU is not configured to provide hardware support for exclusivity of write and execute operations on memory. This allows an attacker to execute data from all of memory.</Description>
            <Extended_Description>
                <xhtml:p>CPUs provide a special bit that supports exclusivity of write and execute operations. This bit is used to segregate areas of memory to either mark them as code (instructions, which can be executed) or data (which should not be executed). In this way, if a user can write to a region of memory, the user cannot execute from that region and vice versa. This exclusivity provided by special hardware bit is leveraged by the operating system to protect executable space. While this bit is available in most modern processors by default, in some CPUs the exclusivity is implemented via a memory-protection unit (MPU) and memory-management unit (MMU) in which memory regions can be carved out with exact read, write, and execute permissions. However, if the CPU does not have an MMU/MPU, then there is no write exclusivity. Without configuring exclusivity of operations via segregated areas of memory, an attacker may be able to inject malicious code onto memory and later execute it.</xhtml:p>
            </Extended_Description>
			<Related_Weaknesses>
              <Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
            <Applicable_Platforms>
                <Language Class="Language-Independent" Prevalence="Undetermined"/>
                <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
                <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
                <Technology Name="Microcontroller IP" Prevalence="Undetermined"/>
                <Technology Name="Processor IP" Prevalence="Undetermined"/>
            </Applicable_Platforms>
            <Modes_Of_Introduction>
                <Introduction>
					<Phase>Architecture and Design</Phase>
                </Introduction>
            </Modes_Of_Introduction>
            <Common_Consequences>
                <Consequence>
                    <Scope>Confidentiality</Scope>
                    <Scope>Integrity</Scope>
                    <Impact>Execute Unauthorized Code or Commands</Impact>
                </Consequence>
            </Common_Consequences>
            <Potential_Mitigations>
                <Mitigation>
                    <Phase>Architecture and Design</Phase>
                    <Description>
                        <xhtml:p>Implement a dedicated bit that can be leveraged by the Operating System to mark data areas as non-executable. If such a bit is not available in the CPU, implement MMU/MPU (memory management unit / memory protection unit).</xhtml:p>                     
                    </Description>
                </Mitigation>
                <Mitigation>
                    <Phase>Integration</Phase>
                    <Description>
                        <xhtml:p>If MMU/MPU are not available, then the firewalls need to be implemented in the SoC interconnect to mimic the write-exclusivity operation.</xhtml:p>                     
                    </Description>
                </Mitigation>
            </Potential_Mitigations>
            <Demonstrative_Examples>
                <Demonstrative_Example>
                    <Intro_Text>MCS51 Microcontroller (based on 8051) does not have a special bit to support write exclusivity. It also does not have an MMU/MPU support. The Cortex-M CPU has an optional MPU that supports up to 8 regions.</Intro_Text>
                    <Example_Code Nature="bad" Language="Other">
                        <xhtml:div>The optional MPU is not configured.</xhtml:div>
                    </Example_Code>
                    <Body_Text>If the MPU is not configured, then an attacker will be able to inject malicious data into memory and execute it.</Body_Text>
            	</Demonstrative_Example>
            </Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <References>
                <Reference External_Reference_ID="REF-1076"/>
                <Reference External_Reference_ID="REF-1077"/>
                <Reference External_Reference_ID="REF-1078"/>
            </References>

            <Content_History>
                <Submission>
                    <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
                    <Submission_Organization>Intel Corporation</Submission_Organization>
                    <Submission_Date>2020-02-13</Submission_Date>
                </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
            </Content_History>
        </Weakness>
      <Weakness ID="1253" Name="Incorrect Selection of Fuse Values" Abstraction="Base" Structure="Simple" Status="Draft">
     <Description>The logic level used to set a system to a secure state relies on a fuse being unblown. An attacker can set the system to an insecure state merely by blowing the fuse.</Description>
     <Extended_Description>
      <xhtml:p>Fuses are often used to store secret data, including security configuration data. When not blown, a fuse is considered to store a logic 0, and, when blown, it indicates a logic 1. Fuses are generally considered to be one-directional, i.e., once blown to logic 1, it cannot be reset to logic 0. However, if the logic used to determine system-security state (by leveraging the values sensed from the fuses) uses negative logic, an attacker might blow the fuse and drive the system to an insecure state.</xhtml:p>
     </Extended_Description>
			<Related_Weaknesses>
			 <Related_Weakness Nature="ChildOf" CWE_ID="693" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
     <Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
     <Modes_Of_Introduction>
      <Introduction>
        <Phase>Architecture and Design</Phase>
      </Introduction>
      <Introduction>
        <Phase>Implementation</Phase>
      </Introduction>
     </Modes_Of_Introduction>
     <Common_Consequences>
      <Consequence>
        <Scope>Access Control</Scope>
        <Scope>Authorization</Scope>
        <Impact>Bypass Protection Mechanism</Impact>
        <Impact>Gain Privileges or Assume Identity</Impact>
      </Consequence>
      <Consequence>
        <Scope>Availability</Scope>
        <Impact>DoS: Crash, Exit, or Restart</Impact>
      </Consequence>
      <Consequence>
        <Scope>Confidentiality</Scope>
        <Impact>Read Memory</Impact>
      </Consequence>
      <Consequence>
        <Scope>Integrity</Scope>
        <Impact>Modify Memory</Impact>
        <Impact>Execute Unauthorized Code or Commands</Impact>
      </Consequence>
     </Common_Consequences>
     <Potential_Mitigations>
      <Mitigation>
        <Phase>Architecture and Design</Phase>
        <Description>Logic should be designed in a way that blown fuses do not put the product into an insecure state that can be leveraged by an attacker.
        </Description>
      </Mitigation>
     </Potential_Mitigations>
     <Demonstrative_Examples>
      <Demonstrative_Example>
        <Intro_Text><xhtml:p>A chip implements a secure boot and uses the sensed value of a fuse 
         "do_secure_boot" to determine whether to perform a secure boot or not. If this fuse 
         value is "0", the system performs secure boot. Otherwise, it does not perform secure 
         boot.</xhtml:p>
         <xhtml:p>An attacker blows the "do_secure_boot" fuse to "1". After reset, the attacker loads a custom 
         bootloader, and, since the fuse value is now "1", the system does not perform secure boot, 
         and the attacker can execute their custom firmware image.</xhtml:p>
         <xhtml:p>Since by default, a fuse-configuration value is a "0", an attacker can blow it to a "1" with 
         inexpensive hardware.</xhtml:p>
         <xhtml:p>If the logic is reversed, an attacker cannot easily reset the fuse. Note that, with 
         specialized and expensive equipment, an attacker with full physical access might be able to "unblow" the fuse 
         value to a "0".</xhtml:p>
        </Intro_Text>
      </Demonstrative_Example>
     </Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="74"/>
         </Related_Attack_Patterns>
         <References>
      <Reference External_Reference_ID="REF-1080"/>
     </References>
     <Notes>
      <Note Type="Maintenance">This entry is still under development and will continue to see updates and content improvements.</Note>
     </Notes>
     <Content_History>
      <Submission>
        <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
        <Submission_Organization>Intel Corporation</Submission_Organization>
        <Submission_Date>2019-10-15</Submission_Date>
      </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Applicable_Platforms, Demonstrative_Examples, Description</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
     </Content_History>
   </Weakness>
      <Weakness ID="1254" Name="Incorrect Comparison Logic Granularity" Abstraction="Base" Structure="Simple" Status="Draft">
         <Description>The product's comparison logic is performed over a series of steps rather than across the entire string in one operation. If there is a comparison logic failure on one of these steps, the operation may be vulnerable to a timing attack that can result in the interception of the process for nefarious purposes.</Description>
         <Extended_Description>
            <xhtml:p>Comparison logic is used to compare a variety of objects including passwords, Message 
         Authentication Codes (MACs), and responses to verification challenges. When comparison logic is 
         implemented at a finer granularity (e.g., byte-by-byte comparison) and breaks in the case of a 
         comparison failure, an attacker can exploit this implementation to identify when exactly 
         the failure occurred. With multiple attempts, the attacker may be able to guesses the correct 
         password/response to challenge and elevate their privileges.</xhtml:p>
         </Extended_Description>
         <Related_Weaknesses>
            <Related_Weakness Nature="ChildOf" CWE_ID="208" View_ID="1000" Ordinal="Primary"/>
            <Related_Weakness Nature="ChildOf" CWE_ID="697" View_ID="1000"/>
         </Related_Weaknesses>
         <Applicable_Platforms>
            <Language Class="Language-Independent" Prevalence="Undetermined"/>
						<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
						<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
                        <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
         </Applicable_Platforms>
         <Modes_Of_Introduction>
            <Introduction>
               <Phase>Architecture and Design</Phase>
            </Introduction>
            <Introduction>
               <Phase>Implementation</Phase>
            </Introduction>
         </Modes_Of_Introduction>
         <Common_Consequences>
            <Consequence>
                <Scope>Confidentiality</Scope>
               <Scope>Authorization</Scope>
               <Impact>Bypass Protection Mechanism</Impact>
            </Consequence>
         </Common_Consequences>
         <Potential_Mitigations>
            <Mitigation>
               <Phase>Implementation</Phase>
               <Description>
                 <xhtml:p>The hardware designer should ensure that comparison logic is implemented so as to compare in one operation instead in smaller chunks.</xhtml:p>
               </Description>
            </Mitigation>
         </Potential_Mitigations>
         <Demonstrative_Examples>
            <Demonstrative_Example>
                <Intro_Text>Consider an example hardware module that checks a user-provided password to grant access to a user. The user-provided password is compared against a golden value in a byte-by-byte manner.</Intro_Text>
                <Example_Code Nature="bad" Language="Other">
                    <xhtml:div/>always_comb @ (posedge clk)
                    <xhtml:br/>begin
                    <xhtml:br/>	assign check_pass[3:0] = 4’b0;
                    <xhtml:br/>	for (i = 0; i &lt; 4; i++) begin
                    <xhtml:br/>		if (entered_pass[(i*8 – 1) : i] eq golden_pass([i*8 -1) : i])
                    <xhtml:br/>			assign check_pass[i] = 1;
                    <xhtml:br/>			continue;
                    <xhtml:br/>		else
                    <xhtml:br/>			assign check_pass[i] = 0;
                    <xhtml:br/>			break;
                    <xhtml:br/>	end
                    <xhtml:br/>	assign grant_access = (check_pass == 4’b1111) ? 1’b1: 1’b0;
                    <xhtml:br/>end
			    </Example_Code>
                <Body_Text>Since the code breaks on an incorrect entry of password, an attacker can guess the correct password for that byte-check iteration with few repeat attempts.</Body_Text>
                <Example_Code Nature="informative">
                <xhtml:br/>Either the comparison of the entire string should be done all at once or the attacker is not given an indication whether pass or fail happened by allowing the comparison to run through all bits before the grant_access signal is set. 
                <xhtml:br/>
                <xhtml:br/>always_comb @ (posedge clk)
                <xhtml:br/>
                <xhtml:br/>begin
                <xhtml:br/>     assign check_pass[3:0] = 4’b0;
                <xhtml:br/>	    for (i = 0; i &lt; 4; i++) begin
                <xhtml:br/>		    if (entered_pass[(i*8 – 1) : i] eq golden_pass([i*8 -1) : i])
                <xhtml:br/>		    	assign check_pass[i] = 1;
                <xhtml:br/>			    continue;
                <xhtml:br/>		    else
                <xhtml:br/>		    	assign check_pass[i] = 0;
                <xhtml:br/>			    continue;
                <xhtml:br/>	    end
                <xhtml:br/>	    assign grant_access = (check_pass == 4’b1111) ? 1’b1: 1’b0;
                <xhtml:br/>end
				</Example_Code>
            </Demonstrative_Example>
        </Demonstrative_Examples>
         <Observed_Examples>
            <Observed_Example>
               <Reference>CVE-2014-0984</Reference>
               <Description>The passwordCheck function in SAP Router 721 patch 117, 720 patch 411, 710 patch 029, and earlier terminates validation of a Route Permission Table entry password upon encountering the first incorrect character, which allows remote attackers to obtain passwords via a brute-force attack that relies on timing differences in responses to incorrect password guesses, aka a timing side-channel attack.</Description>
               <Link>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-0984</Link>
            </Observed_Example>
         </Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="26"/>
         </Related_Attack_Patterns>
         <References>
            <Reference External_Reference_ID="REF-1079"/>
         </References>
         <Content_History>
            <Submission>
               <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
               <Submission_Organization>Intel Corporation</Submission_Organization>
               <Submission_Date>2020-02-12</Submission_Date>
            </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
         </Content_History>
      </Weakness>
      <Weakness ID="1255" Name="Comparison Logic is Vulnerable to Power Side-Channel Attacks" Abstraction="Variant" Structure="Simple" Status="Draft">
      <Description>A device's real time power consumption may be monitored during security token evaluation and the information gleaned may be used to determine the value of the reference token.</Description>
      <Extended_Description>
        <xhtml:p>The power consumed by a device may be instrumented and monitored in real time. If the algorithm for evaluating security tokens is not sufficiently robust, the power consumption may vary by token entry comparison against the reference value. Further, if retries are unlimited, the power difference between a "good" entry and a "bad" entry may be observed and used to determine whether each entry itself is correct thereby allowing unauthorized parties to calculate the reference value.</xhtml:p>
      </Extended_Description>
      <Related_Weaknesses>
        <Related_Weakness Nature="ChildOf" CWE_ID="1300" View_ID="1000" Ordinal="Primary"/>
        <Related_Weakness Nature="PeerOf" CWE_ID="1259" View_ID="1194" Ordinal="Primary"/>
      </Related_Weaknesses>
      <Applicable_Platforms>
        <Language Class="Language-Independent" Prevalence="Undetermined"/>
        <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
        <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
        <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
      </Applicable_Platforms>
      <Modes_Of_Introduction>
        <Introduction>
          <Phase>Architecture and Design</Phase>
          <Note>The design of the algorithm itself may intrinsically allow the power side channel attack to be effective</Note>
        </Introduction>
        <Introduction>
          <Phase>Implementation</Phase>
          <Note>This weakness may be introduced during implementation despite a robust design that otherwise prevents exploitation</Note>
        </Introduction>
      </Modes_Of_Introduction>
      <Common_Consequences>
        <Consequence>
          <Scope>Confidentiality</Scope>
          <Scope>Integrity</Scope>
          <Scope>Availability</Scope>
          <Scope>Access Control</Scope>
          <Scope>Accountability</Scope>
          <Scope>Authentication</Scope>
          <Scope>Authorization</Scope>
          <Scope>Non-Repudiation</Scope>
          <Impact>Modify Memory</Impact>
          <Impact>Read Memory</Impact>
          <Impact>Read Files or Directories</Impact>
          <Impact>Modify Files or Directories</Impact>
          <Impact>Execute Unauthorized Code or Commands</Impact>
          <Impact>Gain Privileges or Assume Identity</Impact>
          <Impact>Bypass Protection Mechanism</Impact>
          <Impact>Read Application Data</Impact>
          <Impact>Modify Application Data</Impact>
          <Impact>Hide Activities</Impact>
          <Note>As compromising a security token may result in complete system control, the impacts are relatively universal</Note>
        </Consequence>
      </Common_Consequences>
      <Potential_Mitigations>
        <Mitigation>
          <Phase>Architecture and Design</Phase>
          <Description>The design phase must consider each check of a security token against a standard and the amount of power consumed during the check of a good token versus a bad token. The alternative is an all at once check where a retry counter is incremented PRIOR to the check.</Description>
        </Mitigation>
        <Mitigation>
          <Phase>Architecture and Design</Phase>
          <Description>Another potential mitigation is to parallelize shifting of secret data (see example 2 below). Note that the wider the bus the more effective the result.</Description>
        </Mitigation>
        <Mitigation>
          <Phase>Architecture and Design</Phase>
          <Description>An additional potential mitigation is to add random data to each crypto operation then subtract it out afterwards. This is highly effective but costly in performance, area, and power consumption. It also requires a random number generator.</Description>
        </Mitigation>
        <Mitigation>
          <Phase>Implementation</Phase>
          <Description>If the architecture is unable to prevent the attack, using filtering components may reduce the ability to implement an attack, however, consideration must be given to the physical removal of the filter elements.</Description>
        </Mitigation>
        <Mitigation>
          <Phase>Integration</Phase>
          <Description>During integration, avoid use of a single secret for an extended period (e.g. frequent key updates). This limits the amount of data compromised but at the cost of complexity of use.</Description>
        </Mitigation>
      </Potential_Mitigations>
      <Demonstrative_Examples>
        <Demonstrative_Example>
          <Intro_Text>Consider an example hardware module that checks a user-provided password (or PIN) to grant access to a user. The user-provided password is compared against a stored value byte-by-byte.</Intro_Text>
          <Example_Code Nature="bad" Language="Other">
            <xhtml:br/>static nonvolatile password_tries = NUM_RETRIES;
            <xhtml:br/>do
            <xhtml:br/>  while (password_tries == 0) ; // Hang here if no more password tries
            <xhtml:br/>  password_ok = 0;
            <xhtml:br/>  for (i = 0; i &lt; NUM_PW_DIGITS; i++)
            <xhtml:br/>    if (GetPasswordByte() == stored_password([i])
            <xhtml:br/>      password_ok |= 1; // Power consumption is different here
            <xhtml:br/>    else
            <xhtml:br/>      password_ok |= 0; // than from here
            <xhtml:br/>  end
            <xhtml:br/>  if (password_ok &gt; 0)
            <xhtml:br/>    password_tries = NUM_RETRIES;
            <xhtml:br/>    break_to_Ok_to_proceed
            <xhtml:br/>  password_tries--;
            <xhtml:br/>while (true)
            <xhtml:br/>// Password OK
          </Example_Code>
          <Body_Text>Since the algorithm uses a different number of 1's and 0's for password validation, a different amount of power is consumed for the good byte versus the bad byte comparison. Using this information, an attacker may be able to guess the correct password for that byte-by-byte iteration with several repeated attempts by stopping the password evaluation before it completes.</Body_Text>
          <Example_Code Nature="good">
            <xhtml:br/>
            <xhtml:br/>Among various options for mitigating the string comparison is obscuring the power comsumption by having opposing bit flips during bit operations. Note that in this example, the initial change of the bit values could still provide power indication depending upon the hardware itself. This possibility needs to be measured for verification.
            <xhtml:br/>static nonvolatile password_tries = NUM_RETRIES;
            <xhtml:br/>do
            <xhtml:br/>  while (password_tries == 0) ; // Hang here if no more password tries
            <xhtml:br/>  password_tries--;  // Put retry code here to catch partial retries
            <xhtml:br/>  password_ok = 0;
            <xhtml:br/>  for (i = 0; i &lt; NUM_PW_DIGITS; i++)
            <xhtml:br/>    if (GetPasswordByte() == stored_password([i])
            <xhtml:br/>      password_ok |= 0x10; // Power consumption here
            <xhtml:br/>    else
            <xhtml:br/>      password_ok |= 0x01; // is now the same here
            <xhtml:br/>  end
            <xhtml:br/>  if ((password_ok &amp; 1) == 0)
            <xhtml:br/>    password_tries = NUM_RETRIES;
            <xhtml:br/>    break_to_Ok_to_proceed
            <xhtml:br/>while (true)
            <xhtml:br/>// Password OK
          </Example_Code>
          <Body_Text>Since the algorithm uses a different number of 1's and 0's for password validation, a different amount of power is consumed for the good byte versus the bad byte comparison. Using this information, an attacker may be able to guess the correct password for that byte-by-byte iteration with several repeated attempts by stopping the password evaluation before it completes.</Body_Text>
          <Example_Code Nature="good">
            <xhtml:br/>An alternative to the previous example is simply comparing the whole password simultaneously.
            <xhtml:br/>
            <xhtml:br/>static nonvolatile password_tries = NUM_RETRIES;
            <xhtml:br/>do
            <xhtml:br/>  while (password_tries == 0) ; // Hang here if no more password tries
            <xhtml:br/>  password_tries--;  // Put retry code here to catch partial retries
            <xhtml:br/>  for (i = 0; i &lt; NUM_PW_DIGITS; i++)
            <xhtml:br/>    stored_password([i] = GetPasswordByte();
            <xhtml:br/>  end
            <xhtml:br/>  if (stored_password == saved_password)
            <xhtml:br/>    password_tries = NUM_RETRIES;
            <xhtml:br/>    break_to_Ok_to_proceed
            <xhtml:br/>while (true)
            <xhtml:br/>// Password OK
          </Example_Code>
           <Body_Text>Since comparison is done atomically, there is no indication which bytes fail forcing the attacker to brute force the whole password at once. Note that other mitigations may exist such as masking - causing a large current draw to mask individual bit flips.</Body_Text>
       </Demonstrative_Example>
       <Demonstrative_Example>
          <Intro_Text>This code demonstrates the transfer of a secret key using Serial-In/Serial-Out shift. It's easy to extract the secret using simple power analysis as each shift gives data on a single bit of the key.</Intro_Text>
          <Example_Code Nature="bad" Language="Other">
            <xhtml:br/>module siso(clk,rst,a,q);
            <xhtml:br/>  input a;
            <xhtml:br/>  input clk,rst;
            <xhtml:br/>  output q;
            <xhtml:br/>  reg q;
            <xhtml:br/>  
            <xhtml:br/>  always@(posedge clk,posedge rst)
            <xhtml:br/>  begin
            <xhtml:br/>    if(rst==1'b1)
            <xhtml:br/>      q&lt;1'b0;
            <xhtml:br/>    else
            <xhtml:br/>      q&lt;a;
            <xhtml:br/>  end
            <xhtml:br/>endmodule
          </Example_Code>
            <Body_Text>This code demonstrates the transfer of a secret key using a Parallel-In/Parallel-Out shift. In a parallel shift, data confounded by multiple bits of the key, not just one.</Body_Text>
            <Example_Code Nature="good" Language="Other">
            <xhtml:br/>module pipo(clk,rst,a,q);
            <xhtml:br/>  input clk,rst;
            <xhtml:br/>  input[3:0]a;
            <xhtml:br/>  output[3:0]q;
            <xhtml:br/>  reg[3:0]q;
            <xhtml:br/>  
            <xhtml:br/>  always@(posedge clk,posedge rst)
            <xhtml:br/>  begin
            <xhtml:br/>    if (rst==1'b1)
            <xhtml:br/>      q&lt;4'b0000;
            <xhtml:br/>    else
            <xhtml:br/>      q&lt;a;
            <xhtml:br/>  end
            <xhtml:br/>endmodule
          </Example_Code>
        </Demonstrative_Example>
      </Demonstrative_Examples>
            <Observed_Examples>
            <Observed_Example>
               <Reference>CVE-2020-12788</Reference>
               <Description>CMAC verification vulnerable to timing and power attacks.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-12788</Link>
            </Observed_Example>
      </Observed_Examples>
      <Functional_Areas>
            <Functional_Area>Power</Functional_Area>
      </Functional_Areas>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="189"/>
         </Related_Attack_Patterns>
         <References>
         <Reference External_Reference_ID="REF-1184"/>
      </References>
      <Content_History>
        <Submission>
          <Submission_Name>CWE Content Team</Submission_Name>
          <Submission_Organization>MITRE</Submission_Organization>
          <Submission_Date>2020-05-29</Submission_Date>
        </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Functional_Areas, Maintenance_Notes, Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Modes_of_Introduction, Observed_Examples, Potential_Mitigations, References, Related_Attack_Patterns</Modification_Comment>
				</Modification>
        <Contribution Type="Content">
          <Contribution_Name>Accellera IP Security Assurance (IPSA) Working Group</Contribution_Name>
          <Contribution_Organization>Accellera Systems Initiative</Contribution_Organization>
          <Contribution_Date>2020-09-09</Contribution_Date>
          <Contribution_Comment>Submitted new material that could be added to already-existing entry CWE-1255. Added new Potential Mitigations, a new example, an observed example, and an additional reference.
        </Contribution_Comment>
        </Contribution>
      </Content_History>
    </Weakness>
      <Weakness ID="1256" Name="Improper Restriction of Software Interfaces to Hardware Features" Abstraction="Base" Structure="Simple" Status="Stable">

			<Description>The product provides software-controllable
			device functionality for capabilities such as power and
			clock management, but it does not properly limit
			functionality that can lead to modification of
			hardware memory or register bits, or the ability to
			observe physical side channels.</Description>
            <Extended_Description>
              <xhtml:p>It is frequently assumed that physical attacks
              such as fault injection and side-channel analysis
              require an attacker to have physical access to the
              target device.  This assumption may be false if the
              device has improperly secured power management features,
              or similar features.  For mobile devices, minimizing
              power consumption is critical, but these devices run a
              wide variety of applications with different performance
              requirements. Software-controllable mechanisms to
              dynamically scale device voltage and frequency and
              monitor power consumption are common features in today's
              chipsets, but they also enable attackers to mount fault
              injection and side-channel attacks without having
              physical access to the device.</xhtml:p>
			  
              <xhtml:p>Fault injection attacks involve strategic
              manipulation of bits in a device to achieve a desired
              effect such as skipping an authentication step,
              elevating privileges, or altering the output of a
              cryptographic operation.  Manipulation of the device
              clock and voltage supply is a well-known technique to
              inject faults and is cheap to implement with physical
              device access.  Poorly protected power management
              features allow these attacks to be performed from
              software.  Other features, such as the ability to write
              repeatedly to DRAM at a rapid rate from unprivileged
              software, can result in bit flips in other memory
              locations (Rowhammer, [REF-1083]).</xhtml:p>

			  <xhtml:p>Side channel analysis requires gathering
			  measurement traces of physical quantities such as power
			  consumption.  Modern processors often include power
			  metering capabilities in the hardware itself (e.g.,
			  Intel RAPL) which if not adequately protected enable
			  attackers to gather measurements necessary for
			  performing side-channel attacks from software.</xhtml:p>
            </Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="285" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
		 <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Primary</Ordinality>
            </Weakness_Ordinality>
		 </Weakness_Ordinalities>
            <Applicable_Platforms>
                <Language Class="Language-Independent" Prevalence="Undetermined"/>
                <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
                <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
                <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				<Technology Name="Memory IP" Prevalence="Undetermined"/>
			        <Technology Name="Power Management IP" Prevalence="Undetermined"/>
				<Technology Name="Clock/Counter IP" Prevalence="Undetermined"/>
            </Applicable_Platforms>
            <Modes_Of_Introduction>
                <Introduction>
                    <Phase>Architecture and Design</Phase>
					<Note>An architect may initiate introduction of
					this weakness via exacting requirements for
					software accessible power/clock management
					requirements</Note>
                </Introduction>
                <Introduction>
		            <Phase>Implementation</Phase>
					<Note>An implementer may introduce this weakness
					by assuming there are no consequences to unbounded
					power and clock management for secure components
					from untrusted ones.</Note>
                </Introduction>
            </Modes_Of_Introduction>
            <Common_Consequences>
                <Consequence>
                    <Scope>Integrity</Scope>
                    <Impact>Modify Memory</Impact>
                    <Impact>Modify Application Data</Impact>
                    <Impact>Bypass Protection Mechanism</Impact>
                </Consequence>
            </Common_Consequences>
	    <Detection_Methods>
	      <Detection_Method>
		<Method>Manual Analysis</Method>
		<Description>Perform a security evaluation of system-level
		architecture and design with software-aided physical attacks
		in scope.</Description>
	      </Detection_Method>
	      <Detection_Method>
		<Method>Automated Dynamic Analysis</Method>
		<Description>
		  <xhtml:p>Use custom software to change registers that control clock settings or power settings to try to bypass security locks, or repeatedly write DRAM to try to change adjacent locations. This can be effective in extracting or changing data. The drawback is that it cannot be run before manufacturing, and it may require specialized software.</xhtml:p>
		</Description>
		<Effectiveness>Moderate</Effectiveness>
	      </Detection_Method>
	    </Detection_Methods>
            <Potential_Mitigations>
                <Mitigation>
                    <Phase>Architecture and Design</Phase>
                    <Phase>Implementation</Phase>
                    <Description>
                        <xhtml:p>Ensure proper access control mechanisms protect software-controllable features altering physical operating conditions such as clock frequency and voltage.</xhtml:p>                     
                    </Description>
                </Mitigation>
            </Potential_Mitigations>
            <Demonstrative_Examples>
               <Demonstrative_Example>
                    <Intro_Text>This example considers the Rowhammer problem [REF-1083]. The Rowhammer issue was caused by a program in a tight loop writing repeatedly to a location to which the program was allowed to write but causing an adjacent memory location value to change.</Intro_Text>
                    <Example_Code Nature="bad" Language="Other">
                        Continuously writing the same value to the same address causes the value of an adjacent location to change value.
                    </Example_Code>
                    <Body_Text>Preventing the loop required to defeat the Rowhammer exploit is not always possible:</Body_Text>
                    <Example_Code Nature="good" Language="Other">
                        Redesign the RAM devices to reduce inter capacitive coupling making the Rowhammer exploit impossible.
                    </Example_Code>
                    <Body_Text>While the redesign may be possible for new devices, a redesign is not possible in existing devices. There is also the possibility that reducing capacitance with a relayout would impact the density of the device resulting in a less capable, more costly device.</Body_Text>
                </Demonstrative_Example>
                <Demonstrative_Example>
                    <Intro_Text>Suppose a hardware design implements a set of software-accessible registers for scaling clock frequency and voltage but does not control access to these registers. Attackers may cause register and memory changes and race conditions by changing the clock or voltage of the device under their control.</Intro_Text>
                </Demonstrative_Example>
            <Demonstrative_Example>
	      <Intro_Text>Consider the following SoC
	      design. Security-critical settings for scaling clock
	      frequency and voltage are available in a range of
	      registers bounded by [PRIV_END_ADDR : PRIV_START_ADDR]
	      in the tmcu.csr module in the HW Root of Trust. These
	      values are writable based on the lock_bit register in
	      the same module. The lock_bit is only writable by
	      privileged software running on the tmcu.</Intro_Text>
	    <Body_Text>
	    <xhtml:img src="https://cwe.mitre.org/data/images/HRoT-CWE.png" alt="Hardware Root of Trust"/>
	    <xhtml:p>
	      We assume that untrusted software running on any of the
	      Core{0-N} processors has access to the input and output
	      ports of the hrot_iface. If untrusted software can clear
	      the lock_bit or write the clock frequency and voltage
	      registers due to inadequate protection, a fault
	      injection attack could be performed.</xhtml:p>
	    </Body_Text>
            </Demonstrative_Example>
            </Demonstrative_Examples>
            <Observed_Examples>
            	<Observed_Example>
               		<Reference>CVE-2019-11157</Reference>
               		<Description>Plundervolt: Improper conditions check in voltage settings for some Intel(R) Processors may allow a privileged user to potentially enable escalation of privilege and/or information disclosure via local access [REF-1081].</Description>
               		<Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-11157</Link>
           		 </Observed_Example>
               <Observed_Example>
                     <Reference>CVE-2020-8694</Reference>
                     <Description>PLATYPUS Attack: Insufficient access control in the Linux kernel driver for some Intel processors allows information disclosure.</Description>
                     <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8694</Link>
                     </Observed_Example>
               <Observed_Example>
                     <Reference>CVE-2020-8695</Reference>
                     <Description>Observable discrepancy in the RAPL interface for some Intel processors allows information disclosure.</Description>
                     <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8695</Link>
                     </Observed_Example>
               <Observed_Example>
                     <Reference>CVE-2020-12912</Reference>
                     <Description>AMD extension to a Linux service does not require privileged access to the RAPL interface, allowing side-channel attacks.</Description>
                     <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-12912</Link>
                     </Observed_Example>
					 <Observed_Example>
               		<Reference>CVE-2015-0565</Reference>
               		<Description>NaCl in 2015 allowed the CLFLUSH instruction, making Rowhammer attacks possible.</Description>
               		<Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-0565</Link>
           		 </Observed_Example>
           	</Observed_Examples>
         <Functional_Areas>
            	<Functional_Area>Power</Functional_Area>
                <Functional_Area>Clock</Functional_Area>
         </Functional_Areas>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="624"/>
         </Related_Attack_Patterns>
         <References>
                <Reference External_Reference_ID="REF-1081"/>
                <Reference External_Reference_ID="REF-1082"/>
                <Reference External_Reference_ID="REF-1083"/>
                <Reference External_Reference_ID="REF-1225"/>
                <Reference External_Reference_ID="REF-1217"/>
            </References>
            <Content_History>
                <Submission>
                    <Submission_Name>Nicole Fern</Submission_Name>
                    <Submission_Organization>Tortuga Logic</Submission_Organization>
                    <Submission_Date>2020-05-08</Submission_Date>
                </Submission>
		<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Description, Maintenance_Notes, Related_Attack_Patterns</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Functional_Areas, Maintenance_Notes</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Observed_Examples</Modification_Comment>
				</Modification>
            <Contribution Type="Content">
               <Contribution_Organization>Tortuga Logic</Contribution_Organization>
               <Contribution_Date>2021-07-16</Contribution_Date>
               <Contribution_Comment>Provided Demonstrative Example for Hardware Root of Trust</Contribution_Comment>
            </Contribution>
		<Contribution Type="Content">
		  <Contribution_Name>Anders Nordstrom, Alric Althoff</Contribution_Name>
		  <Contribution_Organization>Tortuga Logic</Contribution_Organization>
		  <Contribution_Date>2021-10-11</Contribution_Date>
		  <Contribution_Comment>Provided detection method</Contribution_Comment>
		</Contribution>
		<Contribution Type="Content">
		  <Contribution_Name>Nicole Fern</Contribution_Name>
		  <Contribution_Organization>Riscure</Contribution_Organization>
		  <Contribution_Date>2021-10-15</Contribution_Date>
		  <Contribution_Comment>updated description and extended description, detection method, and observed examples</Contribution_Comment>
		</Contribution>
            </Content_History>
        </Weakness>
      <Weakness ID="1257" Name="Improper Access Control Applied to Mirrored or Aliased Memory Regions" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>Aliased or mirrored memory regions in hardware designs may have inconsistent read/write permissions enforced by the hardware. A possible result is that an untrusted agent is blocked from accessing a memory region but is not blocked from accessing the corresponding aliased memory region.
			</Description>
			<Extended_Description>
				<xhtml:p>Hardware product designs often need to implement memory protection features that enable privileged software to define isolated memory regions and access control (read/write) policies. Isolated memory regions can be defined on different memory spaces in a design (e.g. system physical address, virtual address, memory mapped IO).</xhtml:p>
				<xhtml:p>Each memory cell should be mapped and assigned a system address that the core software can use to read/write to that memory. It is possible to map the same memory cell to multiple system addresses such that read/write to any of the aliased system addresses would be decoded to the same memory cell.</xhtml:p>
				<xhtml:p>This is commonly done in hardware designs for redundancy and simplifying address decoding logic. If one of the memory regions is corrupted or faulty, then that hardware can switch to using the data in the mirrored memory region. Memory aliases can also be created in the system address map if the address decoder unit ignores higher order address bits when mapping a smaller address region into the full system address.</xhtml:p>
				<xhtml:p>A common security weakness that can exist in such memory mapping is that aliased memory regions could have different read/write access protections enforced by the hardware such that an untrusted agent is blocked from accessing a memory address but is not blocked from accessing the corresponding aliased memory address. Such inconsistency can then be used to bypass the access protection of the primary memory block and read or modify the protected memory.</xhtml:p>
				<xhtml:p>An untrusted agent could also possibly create memory aliases in the system address map for malicious purposes if it is able to change the mapping of an address region or modify memory region sizes.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
				<Related_Weakness Nature="CanPrecede" CWE_ID="119" View_ID="1000"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Memory IP" Prevalence="Undetermined"/>
				<Technology Name="Processor IP" Prevalence="Undetermined"/>
				<Technology Name="Microcontroller IP" Prevalence="Undetermined"/>
				<Technology Name="Network on Chip IP" Prevalence="Undetermined"/>
				<Technology Class="System on Chip" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Impact>Read Memory</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
				<Consequence>
					<Scope>Integrity</Scope>
					<Impact>Modify Memory</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
				<Consequence>
					<Scope>Availability</Scope>
					<Impact>DoS: Instability</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Phase>Implementation</Phase>
					<Description>The checks should be applied for consistency access rights between primary memory regions and any mirrored or aliased memory regions. If different memory protection units (MPU) are protecting the aliased regions, their protected range definitions and policies should be synchronized.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Phase>Implementation</Phase>
					<Description>The controls that allow enabling memory aliases or changing the size of mapped memory regions should only be programmable by trusted software components.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>
						<xhtml:p>In a System-on-a-Chip (SoC) design the system fabric uses 16 bit addresses. An IP unit (Unit_A) has 4 kilobyte of internal memory which is mapped into a 16 kilobyte address range in the system fabric address map.</xhtml:p>
						<xhtml:table>
							<xhtml:tr>
								<xhtml:td>
									System Address
								</xhtml:td>
								<xhtml:td>
									Mapped to
								</xhtml:td>
							</xhtml:tr>
							<xhtml:tr>
								<xhtml:td>
									0x0000 – 0x3FFF
								</xhtml:td>
								<xhtml:td>
									Unit_A  registers : 0x0000 – 0x0FFF
								</xhtml:td>
							</xhtml:tr>
							<xhtml:tr>
								<xhtml:td>
									0x4000 – 0xFFFF
								</xhtml:td>
								<xhtml:td>
									Other IPs &amp; Memory
								</xhtml:td>
							</xhtml:tr>
						</xhtml:table>
						<xhtml:p>
							To protect the register controls in Unit_A unprivileged software is blocked from accessing addresses between 0x0000 – 0x0FFF.
						</xhtml:p>
						<xhtml:p>
							The address decoder of Unit_A masks off the higher order address bits and decodes only the lower 12 bits for computing the offset into the 4 kilobyte internal memory space.
						</xhtml:p>
					</Intro_Text>
					<Example_Code Nature="bad" Language="Other">
						<xhtml:p>In this design  the aliased memory address ranges are these:</xhtml:p>
						<xhtml:br/>
						<xhtml:p>0x0000 – 0x0FFF</xhtml:p>
						<xhtml:p>0x1000 – 0x1FFF</xhtml:p>
						<xhtml:p>0x2000 – 0x2FFF</xhtml:p>
						<xhtml:p>0x3000 – 0x3FFF</xhtml:p>
						<xhtml:p>
							The same register can be accessed using four different addresses: 0x0000, 0x1000, 0x2000, 0x3000.
						</xhtml:p>
						<xhtml:p>
							The system address filter only blocks access to range 0x0000 - 0x0FFF and does not block access to the aliased addresses in 0x1000 - 0x3FFF range. Thus, untrusted software can leverage the aliased memory addresses to bypass the memory protection.
						</xhtml:p>
					</Example_Code>
					<Example_Code Nature="good" Language="Other">
						<xhtml:p>
							In this design the aliased memory addresses (0x1000 - 0x3FFF) could be blocked from all system software access since they are not used by software.
						</xhtml:p>
						<xhtml:p>
							Alternately, the MPU logic can be changed to apply the memory protection policies to the full address range mapped to Unit_A (0x0000 - 0x3FFF).
						</xhtml:p>
					</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-04-29</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Description, Modes_of_Introduction, Potential_Mitigations, Related_Attack_Patterns</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1258" Name="Exposure of Sensitive System Information Due to Uncleared Debug Information" Abstraction="Base" Structure="Simple" Status="Draft">
         <Description>The hardware does not fully clear security-sensitive values, such as keys and intermediate values in cryptographic operations, when debug mode is entered.</Description>
         <Extended_Description>
            <xhtml:p>Security sensitive values, keys, intermediate steps of cryptographic operations, etc. are stored in temporary registers in the hardware. If these values are not cleared when debug mode is entered they may be accessed by a debugger allowing sensitive information to be accessible by untrusted parties.</xhtml:p>
         </Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="212" View_ID="1000" Ordinal="Primary"/>
			  <Related_Weakness Nature="ChildOf" CWE_ID="200" View_ID="1000"/>
			</Related_Weaknesses>
         <Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
         <Modes_Of_Introduction>
            <Introduction>
               <Phase>Architecture and Design</Phase>
            </Introduction>
            <Introduction>
               <Phase>Implementation</Phase>
            </Introduction>
         </Modes_Of_Introduction>
         <Common_Consequences>
                <Consequence>
               <Scope>Confidentiality</Scope>
               <Impact>Read Memory</Impact>
            </Consequence>
            <Consequence>
               <Scope>Access Control</Scope>
               <Impact>Bypass Protection Mechanism</Impact>
            </Consequence>
         </Common_Consequences>
         <Potential_Mitigations>
            <Mitigation>
               <Phase>Architecture and Design</Phase>
               <Description>
                 <xhtml:p>Whenever debug mode is enabled, all registers containing sensitive assets must be cleared.</xhtml:p>
               </Description>
            </Mitigation>
         </Potential_Mitigations>
         <Demonstrative_Examples>
            <Demonstrative_Example>
               <Intro_Text>A cryptographic core in a System-On-a-Chip (SoC) is used for cryptographic acceleration and implements several cryptographic operations (e.g., computation of AES encryption and decryption, SHA-256, HMAC, etc.). The keys for these operations or the intermediate values are stored in registers internal to the cryptographic core. These internal registers are in the Memory Mapped Input Output (MMIO) space and are blocked from access by software and other untrusted agents on the SoC. These registers are accessible through the debug and test interface.</Intro_Text>

                <Example_Code Nature="bad" Language="Other">In the above scenario, registers that store keys and intermediate values of cryptographic operations are not cleared when system enters debug mode. An untrusted actor running a debugger may read the contents of these registers and gain access to secret keys and other sensitive cryptographic information.</Example_Code>

                <Example_Code Nature="good" Language="Other">Whenever the chip enters debug mode, all registers containing security-sensitive data are be cleared rendering them unreadable.</Example_Code>
            </Demonstrative_Example>
         </Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="150"/>
            <Related_Attack_Pattern CAPEC_ID="204"/>
            <Related_Attack_Pattern CAPEC_ID="37"/>
            <Related_Attack_Pattern CAPEC_ID="545"/>
         </Related_Attack_Patterns>
         <Content_History>
            <Submission>
               <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
               <Submission_Organization>Intel Corporation</Submission_Organization>
               <Submission_Date>2020-02-12</Submission_Date>
            </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Description, Name, Related_Attack_Patterns, Relationships</Modification_Comment>
				</Modification>
			<Previous_Entry_Name Date="2020-08-20">Sensitive Information Uncleared During Hardware Debug Flows</Previous_Entry_Name>
         </Content_History>
      </Weakness>
      <Weakness ID="1259" Name="Improper Restriction of Security Token Assignment" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>The System-On-A-Chip (SoC) implements a Security Token mechanism to differentiate what actions are allowed or disallowed when a transaction originates from an entity. However, the Security Tokens are improperly protected.</Description>
			<Extended_Description>Systems-On-A-Chip (Integrated circuits and hardware engines) implement Security Tokens to differentiate and identify which actions originated from which agent. These actions may be one of the directives: 'read', 'write', 'program', 'reset', 'fetch', 'compute', etc. Security Tokens are assigned to every agent in the System that is capable of generating an action or receiving an action from another agent. Multiple Security Tokens may be assigned to an agent and may be unique based on the agent's trust level or allowed privileges. Since the Security Tokens are integral for the maintenence of security in an SoC, they need to be protected properly. A common weakness afflicting Security Tokens is improperly restricting the assignment to trusted components. Consequently, an improperly protected Security Token may be able to be programmed by a malicious agent (i.e., the Security Token is mutable) to spoof the action as if it originated from a trusted agent.
			</Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			  <Related_Weakness Nature="ChildOf" CWE_ID="1294" View_ID="1194" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>	
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Processor IP" Class="Technology-Independent" Prevalence="Undetermined"/>
				<Technology Class="System on Chip" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Scope>Access Control</Scope>
					<Impact>Modify Files or Directories</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
					<Impact>Bypass Protection Mechanism</Impact>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Modify Memory</Impact>
					<Impact>Modify Memory</Impact>
					<Impact>DoS: Crash, Exit, or Restart</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Phase>Implementation</Phase>
					<Description>
						<xhtml:ul>
							<xhtml:li>Security Token assignment review checks for design inconsistency and common weaknesses.</xhtml:li>
							<xhtml:li>Security-Token definition and programming flow is tested in both pre-silicon and post-silicon testing.</xhtml:li>
						</xhtml:ul>
					</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>For example, consider a system with a register for storing an AES key for encryption and decryption. The key is of 128 bits implemented as a set of four 32-bit registers. The key register assets have an associated control register, AES_KEY_ACCESS_POLICY, which provides the necessary access controls. This access-policy register defines which agents may engage in a transaction, and the type of transaction, with the AES-key registers. Each bit in this 32-bit register defines a security Token. There could be a maximum of 32 security Tokens that are allowed access to the AES-key registers. The number of the bit when set (i.e., “1”) allows respective action from an agent whose identity matches the number of the bit and, if “0” (i.e., Clear), disallows the respective action to that corresponding agent.</Intro_Text>
					
					
					<Body_Text>Let’s assume the system has two agents: a Main-controller and an Aux-controller. The respective Security Tokens are “1” and “2”.
					
					<xhtml:table>		
						<xhtml:tr>			
							<xhtml:th>Register</xhtml:th>
							<xhtml:th>Description</xhtml:th>
							<xhtml:th>Default</xhtml:th>
						</xhtml:tr>		
						<xhtml:tr>			
							<xhtml:td>AES_ENC_DEC_KEY_0</xhtml:td>
							<xhtml:td>AES key [0:31] for encryption or decryption</xhtml:td>
							<xhtml:td>0x00000000</xhtml:td>
						</xhtml:tr>
						<xhtml:tr>
							<xhtml:td>AES_ENC_DEC_KEY_1</xhtml:td>
							<xhtml:td>AES key [32:63] for encryption or decryption</xhtml:td>
							<xhtml:td>0x00000000</xhtml:td>
						</xhtml:tr>	
						<xhtml:tr>
							<xhtml:td>AES_ENC_DEC_KEY_2</xhtml:td>
							<xhtml:td>AES key [64:95] for encryption or decryption</xhtml:td>
							<xhtml:td>0x00000000</xhtml:td>
						</xhtml:tr>	
						<xhtml:tr>
							<xhtml:td>AES_ENC_DEC_KEY_3</xhtml:td>
							<xhtml:td>AES key [96:127] for encryption or decryption</xhtml:td>
							<xhtml:td>0x00000000</xhtml:td>
						</xhtml:tr>	
						<xhtml:tr>
							<xhtml:td>AES_KEY_ACCESS_POLICY</xhtml:td>
							<xhtml:td>AES key access register [31:0]</xhtml:td>
							<xhtml:td>0x00000002</xhtml:td>
						</xhtml:tr>
					</xhtml:table>
				</Body_Text>
					
					<Body_Text>An agent with Security Token “1” has access to AES_ENC_DEC_KEY_0 through AES_ENC_DEC_KEY_3 registers. As per the above access policy, the AES-Key-access policy allows access to the AES-key registers if the security Token is “1”.</Body_Text>
					
					<Example_Code Nature="bad" Language="Other">The Aux-controller could program its Security Token to “1” from “2”.</Example_Code>
					<Body_Text>The SoC does not properly protect the Security Token of the agents, and, hence, the Aux-controller in the above example can spoof the transaction (i.e., send the transaction as if it is coming from the Main-controller to access the AES-Key registers)</Body_Text>
					<Example_Code Nature="good" Language="Other">The SoC needs to protect the Security Tokens. None of the agents in the SoC should have the ability to change the Security Token.</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <Notes>
        <Note Type="Maintenance">
          This entry is still under development and will continue to see updates and content improvements. Currently it is expressed as a general absence of a protection mechanism as opposed to a specific mistake, and the entry's name and description could be interpreted as applying to software.
        </Note>
      </Notes>
			<Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-03-06</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Description, Modes_of_Introduction, Name, Potential_Mitigations, Related_Attack_Patterns, Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Maintenance_Notes</Modification_Comment>
				</Modification>
			<Previous_Entry_Name Date="2020-08-20">Improper Protection of Security Identifiers</Previous_Entry_Name>
			</Content_History>
		</Weakness>
      <Weakness ID="1260" Name="Improper Handling of Overlap Between Protected Memory Ranges" Abstraction="Base" Structure="Simple" Status="Stable">
         <Description>The product allows address regions to overlap, which can result in the bypassing of intended memory protection.</Description>
         <Extended_Description>
            <xhtml:p>Isolated memory regions and access control (read/write) policies are used by hardware to protect privileged software. Software components are often allowed to change or remap memory region definitions in order to enable flexible and dynamically changeable memory management by system software.</xhtml:p>
            <xhtml:p>If a software component running at lower privilege can program a memory address region to overlap with other memory regions used by software running at higher privilege, privilege escalation may be available to attackers. The memory protection unit (MPU) logic can incorrectly handle such an address overlap and allow the lower-privilege software to read or write into the protected memory region, resulting in privilege escalation attack. An address overlap weakness can also be used to launch a denial of service attack on the higher-privilege software memory regions.</xhtml:p>
         </Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			  <Related_Weakness Nature="CanPrecede" CWE_ID="119" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
		 <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Primary</Ordinality>
            </Weakness_Ordinality>
            <Weakness_Ordinality>
               <Ordinality>Resultant</Ordinality>
            </Weakness_Ordinality>
		 </Weakness_Ordinalities>
         <Applicable_Platforms>
            <Language Class="Language-Independent" Prevalence="Undetermined"/>
	    <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
	    <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
            <Technology Name="Memory IP" Prevalence="Undetermined"/>
            <Technology Name="Processor IP" Prevalence="Undetermined"/>
         </Applicable_Platforms>
         <Modes_Of_Introduction>
            <Introduction>
               <Phase>Architecture and Design</Phase>
            <Note>Such issues could be introduced during hardware architecture and design or implementation and identified later during the Testing phase.</Note>            
            </Introduction>
            <Introduction>
               <Phase>Implementation</Phase>
            </Introduction>
         </Modes_Of_Introduction>
         <Common_Consequences>
            <Consequence>
               <Scope>Confidentiality</Scope>
               <Scope>Integrity</Scope>
               <Scope>Availability</Scope>
               <Impact>Modify Memory</Impact>
               <Impact>Read Memory</Impact>
               <Impact>DoS: Instability</Impact>
               <Likelihood>High</Likelihood>
            </Consequence>
         </Common_Consequences>
	 <Detection_Methods>
	   <Detection_Method>
	     <Method>Manual Analysis</Method>
	     <Description>Create a high privilege memory block of any arbitrary size. Attempt to create a lower privilege memory block with an overlap of the high privilege memory block. If the creation attempt works, fix the hardware. Repeat the test.</Description>
	     <Effectiveness>High</Effectiveness>
	   </Detection_Method>
	 </Detection_Methods>
         <Potential_Mitigations>
            <Mitigation>
               <Phase>Architecture and Design</Phase>
               <Description>
                   <xhtml:p>Ensure that memory regions are isolated as intended and that access control (read/write) policies are used by hardware to protect privileged software.</xhtml:p>
               </Description>
            </Mitigation>
            <Mitigation> 
               <Phase>Implementation</Phase>
               <Description>
                 <xhtml:p>For all of the programmable memory protection regions, the memory protection unit (MPU) design can define a priority scheme.</xhtml:p>
                 <xhtml:p>For example: if three memory regions can be programmed (Region_0, Region_1, and Region_2), the design can enforce a priority scheme, such that, if a system address is within multiple regions, then the region with the lowest ID takes priority and the access-control policy of that region will be applied.  In some MPU designs, the priority scheme can also be programmed by trusted software.</xhtml:p>
                 <xhtml:p>Hardware logic or trusted firmware can also check for region definitions and block programming of memory regions with overlapping addresses. </xhtml:p>
                 <xhtml:p>The memory-access-control-check filter can also be designed to apply a policy filter to all of the overlapping ranges, i.e., if an address is within Region_0 and Region_1, then access to this address is only granted if both Region_0 and Region_1 policies allow the access.</xhtml:p>
               </Description>
               <Effectiveness>High</Effectiveness>
            </Mitigation>
         </Potential_Mitigations>
         <Demonstrative_Examples>
            <Demonstrative_Example>
	      <Intro_Text>
		<xhtml:p>For example, consider a design with a 16-bit address that has two software privilege levels: Privileged_SW and Non_privileged_SW. To isolate the system memory regions accessible by these two privilege levels, the design supports three memory regions: Region_0, Region_1, and Region_2.</xhtml:p>
		<xhtml:p>Each region is defined by two 32 bit registers: its range and its access policy.</xhtml:p>
		<xhtml:ul>
		  <xhtml:li>Address_range[15:0]: specifies the Base address of the region</xhtml:li>
		  <xhtml:li>Address_range[31:16]: specifies the size of the region</xhtml:li>
		  <xhtml:li>Access_policy[31:0]: specifies what types of software can access a region and which actions are allowed</xhtml:li>
		</xhtml:ul>
		<xhtml:p>Certain bits of the access policy are defined symbolically as follows:</xhtml:p>
		<xhtml:ul>
		  <xhtml:li>Access_policy.read_np: if set to one, allows reads from Non_privileged_SW</xhtml:li>
		  <xhtml:li>Access_policy.write_np: if set to one, allows writes from Non_privileged_SW</xhtml:li>
		  <xhtml:li>Access_policy.execute_np: if set to one, allows code execution by Non_privileged_SW</xhtml:li>
		  <xhtml:li>Access_policy.read_p: if set to one, allows reads from Privileged_SW</xhtml:li>
		  <xhtml:li>Access_policy.write_p: if set to one, allows writes from Privileged_SW</xhtml:li>
		  <xhtml:li>Access_policy.execute_p: if set to one, allows code execution by Privileged_SW</xhtml:li>
		</xhtml:ul>
		<xhtml:p>For any requests from software, an address-protection filter checks the address range and access policies for each of the three regions, and only allows software access if all three filters allow access.</xhtml:p>
		<xhtml:p>Consider the following goals for access control as intended by the designer:</xhtml:p>
		<xhtml:ul>
		  <xhtml:li>Region_0 &amp; Region_1: registers are programmable by Privileged_SW</xhtml:li>
		  <xhtml:li>Region_2: registers are programmable by Non_privileged_SW</xhtml:li>
		</xhtml:ul>
		<xhtml:p>The intention is that Non_privileged_SW cannot modify memory region and policies defined by Privileged_SW in Region_0 and Region_1. Thus, it cannot read or write the memory regions that Privileged_SW is using.</xhtml:p>
	      </Intro_Text>
            <Example_Code Nature="bad">
               <xhtml:p>Non_privileged_SW can program the Address_range register for Region_2 so that its address overlaps with the ranges defined by Region_0 or Region_1. Using this capability, it is possible for Non_privileged_SW to block any memory region from being accessed by Privileged_SW, i.e., Region_0 and Region_1.</xhtml:p>
            </Example_Code>
	    <Body_Text>This design could be improved in several ways.</Body_Text>
            <Example_Code Nature="good">Ensure that software accesses to memory regions are only permitted if all three filters permit access. Additionally, the scheme could define a memory region priority to ensure that Region_2 (the memory region defined by Non_privileged_SW) cannot overlap Region_0 or Region_1 (which are used by Privileged_SW).</Example_Code>
	    </Demonstrative_Example>
         </Demonstrative_Examples>
         <Observed_Examples>
            <Observed_Example>
               <Reference>CVE-2008-7096</Reference>
               <Description>virtualization product allows compromise of hardware product by accessing certain remapping registers.</Description>
               <Link>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2008-7096</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>[REF-1100]</Reference>
               <Description>processor design flaw allows ring 0 code to access more privileged rings by causing a register window to overlap a range of protected system RAM [REF-1100]</Description>
               <Link>https://github.com/xoreaxeaxeax/sinkhole/blob/master/us-15-Domas-TheMemorySinkhole-wp.pdf</Link>
            </Observed_Example>
			</Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <References>
         <Reference External_Reference_ID="REF-1100"/>
      </References>
      <Notes>
	<Note Type="Maintenance">As of CWE 4.6, CWE-1260 and CWE-1316 are siblings under view 1000, but CWE-1260 might be a parent of CWE-1316. More analysis is warranted.</Note>
      </Notes>
         <Content_History>
            <Submission>
               <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
               <Submission_Organization>Intel Corporation</Submission_Organization>
               <Submission_Date>2020-02-10</Submission_Date>
            </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Description, Modes_of_Introduction, Related_Attack_Patterns</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-12-10</Modification_Date>
					<Modification_Comment>updated Maintenance_Notes</Modification_Comment>
				</Modification>
				<Contribution Type="Feedback">
				  <Contribution_Name>Narasimha Kumar V Mangipudi</Contribution_Name>
				  <Contribution_Organization>Lattice Semiconductor</Contribution_Organization>
				  <Contribution_Date>2021-10-20</Contribution_Date>
				  <Contribution_Comment>suggested content improvements</Contribution_Comment>
				</Contribution>
				<Contribution Type="Content">
				  <Contribution_Name>Hareesh Khattri</Contribution_Name>
				  <Contribution_Organization>Intel Corporation</Contribution_Organization>
				  <Contribution_Date>2021-10-22</Contribution_Date>
				  <Contribution_Comment>suggested observed examples</Contribution_Comment>
				</Contribution>
         </Content_History>
      </Weakness>
      <Weakness ID="1261" Name="Improper Handling of Single Event Upsets" Abstraction="Base" Structure="Simple" Status="Draft">
         <Description>The hardware logic does not effectively handle when single-event upsets (SEUs) occur.</Description>
         <Extended_Description>
            <xhtml:p>Technology trends such as CMOS-transistor down-sizing, use of 
            new materials, and system-on-chip architectures continue to increase the 
            sensitivity of systems to soft errors. These errors are random, and 
            their causes might be internal (e.g., interconnect coupling) or external 
            (e.g., cosmic radiation). These soft errors are not permanent in nature 
            and cause temporary bit flips known as single-event upsets (SEUs). 
            SEUs are induced errors in circuits caused when charged particles lose 
            energy by ionizing the medium through which they pass, leaving behind a 
            wake of electron-hole pairs that cause temporary failures. If these 
            failures occur in security-sensitive modules in a chip, it might 
            compromise the security guarantees of the chip. For instance, these 
            temporary failures could be bit flips that change the privilege of
	    a regular user to root.</xhtml:p>
         </Extended_Description>
         <Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="755" View_ID="1000" Ordinal="Primary"/>
				<Related_Weakness Nature="PeerOf" CWE_ID="1254" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
         <Applicable_Platforms>	
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
            <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
         </Applicable_Platforms>
         <Modes_Of_Introduction>
            <Introduction>
               <Phase>Architecture and Design</Phase>
            </Introduction>
            <Introduction>
               <Phase>Implementation</Phase>
            </Introduction>
         </Modes_Of_Introduction>
         <Common_Consequences>
            <Consequence>
               <Scope>Availability</Scope>
               <Scope>Access Control</Scope>
               <Impact>DoS: Crash, Exit, or Restart</Impact>
               <Impact>DoS: Instability</Impact>
               <Impact>Gain Privileges or Assume Identity</Impact>
               <Impact>Bypass Protection Mechanism</Impact>
            </Consequence>
         </Common_Consequences>
         <Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>
						<xhtml:p>Implement triple-modular redundancy around security-sensitive modules.</xhtml:p>
					</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>
						<xhtml:p>SEUs mostly affect SRAMs.  For SRAMs storing security-critical data, implement Error-Correcting-Codes (ECC) and Address Interleaving.</xhtml:p>
					</Description>
				</Mitigation>
			</Potential_Mitigations>
         <Demonstrative_Examples>
            <Demonstrative_Example>
               <Intro_Text>This is an example from [REF-1089].  See the reference for full details of this issue.</Intro_Text>
               <Body_Text>Parity is error detecting but not error correcting.</Body_Text>
               <Example_Code Nature="bad" Language="Other">Due to single-event upsets, bits are flipped in memories.  As a result, memory-parity checks fail, which results in restart and a temporary denial of service of two to three minutes.</Example_Code>
               <Example_Code Nature="good" Language="Other">Using error-correcting codes could have avoided the restart caused by SEUs. </Example_Code>
            </Demonstrative_Example>
            <Demonstrative_Example>
               <Intro_Text>In 2016, a security researcher, who was also a patient using a pacemaker, was on an airplane when a bit flip occurred in the pacemaker, likely due to the higher prevalence of cosmic radiation at such heights. The pacemaker was designed to account for bit flips and went into a default safe mode, which still forced the patient to go to a hospital to get it reset. The bit flip also inadvertently enabled the researcher to access the crash file, perform reverse engineering, and detect a hard-coded key. [REF-1101]</Intro_Text>
            </Demonstrative_Example>
         </Demonstrative_Examples>
         <References>
            <Reference External_Reference_ID="REF-1086"/>
            <Reference External_Reference_ID="REF-1087"/>
            <Reference External_Reference_ID="REF-1088"/>
            <Reference External_Reference_ID="REF-1089"/>
            <Reference External_Reference_ID="REF-1090"/>
            <Reference External_Reference_ID="REF-1091"/>
            <Reference External_Reference_ID="REF-1101"/>
         </References>
         <Content_History>
            <Submission>
               <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
               <Submission_Organization>Intel Corporation</Submission_Organization>
               <Submission_Date>2020-02-12</Submission_Date>
            </Submission>
         </Content_History>
      </Weakness>
      <Weakness ID="1262" Name="Improper Access Control for Register Interface" Abstraction="Base" Structure="Simple" Status="Stable">
			<Description>The product uses memory-mapped I/O registers that act as an interface to hardware functionality from software, but there is improper access control to those registers.</Description>
			<Extended_Description>
				<xhtml:p>Software commonly accesses peripherals in a System-on-Chip (SoC) or other device through a memory-mapped register interface. Malicious software could tamper with any security-critical hardware data that is accessible directly or indirectly through the register interface, which could lead to a loss of confidentiality and integrity.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
			 <Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
		 <Weakness_Ordinalities>
		   <Weakness_Ordinality>
		     <Ordinality>Primary</Ordinality>
		   </Weakness_Ordinality>
		 </Weakness_Ordinalities>
		 <Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
					<Note>This weakness may be exploited if the register interface design does not adequately protect hardware assets from software.</Note>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>Mis-implementation of access control policies may inadvertently allow access to hardware assets through the register interface.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Impact>Read Memory</Impact>
					<Impact>Read Application Data</Impact>
					<Impact>Modify Memory</Impact>
					<Impact>Modify Application Data</Impact>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Bypass Protection Mechanism</Impact>
					<Impact>Unexpected State</Impact>
					<Impact>Alter Execution Logic</Impact>
					<Note>Confidentiality of hardware assets may be violated if the protected information can be read out by software through the register interface. Registers storing security state, settings, other security-critical data may be corruptible by software without correctly implemented protections.</Note>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
			  <Detection_Method>
			    <Method>Manual Analysis</Method>
			    <Description>This is applicable in the Architecture phase before implementation started. Make sure access policy is specified for the entire memory map. Manual analysis may not ensure the implementation is correct.</Description>
			    <Effectiveness>Moderate</Effectiveness>
			  </Detection_Method>
            <Detection_Method>
               <Method>Manual Analysis</Method>
               <Description>Registers controlling hardware should have access control implemented. This access control may be checked manually for correct implementation. Items to check consist of how are trusted parties set, how are trusted parties verified, how are accesses verified, etc. Effectiveness of a manual analysis will vary depending upon how complicated the interface is constructed.</Description>
               <Effectiveness>Moderate</Effectiveness>
            </Detection_Method>
			  <Detection_Method>
			    <Method>Simulation / Emulation</Method>
			    <Description>Functional simulation is applicable during the Implementation Phase. Testcases must be created and executed for memory mapped registers to verify adherence to the access control policy. This method can be effective, since functional verification needs to be performed on the design, and verification for this weakness will be included. There can be difficulty covering the entire memory space during the test.</Description>
			    <Effectiveness>Moderate</Effectiveness>
			  </Detection_Method>
			  <Detection_Method>
			    <Method>Formal Verification</Method>
			    <Description>Formal verification is applicable during the Implementation phase. Assertions need to be created in order to capture illegal register access scenarios and prove that they cannot occur. Formal methods are exhaustive and can be very effective, but creating the cases for large designs may be complex and difficult.</Description>
			    <Effectiveness>High</Effectiveness>
			  </Detection_Method>
			  <Detection_Method>
			    <Method>Automated Analysis</Method>
			    <Description>Information flow tracking can be applicable during the Implementation phase. Security sensitive data (assets) - for example, as stored in registers - is automatically tracked over time through the design to verify the data doesn't reach illegal destinations that violate the access policies for the memory map. This method can be very effective when used together with simulation and emulation, since detecting violations doesn't rely on specific scenarios or data values. This method does rely on simulation and emulation, so testcases must exist in order to use this method.</Description>
			    <Effectiveness>High</Effectiveness>
			  </Detection_Method>
			  <Detection_Method>
			    <Method>Architecture or Design Review</Method>
			    <Description>Manual documentation review of the system memory map, register specification, and permissions associated with accessing security-relevant functionality exposed via memory-mapped registers.</Description>
			    <Effectiveness>Moderate</Effectiveness>
			  </Detection_Method>
			  <Detection_Method>
			    <Method>Fuzzing</Method>
			    <Description>Perform penetration testing (either manual or semi-automated with fuzzing) to verify that access control mechanisms such as the memory protection units or on-chip bus firewall settings adequately protect critical hardware registers from software access.</Description>
			    <Effectiveness>Moderate</Effectiveness>
			  </Detection_Method>
			</Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Design proper policies for hardware register access from software.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Ensure that access control policies for register access are implemented in accordance with the specified design.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>The register interface provides software access to hardware functionality. This functionality is an attack surface. This attack surface may be used to run untrusted code on the system through the register interface. As an example, cryptographic accelerators require a mechanism for software to select modes of operation and to provide plaintext or ciphertext data to be encrypted or decrypted as well as other functions. This functionality is commonly provided through registers.</Intro_Text>
					<Example_Code Nature="bad">Cryptographic key material stored in registers inside the cryptographic accelerator can be accessed by software.</Example_Code>
					<Example_Code Nature="good">Key material stored in registers should never be accessible to software. Even if software can provide a key, all read-back paths to software should be disabled.</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
		<Observed_Examples>
		  <Observed_Example>
		    <Reference>CVE-2014-2915</Reference>
		    <Description>virtualization product does not restrict access to debug and other processor registers in the hardware, allowing a crash of the host or guest OS</Description>
		    <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-2915</Link>
		  </Observed_Example>
		  <Observed_Example>
		    <Reference>CVE-2021-3011</Reference>
		    <Description>virtual interrupt controller in a virtualization product allows crash of host by writing a certain invalid value to a register, which triggers a fatal error instead of returning an error code</Description>
		    <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-3011</Link>
		  </Observed_Example>
          <Observed_Example>
            <Reference>CVE-2020-12446</Reference>
            <Description>Driver exposes access to Model Specific Register (MSR) registers, allowing admin privileges.</Description>
            <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-12446</Link>
          </Observed_Example>
          <Observed_Example>
            <Reference>CVE-2015-2150</Reference>
            <Description>Virtualization product does not restrict access to PCI command registers, allowing host crash from the guest.</Description>
            <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-2150</Link>
          </Observed_Example>
		</Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <Content_History>
	   <Submission>
	     <Submission_Name>Nicole Fern</Submission_Name>
	     <Submission_Organization>Tortuga Logic</Submission_Organization>
	     <Submission_Date>2020-05-08</Submission_Date>
	   </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Common_Consequences, Demonstrative_Examples, Description, Maintenance_Notes, Modes_of_Introduction, Potential_Mitigations, Related_Attack_Patterns</Modification_Comment>
				</Modification>
           <Contribution Type="Content">
             <Contribution_Name>Anders Nordstrom, Alric Althoff</Contribution_Name>
             <Contribution_Organization>Tortuga Logic</Contribution_Organization>
             <Contribution_Date>2021-10-11</Contribution_Date>
             <Contribution_Comment>Provided detection methods and observed examples</Contribution_Comment>
            </Contribution>
           <Contribution Type="Content">
             <Contribution_Name>Nicole Fern</Contribution_Name>
             <Contribution_Organization>Riscure</Contribution_Organization>
             <Contribution_Date>2021-10-12</Contribution_Date>
             <Contribution_Comment>Provided detection methods</Contribution_Comment>
            </Contribution>
			</Content_History>
		</Weakness>
      <Weakness ID="1263" Name="Improper Physical Access Control" Abstraction="Class" Structure="Simple" Status="Incomplete">
			<Description>The product is designed with access restricted to certain information, but it does not sufficiently protect against an unauthorized actor with physical access to these areas.</Description>
			<Extended_Description>Sections of a product intended to have restricted access may be inadvertently or intentionally rendered accessible when the implemented physical protections are insufficient. The specific requirements around how robust the design of the physical protection mechanism needs to be depends on the type of product being protected. Selecting the correct physical protection mechanism and properly enforcing it through implementation and manufacturing are critical to the overall physical security of the product.
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
				<Related_Weakness Nature="PeerOf" CWE_ID="1191" View_ID="1000"/>
				<Related_Weakness Nature="PeerOf" CWE_ID="1243" View_ID="1000"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
					<Note>This weakness can arise if design decisions are made that do not align with the intended physical protection of the product</Note>
				</Introduction>
				<Introduction>
					<Phase>Manufacturing</Phase>
					<Note>While the architecture and design phase of the product may have accurately met the intended robustness for product physical protections, this phase may introduce the weakness through errors in physically manufacturing the product.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Access Control</Scope>
					<Impact>Varies by Context</Impact>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Specific protection requirements depend strongly on contextual factors including the level of acceptable risk associated with compromise to the product's protection mechanism. Designers could incorporate anti-tampering measures that protect against or detect when the product has been tampered with.</Description>
				</Mitigation>
				<Mitigation>
				  <Phase>Testing</Phase>
				  <Description>The testing phase of the lifecycle should establish a method for determining whether the protection mechanism is sufficient to prevent unauthorized access.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Manufacturing</Phase>
					<Description>Ensure that all protection mechanisms are fully activated at the time of manufacturing and distribution.</Description>
				</Mitigation>
			</Potential_Mitigations>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="401"/>
         </Related_Attack_Patterns>
         <Notes>
        <Note Type="Maintenance">This entry is still under development and will continue to see updates and content improvements.</Note>
      </Notes>
			<Content_History>
				<Submission>
					<Submission_Name>CWE Content Team</Submission_Name>
				<Submission_Organization>MITRE</Submission_Organization>
					<Submission_Date>2020-05-28</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Common_Consequences, Description, Modes_of_Introduction, Name, Potential_Mitigations, Related_Attack_Patterns, Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-12-10</Modification_Date>
					<Modification_Comment>updated Potential_Mitigations</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
			<Previous_Entry_Name Date="2020-08-20">Insufficient Physical Protection Mechanism</Previous_Entry_Name>
			</Content_History>
		</Weakness>
      <Weakness ID="1264" Name="Hardware Logic with Insecure De-Synchronization between Control and Data Channels" Abstraction="Base" Structure="Simple" Status="Incomplete">
         <Description>The hardware logic for error handling and security checks can incorrectly forward data before the security check is complete.</Description>
         <Extended_Description>
            <xhtml:p>Many high-performance on-chip bus protocols and processor data-paths employ separate channels for control and data to increase parallelism and maximize throughput. Bugs in the hardware logic that handle errors and security checks can make it possible for data to be forwarded before the completion of the security checks. If the data can propagate to a location in the hardware observable to an attacker, loss of data confidentiality can occur. 'Meltdown' is a concrete example of how de-synchronization between data and permissions checking logic can violate confidentiality requirements. Data loaded from a page marked as privileged was returned to the cpu regardless of current privilege level for performance reasons. The assumption was that the cpu could later remove all traces of this data during the handling of the illegal memory access exception, but this assumption was proven false as traces of the secret data were not removed from the microarchitectural state.</xhtml:p>
         </Extended_Description>
         <Related_Weaknesses>
            <Related_Weakness Nature="ChildOf" CWE_ID="821" View_ID="1000" Ordinal="Primary"/>
            <Related_Weakness Nature="PeerOf" CWE_ID="1037" View_ID="1000"/>
         </Related_Weaknesses>
		 <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Primary</Ordinality>
            </Weakness_Ordinality>
		 </Weakness_Ordinalities>
         <Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
         <Modes_Of_Introduction>
            <Introduction>
               <Phase>Architecture and Design</Phase>
               <Note>The weakness can be introduced in the data transfer or bus protocol itself or in the implementation.</Note>
            </Introduction>
            <Introduction>
               <Phase>Implementation</Phase>
            </Introduction>
         </Modes_Of_Introduction>
         <Common_Consequences>
            <Consequence>
               <Scope>Confidentiality</Scope>
               <Impact>Read Memory</Impact>
               <Impact>Read Application Data</Impact>
            </Consequence>
         </Common_Consequences>
         <Potential_Mitigations>
            <Mitigation>
               <Phase>Architecture and Design</Phase>
               <Description>
                 <xhtml:p>Thoroughly verify the data routing logic to ensure that any error handling or security checks effectively block illegal dataflows.</xhtml:p>
               </Description>
            </Mitigation>
         </Potential_Mitigations>
         <Demonstrative_Examples>
            <Demonstrative_Example>
               <Intro_Text>There are several standard on-chip bus protocols used in modern SoCs to allow communication between components. There are a wide variety of commercially available hardware IP implementing the interconnect logic for these protocols. A bus connects components which initiate/request communications such as processors and DMA controllers (bus masters) with peripherals which respond to requests. In a typical system, the privilege level or security designation of the bus master along with the intended functionality of each peripheral determine the security policy specifying which specific bus masters can access specific peripherals.  This security policy (commonly referred to as a bus firewall) can be enforced using separate IP/logic from the actual interconnect responsible for the data routing.</Intro_Text>
                <Example_Code Nature="bad" Language="Other">The firewall and data routing logic becomes de-synchronized due to a hardware logic bug allowing components that should not be allowed to communicate to share data. For example, consider an SoC with two processors. One is being used as a root of trust and can access a cryptographic key storage peripheral. The other processor (application cpu) may run potentially untrusted code and should not access the key store. If the application cpu can issue a read request to the key store which is not blocked due to de-synchronization of data routing and the bus firewall, disclosure of cryptographic keys is possible.</Example_Code>
                <Example_Code Nature="good" Language="Other">All data is correctly buffered inside the interconnect until the firewall has determined that the endpoint is allowed to receive the data.</Example_Code>
            </Demonstrative_Example>
         </Demonstrative_Examples>
         <Observed_Examples>
				<Observed_Example>
					<Reference>CVE-2017-5754</Reference>
					<Description>Systems with microprocessors utilizing speculative execution and indirect branch prediction may allow unauthorized disclosure of information to an attacker with local user access via a side-channel analysis of the data cache.</Description>
					<Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-5754</Link>
				</Observed_Example>
			</Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="233"/>
            <Related_Attack_Pattern CAPEC_ID="663"/>
         </Related_Attack_Patterns>
         <Content_History>
            <Submission>
               <Submission_Name>Nicole Fern</Submission_Name>
               <Submission_Organization>Tortuga Logic</Submission_Organization>
               <Submission_Date>2020-05-22</Submission_Date>
            </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Description, Related_Attack_Patterns</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
         </Content_History>
      </Weakness>
      <Weakness ID="1266" Name="Improper Scrubbing of Sensitive Data from Decommissioned Device" Abstraction="Base" Structure="Simple" Status="Incomplete">
         <Description>The product does not properly provide a capability for the product administrator to remove sensitive data at the time the product is decommissioned.  A scrubbing capability could be missing, insufficient, or incorrect.</Description>
         <Extended_Description>
            <xhtml:p>When a product is decommissioned - i.e., taken out of service - best practices or regulatory requirements may require the administrator to remove or overwrite sensitive data first, i.e. "scrubbing."  Improper scrubbing of sensitive data from a decommissioned device leaves that data vulnerable to acquisition by a malicious actor. Sensitive data may include, but is not limited to, device/manufacturer proprietary information, user/device credentials, network configurations, and other forms of sensitive data.</xhtml:p>
         </Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="404" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
         <Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
         <Modes_Of_Introduction>
            <Introduction>
               <Phase>Architecture and Design</Phase>
            </Introduction>
            <Introduction>
               <Phase>Policy</Phase>
            </Introduction>
            <Introduction>
               <Phase>Implementation</Phase>
            </Introduction>
         </Modes_Of_Introduction>
         <Common_Consequences>
            <Consequence>
               <Scope>Confidentiality</Scope>
               <Impact>Read Memory</Impact>
            </Consequence>
         </Common_Consequences>
         <Potential_Mitigations>
            <Mitigation>
               <Phase>Architecture and Design</Phase>
               <Description>
                 <xhtml:p>Functionality to completely scrub data from a product at the conclusion of its lifecycle should be part of the design phase. Trying to add this function on top of an existing architecture could lead to incomplete removal of sensitive information/data.</xhtml:p>
               </Description>
            </Mitigation>
            <Mitigation>
               <Phase>Policy</Phase>
               <Description>
                 <xhtml:p>The manufacturer should describe the location(s) where sensitive data is stored and the policies and procedures for its removal. This information may be conveyed, for example, in an Administrators Guide or a Statement of Volatility.</xhtml:p>
               </Description>
            </Mitigation>
            <Mitigation>
               <Phase>Implementation</Phase>
               <Description>
                 <xhtml:p>If the capability to wipe sensitive data isn't built-in, the manufacturer may need to provide a utility to scrub sensitive data from storage if that data is located in a place which is non-accessible by the administrator. One example of this could be when sensitive data is stored on an EEPROM for which there is no user/admin interface provided by the system.</xhtml:p>
               </Description>
            </Mitigation>
         </Potential_Mitigations>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="150"/>
            <Related_Attack_Pattern CAPEC_ID="37"/>
            <Related_Attack_Pattern CAPEC_ID="545"/>
            <Related_Attack_Pattern CAPEC_ID="546"/>
         </Related_Attack_Patterns>
         <References>
            <Reference External_Reference_ID="REF-1080"/>
         </References>
         <Notes>
            <Note Type="Maintenance">This entry is still under development and will continue to see updates and content improvements.</Note>
         </Notes>
         <Content_History>
            <Submission>
               <Submission_Name>Paul A. Wortman</Submission_Name>
               <Submission_Organization>Wells Fargo</Submission_Organization>
               <Submission_Date>2020-05-28</Submission_Date>
            </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Potential_Mitigations, Related_Attack_Patterns</Modification_Comment>
				</Modification>
         </Content_History>
      </Weakness>
      <Weakness ID="1267" Name="Policy Uses Obsolete Encoding" Abstraction="Base" Structure="Simple" Status="Draft">
   <Description>The product uses an obsolete encoding mechanism to implement access controls.</Description>
   <Extended_Description>
    <xhtml:p>Within a System-On-a-Chip (SoC), various circuits and hardware engines generate transactions for the purpose of accessing (read/write) assets or performing various actions (e.g., reset, fetch, compute, etc.). Among various types of message information, a typical transaction is comprised of source identity (identifying the originator of the transaction) and a destination identity (routing the transaction to the respective entity). Sometimes the transactions are qualified with a Security Token. This Security Token helps the destination agent decide on the set of allowed actions (e.g., access to an asset for reads and writes). A policy encoder is used to map the bus transactions to Security Tokens that in turn are used as access-controls/protection mechanisms. A common weakness involves using an encoding which is no longer trusted, i.e., an obsolete encoding.</xhtml:p>
   </Extended_Description>
	 <Related_Weaknesses>
		<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
	 </Related_Weaknesses>
   <Applicable_Platforms>
    <Language Class="Language-Independent" Prevalence="Undetermined"/>
    <Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
    <Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
    <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
   </Applicable_Platforms>
   <Modes_Of_Introduction>
    <Introduction>
     <Phase>Architecture and Design</Phase>
     </Introduction>
    <Introduction>
     <Phase>Implementation</Phase>   
    </Introduction>
   </Modes_Of_Introduction>
   <Common_Consequences>
    <Consequence>
     <Scope>Confidentiality</Scope>
     <Scope>Integrity</Scope>
     <Scope>Availability</Scope>
     <Scope>Access Control</Scope>
     <Impact>Modify Memory</Impact>
     <Impact>Read Memory</Impact>
     <Impact>Modify Files or Directories</Impact>
     <Impact>Read Files or Directories</Impact>
     <Impact>DoS: Resource Consumption (Other)</Impact>
     <Impact>Execute Unauthorized Code or Commands</Impact>
     <Impact>Gain Privileges or Assume Identity</Impact>
     <Impact>Bypass Protection Mechanism</Impact>
     <Impact>Reduce Reliability</Impact>
     <Likelihood>High</Likelihood>
    </Consequence>
   </Common_Consequences>
   <Potential_Mitigations>
    <Mitigation>
     <Phase>Architecture and Design</Phase>
     <Phase>Implementation</Phase>
     <Description>
      <xhtml:p>Security Token Decoders should be reviewed for design inconsistency and common weaknesses.</xhtml:p>
      <xhtml:p>Access and programming flows should be tested in both pre-silicon and post-silicon testing.</xhtml:p>
     </Description>
     <Effectiveness>High</Effectiveness>
    </Mitigation>
   </Potential_Mitigations>
   <Demonstrative_Examples>
		<Demonstrative_Example>
      <Intro_Text>
       <xhtml:p>For example, consider a system that has four bus masters. The table below provides bus masters, their Security Tokens, and trust assumptions.</xhtml:p>
       <xhtml:table>
        <xhtml:tr>
         <xhtml:th>Bus Master</xhtml:th>
         <xhtml:th>Security Token Decoding</xhtml:th>
         <xhtml:th>Trust Assumptions</xhtml:th>
        </xhtml:tr>
        <xhtml:tr>
         <xhtml:td>Master_0</xhtml:td>
         <xhtml:td>"00"</xhtml:td>
         <xhtml:td>Untrusted</xhtml:td>
        </xhtml:tr>
        <xhtml:tr>
         <xhtml:td>Master_1</xhtml:td>
         <xhtml:td>"01"</xhtml:td>
         <xhtml:td>Trusted</xhtml:td>
        </xhtml:tr>
        <xhtml:tr>
         <xhtml:td>Master_2</xhtml:td>
         <xhtml:td>"10"</xhtml:td>
         <xhtml:td>Untrusted</xhtml:td>
        </xhtml:tr>
        <xhtml:tr>
         <xhtml:td>Master_3</xhtml:td>
         <xhtml:td>"11"</xhtml:td>
         <xhtml:td>Untrusted</xhtml:td>
        </xhtml:tr>
       </xhtml:table>
       <xhtml:p>The policy encoding is to be defined such that Security Token will be used in implemented access-controls. The bits in the bus transaction that contain Security-Token information are Bus_transaction [15:11]. The assets are the AES-Key registers for encryption or decryption. The key of 128 bits is implemented as a set of four, 32-bit registers.</xhtml:p>
       <xhtml:table>
        <xhtml:tr>
         <xhtml:th>Register</xhtml:th>
         <xhtml:th>Field description</xhtml:th>
        </xhtml:tr>
        <xhtml:tr>
         <xhtml:td>AES_ENC_DEC_KEY_0</xhtml:td>
         <xhtml:td>AES key [0:31] for encryption or decryption, Default 0x00000000</xhtml:td>
        </xhtml:tr>
        <xhtml:tr>
         <xhtml:td>AES_ENC_DEC_KEY_1</xhtml:td>
         <xhtml:td>AES key [32:63] for encryption or decryption, Default 0x00000000</xhtml:td>
        </xhtml:tr>
        <xhtml:tr>
         <xhtml:td>AES_ENC_DEC_KEY_2</xhtml:td>
         <xhtml:td>AES key [64:95] for encryption or decryption, Default 0x00000000</xhtml:td>
        </xhtml:tr>
        <xhtml:tr>
         <xhtml:td>AES_ENC_DEC_KEY_4</xhtml:td>
         <xhtml:td>AES key [96:127] for encryption or decryption, Default 0x00000000</xhtml:td>
        </xhtml:tr>
       </xhtml:table>
       <xhtml:p>Below is an example of a policy encoding scheme inherited from a previous project where all "ODD" numbered Security Tokens are trusted.</xhtml:p>
      </Intro_Text>
      <Example_Code Nature="bad">
        <xhtml:div>If (Bus_transaction[14] == "1")<xhtml:div style="margin-left:10px">Trusted = "1"</xhtml:div>Else<xhtml:div style="margin-left:10px">Trusted = "0"</xhtml:div></xhtml:div>
        <xhtml:div>If (trusted)<xhtml:div style="margin-left:10px">  Allow access to AES-Key registers</xhtml:div>Else<xhtml:div style="margin-left:10px">Deny access to AES-Key registers</xhtml:div></xhtml:div>
      </Example_Code>
		  <Body_Text><xhtml:p>The inherited policy encoding is obsolete and does not work for the new system where an untrusted bus master with an odd Security Token exists in the system, i.e., Master_3 whose Security Token is "11". Based on the old policy, the untrusted bus master (Master_3) has access to the AES-Key registers. To resolve this, a register AES_KEY_ACCESS_POLICY can be defined to provide necessary, access controls:</xhtml:p></Body_Text>
		  <Body_Text>
		    <xhtml:p>New Policy: </xhtml:p>
		    <xhtml:table>
		      <xhtml:tr>
		        <xhtml:td>AES_KEY_ACCESS_POLICY</xhtml:td>
		        <xhtml:td>[31:0] Default 0x00000002 – agent with Security Token "1" has access to AES_ENC_DEC_KEY_0 through AES_ENC_DEC_KEY_4 registers</xhtml:td>
		      </xhtml:tr>
		    </xhtml:table>
		    <xhtml:p>The AES_KEY_ACCESS_POLICY register defines which agents with a Security Token in the transaction can access the AES-key registers. Each bit in this 32-bit register defines a Security Token. There could be a maximum of 32 security Tokens that are allowed access to the AES-key registers. The number of the bit when set (i.e., "1") allows respective action from an agent whose identity matches the number of the bit and, if "0" (i.e., Clear), disallows the respective action to that corresponding agent. Thus, any bus master with Security Token "01" is allowed access to the AES-Key registers. Below is the Pseudo Code for policy encoding:</xhtml:p>
		  </Body_Text>
      <Example_Code Nature="good">
        <xhtml:div>Security_Token[4:0] = Bus_transaction[15:11]</xhtml:div>
        <xhtml:div>If (AES_KEY_ACCESS_POLICY[Security_Token] == "1")<xhtml:div style="margin-left:10px;">Allow access to AES-Key registers</xhtml:div>Else<xhtml:div style="margin-left:10px;">Deny access to AES-Key registers</xhtml:div></xhtml:div>
      </Example_Code>
		</Demonstrative_Example>
   </Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <References>
    <Reference External_Reference_ID="REF-1093"/>
   </References>
   <Content_History>
    <Submission>
     <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
     <Submission_Organization>Intel Corporation</Submission_Organization>
     <Submission_Date>2020-04-18</Submission_Date>
    </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Applicable_Platforms, Demonstrative_Examples, Description, Modes_of_Introduction, Potential_Mitigations</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
   </Content_History>
  </Weakness>
      <Weakness ID="1268" Name="Policy Privileges are not Assigned Consistently Between Control and Data Agents" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>The product's hardware-enforced access control for a particular resource improperly accounts for privilege discrepancies between control and write policies.
			   </Description>
			<Extended_Description>
				<xhtml:p>Integrated circuits and hardware engines may provide access to resources (device-configuration, encryption keys, etc.) belonging to trusted firmware or software modules (commonly set by a BIOS or a bootloader). These accesses are typically controlled and limited by the hardware. Hardware design access control is sometimes implemented using a policy. A policy defines which entity or agent may or may not be allowed to perform an action. When a system implements multiple levels of policies, a control policy may allow direct access to a resource as well as changes to the policies themselves.</xhtml:p>
				<xhtml:p>Resources that include agents in their control policy but not in their write policy could unintentionally allow an untrusted agent to insert itself in the write policy register. Inclusion in the write policy register could allow a malicious or misbehaving agent write access to resources. This action could result in security compromises including leaked information, leaked encryption keys, or modification of device configuration.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
					<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			 </Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
					<Note>This weakness may be introduced during the design of a device when the architect does not comprehensively specify all of the policies required by an agent.</Note>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>This weakness may be introduced during implementation if device policy restrictions do not sufficiently constrain less-privileged clients.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Scope>Access Control</Scope>
					<Impact>Modify Memory</Impact>
					<Impact>Read Memory</Impact>
					<Impact>DoS: Crash, Exit, or Restart</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Bypass Protection Mechanism</Impact>
					<Impact>Read Files or Directories</Impact>
					<Impact>Reduce Reliability</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Phase>Implementation</Phase>
					<Description>Access-control-policy definition and programming flow must be sufficiently tested in pre-silicon and post-silicon testing.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text><xhtml:p>Consider a system with a register for storing an AES key for encryption or decryption. The key is composed of 128 bits implemented as a set of four 32-bit registers. The key registers are resources and registers, AES_KEY_CONTROL_POLICY, AES_KEY_READ_POLICY and AES_KEY_WRITE_POLICY, and are defined to provide necessary, access controls.</xhtml:p>
					<xhtml:p>The control-policy register defines which agents can write to the read-policy and write-policy registers. The read-policy register defines which agents can read the AES-key registers, and write-policy register defines which agents can program or write to those registers. Each 32-bit register can support access control for a maximum of 32 agents. The number of the bit when set (i.e., "1") allows respective action from an agent whose identity matches the number of the bit and, if "0" (i.e., Clear), disallows the respective action to that corresponding agent.</xhtml:p>
					</Intro_Text>
					<Example_Code Nature="bad"><xhtml:table>
<xhtml:tr><xhtml:th>Register</xhtml:th><xhtml:th>Field description</xhtml:th></xhtml:tr>
<xhtml:tr><xhtml:td>AES_ENC_DEC_KEY_0</xhtml:td><xhtml:td>AES key [0:31] for encryption or decryption<xhtml:br/>Default 0x00000000</xhtml:td></xhtml:tr>
<xhtml:tr><xhtml:td>AES_ENC_DEC_KEY_1</xhtml:td><xhtml:td>AES key [32:63] for encryption or decryption<xhtml:br/>Default 0x00000000</xhtml:td></xhtml:tr>
<xhtml:tr><xhtml:td>AES_ENC_DEC_KEY_2</xhtml:td><xhtml:td>AES key [64:95] for encryption or decryption<xhtml:br/>Default 0x00000000</xhtml:td></xhtml:tr>
<xhtml:tr><xhtml:td>AES_ENC_DEC_KEY_3</xhtml:td><xhtml:td>AES key [96:127] for encryption or decryption<xhtml:br/>Default 0x00000000</xhtml:td></xhtml:tr>
<xhtml:tr><xhtml:td>AES_KEY_CONTROL_POLICY</xhtml:td><xhtml:td>[31:0] Default 0x00000018, meaning agent with identities "4" and "3" has read/write access to this register (i.e., AES_KEY_CONTROL_POLICY), AES_KEY_READ_POLICY, and AES_KEY_WRITE_POLICY registers</xhtml:td></xhtml:tr>
<xhtml:tr><xhtml:td>AES_KEY_READ_POLICY</xhtml:td><xhtml:td>[31:0] Default 0x00000002, agent with identity "1" can only read AES_ENC_DEC_KEY_0 through AES_ENC_DEC_KEY_3 registers</xhtml:td></xhtml:tr>
<xhtml:tr><xhtml:td>AES_KEY_WRITE_POLICY</xhtml:td><xhtml:td>[31:0] Default 0x00000004, agent with identity "2" can only write to AES_ENC_DEC_KEY_0 through AES_ENC_DEC_KEY_3 registers</xhtml:td></xhtml:tr>
</xhtml:table></Example_Code>
					<Body_Text><xhtml:p>In the above example, the AES_KEY_CONTROL_POLICY register has agents with identities "4"and "3" in its policy. Assuming the agent with identity "4" is trusted and the agent with identity "3" is untrusted. The untrusted agent "3" can write to AES_KEY_WRITE_POLICY with a value of 0x0000000C thus allowing write access to AES_ENC_DEC_KEY_0 through AES_ENC_DEC_KEY_3 registers.</xhtml:p>
					<xhtml:ol>
<xhtml:li>The AES_KEY_CONTROL_POLICY defines which agents have write access to the AES_KEY_CONTROL_POLICY, AES_KEY_READ_POLICY, and the AES_KEY_WRITE_POLICY registers,</xhtml:li>
<xhtml:li>The AES-key registers can only be read or used by a crypto agent with identity "1" when bit #1 is set.</xhtml:li>
<xhtml:li>The AES-key registers can only be programmed by a trusted firmware with identity "2" when bit #2 is set.</xhtml:li></xhtml:ol>
<xhtml:p>For the above example, the control, read-and-write-policy registers’ values are defined as below.</xhtml:p></Body_Text>
					<Example_Code Nature="good">
<xhtml:table>
<xhtml:tr><xhtml:th>Register</xhtml:th><xhtml:th>Field description</xhtml:th></xhtml:tr>
<xhtml:tr><xhtml:td>AES_KEY_CONTROL_POLICY</xhtml:td><xhtml:td>[31:0] Default 0x00000010, meaning only agents with an identity of "4" have read/write access to this register (i.e., AES_KEY_CONTROL_POLICY), AES_KEY_READ_POLICY, and AES_KEY_WRITE_POLICY registers</xhtml:td></xhtml:tr>
<xhtml:tr><xhtml:td>AES_KEY_READ_POLICY</xhtml:td><xhtml:td>[31:0] Default 0x00000002, meaning only trusted firmware with an identity of "1" can program registers: 
AES_ENC_DEC_KEY_0, AES_ENC_DEC_KEY_1, AES_ENC_DEC_KEY_2, AES_ENC_DEC_KEY_3</xhtml:td></xhtml:tr>
<xhtml:tr><xhtml:td>AES_KEY_WRITE_POLICY</xhtml:td><xhtml:td>[31:0] Default 0x00000004, meaning only trusted firmware with an identity of "2" can program registers: 
AES_ENC_DEC_KEY_0, AES_ENC_DEC_KEY_1, AES_ENC_DEC_KEY_2, AES_ENC_DEC_KEY_3</xhtml:td></xhtml:tr>
</xhtml:table></Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
         </Related_Attack_Patterns>
         <Notes>
                <Note Type="Maintenance">This entry is still under development and will continue to see updates and content improvements.</Note>
            </Notes>
			<Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-02-12</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Description, Modes_of_Introduction, Name, Potential_Mitigations, Related_Attack_Patterns</Modification_Comment>
				</Modification>
			<Previous_Entry_Name Date="2020-08-20">Agents Included in Control Policy are not Contained in Less-Privileged Policy</Previous_Entry_Name>
			</Content_History>
		</Weakness>
      <Weakness ID="1269" Name="Product Released in Non-Release Configuration" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>The product released to market is released in pre-production or manufacturing configuration.</Description>
			<Extended_Description>
				<xhtml:p>Products in the pre-production or manufacturing stages are configured to have many debug hooks and debug capabilities, including but not limited to:</xhtml:p>
				<xhtml:ul>
				<xhtml:li>Ability to override/bypass various cryptographic checks (including authentication, authorization, and integrity)</xhtml:li>
				<xhtml:li>Ability to read/write/modify/dump internal state (including registers and memory)</xhtml:li>
				<xhtml:li>Ability to change system configurations</xhtml:li>
				<xhtml:li>Ability to run hidden or private commands that are not allowed during production (as they expose IP).</xhtml:li></xhtml:ul>
				<xhtml:p>The above is by no means an exhaustive list, but it alludes to the greater capability and the greater state of vulnerability of a product during it's preproduction or manufacturing state.</xhtml:p>
				<xhtml:p>Complexity increases when multiple parties are involved in executing the tests before the final production version. For example, a chipmaker might fabricate a chip and run its own preproduction tests, following which the chip would be delivered to the Original Equipment Manufacturer (OEM), who would now run a second set of different preproduction tests on the same chip. Only after both of these sets of activities are complete, can the overall manufacturing phase be called “complete” and have the “Manufacturing Complete” fuse blown. However, if the OEM forgets to blow the Manufacturing Complete fuse, then the system remains in the manufacturing stage, rendering the system both exposed and vulnerable.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="693" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Name="VHDL" Prevalence="Undetermined"/>
				<Language Name="Verilog" Prevalence="Undetermined"/>
				<Language Class="Compiled" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Other" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
				<Introduction>
					<Phase>Integration</Phase>
				</Introduction>
				<Introduction>
					<Phase>Manufacturing</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Scope>Access Control</Scope>
					<Scope>Accountability</Scope>
					<Scope>Authentication</Scope>
					<Scope>Authorization</Scope>
					<Scope>Non-Repudiation</Scope>
					<Impact>Other</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Ensure that there exists a marker for denoting the Manufacturing Complete stage and that the Manufacturing Complete marker gets updated at the Manufacturing Complete stage (i.e., the Manufacturing Complete fuse gets blown).</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Integration</Phase>
					<Description>Ensure that there exists a marker for denoting the Manufacturing Complete stage and that the Manufacturing Complete marker gets updated at the Manufacturing Complete stage (i.e., the Manufacturing Complete fuse gets blown).</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Manufacturing</Phase>
					<Description>Ensure that there exists a marker for denoting the Manufacturing Complete stage and that the Manufacturing Complete marker gets updated at the Manufacturing Complete stage (i.e., the Manufacturing Complete fuse gets blown).</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>This example shows what happens when a preproduction system is made available for production.</Intro_Text>
					<Example_Code Nature="bad">Suppose the chipmaker has a way of scanning all the internal memory (containing chipmaker-level secrets) during the manufacturing phase, and the way the chipmaker or the Original Equipment Manufacturer (OEM) marks the end of the manufacturing phase is by blowing a Manufacturing Complete fuse. Now, suppose that whoever blows the Manufacturing Complete fuse inadvertently forgets to execute the step to blow the fuse.</Example_Code>
					<Body_Text>An attacker will now be able to scan all the internal memory (containing chipmaker-level secrets).</Body_Text>
					<Example_Code Nature="good">Blow the Manufacturing Complete fuse.</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
			<Observed_Examples>
				<Observed_Example>
					<Reference>CVE-2019-13945</Reference>
					<Description>Regarding SSA-686531, a hardware based manufacturing access on S7-1200 and
S7-200 SMART has occurred. A vulnerability has been identified in SIMATIC S7-1200 CPU family (incl. SIPLUS variants) (All versions), SIMATIC S7-200 SMART CPU family (All versions). There is an access mode used during manufacturing of S7-1200 CPUs that allows additional diagnostic functionality. The security vulnerability could be exploited by an attacker with physical access to the UART interface during boot process. At the time of advisory publication, no public exploitation of this security vulnerability was known.</Description>
					<Link>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-13945</Link>
				</Observed_Example>
				<Observed_Example>
					<Reference>CVE-2018-4251</Reference>
					<Description>Laptops with Intel chipsets were found to be running in Manufacturing Mode. After this information was reported to the OEM, the vulnerability (CVE-2018-4251) was patched disallowing access to the interface.</Description>
					<Link>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-4251</Link>
				</Observed_Example>
			</Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="439"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1103"/>
			</References>
			<Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-05-31</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Description, Related_Attack_Patterns</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1270" Name="Generation of Incorrect Security Tokens" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>The product implements a Security Token mechanism to differentiate what actions are allowed or disallowed when a transaction originates from an entity. However, the Security Tokens generated in the system are incorrect.</Description>
			<Extended_Description>
				<xhtml:p>Systems-On-a-Chip (SoC) (Integrated circuits and hardware engines) implement Security Tokens to differentiate and identify actions originated from various agents. These actions could be "read", "write", "program", "reset", "fetch", "compute", etc. Security Tokens are generated and assigned to every agent on the SoC that is either capable of generating an action or receiving an action from another agent. Every agent could be assigned a unique, Security Token based on its trust level or privileges. Incorrectly generated Security Tokens could result in the same token used for multiple agents or multiple tokens being used for the same agent. This condition could result in a Denial-of-Service (DoS) or the execution of an action that in turn could result in privilege escalation or unintended access.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
        <Related_Weakness Nature="ChildOf" CWE_ID="1294" View_ID="1194" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>	
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Scope>Access Control</Scope>
					<Impact>Modify Files or Directories</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
					<Impact>Bypass Protection Mechanism</Impact>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Read Memory</Impact>
					<Impact>Modify Memory</Impact>
					<Impact>DoS: Crash, Exit, or Restart</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Phase>Implementation</Phase>
					<Description>
						<xhtml:ul>
							<xhtml:li>Generation of Security Tokens should be reviewed for design inconsistency and common weaknesses.</xhtml:li>
							<xhtml:li>Security-Token definition and programming flow should be tested in pre-silicon and post-silicon testing.</xhtml:li>
						</xhtml:ul>
					</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>Consider a system with a register for storing an AES key for encryption or decryption. The key is 128 bits long implemented as a set of four 32-bit registers. The key registers are assets, and register, AES_KEY_ACCESS_POLICY, is defined to provide necessary access controls. The access-policy register defines which agents, using a Security Token, may access the AES-key registers. Each bit in this 32-bit register is used to define a Security Token. There could be a maximum of 32 Security Tokens that are allowed access to the AES-key registers. When set (bit = "1") bit number allows action from an agent whose identity matches that bit number. If Clear (bit = "0") the action is disallowed for the corresponding agent.</Intro_Text>
					
					<Body_Text>Let"s assume the system has two agents: a Main-controller and an Aux-controller. The respective Security Tokens are "1" and "2".
					
					<xhtml:table>		
						<xhtml:tr>			
							<xhtml:th>Register</xhtml:th>
							<xhtml:th>Description</xhtml:th>
							<xhtml:th>Default</xhtml:th>
						</xhtml:tr>		
						<xhtml:tr>			
							<xhtml:td>AES_ENC_DEC_KEY_0</xhtml:td>
							<xhtml:td>AES key [0:31] for encryption or decryption</xhtml:td>
							<xhtml:td>0x00000000</xhtml:td>
						</xhtml:tr>
						<xhtml:tr>
							<xhtml:td>AES_ENC_DEC_KEY_1</xhtml:td>
							<xhtml:td>AES key [32:63] for encryption or decryption</xhtml:td>
							<xhtml:td>0x00000000</xhtml:td>
						</xhtml:tr>	
						<xhtml:tr>
							<xhtml:td>AES_ENC_DEC_KEY_2</xhtml:td>
							<xhtml:td>AES key [64:95] for encryption or decryption</xhtml:td>
							<xhtml:td>0x00000000</xhtml:td>
						</xhtml:tr>	
						<xhtml:tr>
							<xhtml:td>AES_ENC_DEC_KEY_3</xhtml:td>
							<xhtml:td>AES key [96:127] for encryption or decryption</xhtml:td>
							<xhtml:td>0x00000000</xhtml:td>
						</xhtml:tr>	
						<xhtml:tr>
							<xhtml:td>AES_KEY_ACCESS_POLICY</xhtml:td>
							<xhtml:td>AES key access register [31:0]</xhtml:td>
							<xhtml:td>0x00000002</xhtml:td>
						</xhtml:tr>
					</xhtml:table>
				</Body_Text>
					
					<Body_Text>An agent with a Security Token "1" has access to AES_ENC_DEC_KEY_0 through AES_ENC_DEC_KEY_3 registers. As per the above access policy, the AES-Key-access policy allows access to the AES-key registers if the security Token is "1".</Body_Text>
					
					<Example_Code Nature="bad" Language="Other">The SoC incorrectly generates Security Token "1" for every agent. In other words, both Main-controller and Aux-controller are assigned Security Token "1".</Example_Code>
					<Body_Text>Both agents have access to the AES-key registers.</Body_Text>
					<Example_Code Nature="good" Language="Other">The SoC should correctly generate Security Tokens, assigning "1" to the Main-controller and "2" to the Aux-controller </Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="180"/>
            <Related_Attack_Pattern CAPEC_ID="633"/>
         </Related_Attack_Patterns>
         <Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-03-06</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Applicable_Platforms, Demonstrative_Examples, Description, Modes_of_Introduction, Name, Potential_Mitigations, Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
			<Previous_Entry_Name Date="2020-08-20">Generation of Incorrect Security Identifiers</Previous_Entry_Name>
			</Content_History>
		</Weakness>
      <Weakness ID="1271" Name="Uninitialized Value on Reset for Registers Holding Security Settings" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>Security-critical logic is not set to a known value on reset.</Description>
			<Extended_Description>
				<xhtml:p>When the device is first brought out of reset, the state of registers will be indeterminate if they have not been initialized by the logic. Before the registers are initialized, there will be a window during which the device is in an insecure state and may be vulnerable to attack.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="665" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
		 <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Primary</Ordinality>
            </Weakness_Ordinality>
		 </Weakness_Ordinalities>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Access Control</Scope>
					<Scope>Authentication</Scope>
					<Scope>Authorization</Scope>
					<Impact>Varies by Context</Impact>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Design checks should be performed to identify any uninitialized flip-flops used for security-critical functions.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>All registers holding security-critical information should be set to a specific value on reset.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>Shown below is a positive clock edge triggered flip-flop used to implement a lock bit for test and debug interface. When the circuit is first brought out of reset, the state of the flip-flop will be unknown until the enable input and D-input signals update the flip-flop state. In this example, an attacker can reset the device until the test and debug interface is unlocked and access the test interface until the lock signal is driven to a known state by the logic.</Intro_Text>
					<Example_Code Nature="bad" Language="Other">
					    <xhtml:div>always @(posedge clk) begin
					    <xhtml:div style="margin-left:10px;">if (en) lock_jtag &lt;= d;</xhtml:div>
					    end</xhtml:div>
					</Example_Code>
					<Body_Text>The flip-flop can be set to a known value (0 or 1) on reset, but requires that the logic explicitly update the output of the flip-flop if the reset signal is active.</Body_Text>
					<Example_Code Nature="good" Language="Other">
					    <xhtml:div>always @(posedge clk) begin
					    <xhtml:div style="margin-left:10px;">   if (~reset) lock_jtag &lt;= 0;</xhtml:div>
					    <xhtml:div style="margin-left:10px;">   else if (en) lock_jtag &lt;= d;</xhtml:div>
					    end</xhtml:div>
					</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="74"/>
         </Related_Attack_Patterns>
         <Notes>
                <Note Type="Maintenance">This entry is still under development and will continue to see updates and content improvements.</Note>
            </Notes>
			<Content_History>
				<Submission>
					<Submission_Name>Nicole Fern</Submission_Name>
				<Submission_Organization>Tortuga Logic</Submission_Organization>
					<Submission_Date>2020-05-15</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Common_Consequences, Demonstrative_Examples, Description, Modes_of_Introduction, Name, Potential_Mitigations, Related_Attack_Patterns, Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Name, Type</Modification_Comment>
				</Modification>
			<Previous_Entry_Name Date="2020-08-20">Missing Known Value on Reset for Registers Holding Security Settings</Previous_Entry_Name>
			<Previous_Entry_Name Date="2021-03-15">Unitialized Value on Reset for Registers Holding Security Settings</Previous_Entry_Name>
			</Content_History>
		</Weakness>
      <Weakness ID="1272" Name="Sensitive Information Uncleared Before Debug/Power State Transition" Abstraction="Base" Structure="Simple" Status="Stable">
			<Description>The product performs a power or debug state transition, but it does not clear sensitive information that should no longer be accessible due to changes to information access restrictions.</Description>
			<Extended_Description>
				<xhtml:p>A device or system frequently employs many power and sleep states during its normal operation (e.g., normal power, additional power, low power, hibernate, deep sleep, etc.). A device also may be operating within a debug condition. State transitions can happen from one power or debug state to another. If there is information available in the previous state which should not be available in the next state and is not properly removed before the transition into the next state, sensitive information may leak from the system.</xhtml:p>
			</Extended_Description>
     <Related_Weaknesses>
      <Related_Weakness Nature="ChildOf" CWE_ID="226" View_ID="1000" Ordinal="Primary"/>
      <Related_Weakness Nature="CanPrecede" CWE_ID="200" View_ID="1000" Ordinal="Primary"/>
     </Related_Weaknesses>
		 <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Primary</Ordinality>
            </Weakness_Ordinality>
		 </Weakness_Ordinalities>
			<Applicable_Platforms>
				<Language Name="VHDL" Prevalence="Undetermined"/>
				<Language Name="Verilog" Prevalence="Undetermined"/>
				<Language Class="Compiled" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Scope>Access Control</Scope>
					<Scope>Accountability</Scope>
					<Scope>Authentication</Scope>
					<Scope>Authorization</Scope>
					<Scope>Non-Repudiation</Scope>
					<Impact>Read Memory</Impact>
					<Impact>Read Application Data</Impact>
					<Likelihood>High</Likelihood>
					<Note>Sensitive information may be used to unlock additional capabilities of the device and take advantage of hidden functionalities which could be used to compromise device security.</Note>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
			  <Detection_Method>
			    <Method>Manual Analysis</Method>
			    <Description>Write a known pattern into each sensitive location. Enter the power/debug state in question. Read data back from the sensitive locations. If the reads are successful, and the data is the same as the pattern that was originally written, the test fails and the device needs to be fixed. Note that this test can likely be automated.</Description>
			    <Effectiveness>High</Effectiveness>
			  </Detection_Method>
			</Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Phase>Implementation</Phase>
					<Description>During state transitions, information not needed in the next state should be removed before the transition to the next state.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
       <Demonstrative_Example Demonstrative_Example_ID="DX-147">
	 <Intro_Text>This example shows how an attacker can take advantage of an incorrect state transition.</Intro_Text>
	 <Body_Text>
	   <xhtml:p>Suppose a device is transitioning from state A to state B. During state A, it can read certain private keys from the hidden fuses that are only accessible in state A but not in state B. The device reads the keys, performs operations using those keys, then transitions to state B, where those private keys should no longer be accessible.</xhtml:p>
	 </Body_Text>
	 <Example_Code Nature="bad">
	   <xhtml:p>During the transition from A to B, the device does not scrub the memory.</xhtml:p>
	 </Example_Code>
	 <Body_Text><xhtml:p>After the transition to state B, even though the private keys are no longer accessible directly from the fuses in state B, they can be accessed indirectly by reading the memory that contains the private keys.</xhtml:p></Body_Text>
	 <Example_Code Nature="good">For transition from state A to state B, remove information which should not be available once the transition is complete.</Example_Code>
       </Demonstrative_Example>
     </Demonstrative_Examples>
			<Observed_Examples>
			  <Observed_Example>
				<Reference>CVE-2020-12926</Reference>
				<Description>Product software does not set a flag as per TPM specifications, thereby preventing a failed authorization attempt from being recorded after a loss of power.</Description>
				<Link>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-12926</Link>
			  </Observed_Example>
			</Observed_Examples>
		<Functional_Areas>
            <Functional_Area>Power</Functional_Area>
        </Functional_Areas>
		 <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="150"/>
            <Related_Attack_Pattern CAPEC_ID="37"/>
            <Related_Attack_Pattern CAPEC_ID="545"/>
            <Related_Attack_Pattern CAPEC_ID="546"/>
         </Related_Attack_Patterns>
         <References>
		   <Reference External_Reference_ID="REF-1220"/>
		 </References>
         <Content_History>
				<Submission>
					<Submission_Name>Parbati Kumar Manna, Hareesh Khattri, Arun Kanuparthi</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-05-31</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Applicable_Platforms, Common_Consequences, Demonstrative_Examples, Description, Name, Potential_Mitigations, Related_Attack_Patterns, Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Functional_Areas</Modification_Comment>
				</Modification>
			<Previous_Entry_Name Date="2020-08-20">Debug/Power State Transitions Leak Information</Previous_Entry_Name>
			</Content_History>
		</Weakness>
      <Weakness ID="1273" Name="Device Unlock Credential Sharing" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>The credentials necessary for unlocking a device are shared across multiple parties and may expose sensitive information.</Description>
			<Extended_Description>
				<xhtml:p>“Unlocking a device” often means activating certain, unadvertised, debug and manufacturer-specific capabilities of a device using sensitive credentials. Unlocking a device might be necessary for the purpose of troubleshooting device problems. For example, suppose a device contains the ability to dump the content of the full system memory by disabling the memory-protection mechanisms. Since this is a highly security-sensitive capability, this capability is “locked” in the production part. Unless the device gets unlocked by supplying the proper credentials the debug capabilities are not available. For cases where the chip designer, chip manufacturer (fabricator), and manufacturing and assembly testers are the all employed by the same company, the compromise of the credentials are greatly reduced. However, when the chip designer is employed by one company, the chip manufacturer is employed by another company (a foundry), and the assemblers and testers are employed by yet a third company. Since these different companies will need to perform various tests on the device to verify correct device function, they all need to share the unlock key. Unfortunately, the level of secrecy and policy might be quite different at each company, greatly increasing the risk of sensitive credentials being compromised.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="200" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Name="VHDL" Prevalence="Undetermined"/>
				<Language Name="Verilog" Prevalence="Undetermined"/>
				<Language Class="Compiled" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Other" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Integration</Phase>
				</Introduction>
				<Introduction>
					<Phase>Manufacturing</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Scope>Access Control</Scope>
					<Scope>Accountability</Scope>
					<Scope>Authentication</Scope>
					<Scope>Authorization</Scope>
					<Scope>Non-Repudiation</Scope>
					<Impact>Modify Memory</Impact>
					<Impact>Read Memory</Impact>
					<Impact>Modify Files or Directories</Impact>
					<Impact>Read Files or Directories</Impact>
					<Impact>Modify Application Data</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Bypass Protection Mechanism</Impact>
					<Note>Once unlock credentials are compromised, an attacker can use the credentials to unlock the device and gain unauthorized access to the hidden functionalities protected by those credentials.</Note>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Integration</Phase>
					<Description>Ensure the unlock credentials are shared with the minimum number of parties and with utmost secrecy. To limit the risk associated with compromised credentials, where possible, the credentials should be part-specific.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Manufacturing</Phase>
					<Description>Ensure the unlock credentials are shared with the minimum number of parties and with utmost secrecy. To limit the risk associated with compromised credentials, where possible, the credentials should be part-specific.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>This example shows how an attacker can take advantage of compromised credentials.</Intro_Text>
					<Example_Code Nature="bad">Suppose a semiconductor chipmaker, “C”, uses the foundry “F” for fabricating its chips. Now, F has many other customers in addition to C, and some of the other customers are much smaller companies. F has dedicated teams for each of its customers, but somehow it mixes up the unlock credentials and sends the unlock credentials of C to the wrong team. This other team does not take adequate precautions to protect the credentials that have nothing to do with them, and eventually the unlock credentials of C get leaked.</Example_Code>
					<Body_Text>When the credentials of multiple organizations are stored together, exposure to third parties occurs frequently.</Body_Text>
					<Example_Code Nature="good">Vertical integration of a production company is one effective method of protecting sensitive credentials. Where vertical integration is not possible, strict access control and need-to-know are methods which can be implemented to reduce these risks.</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="560"/>
         </Related_Attack_Patterns>
         <Notes>
                <Note Type="Maintenance">This entry is still under development and will continue to see updates and content improvements.</Note>
            </Notes>
			
			<Content_History>
				<Submission>
					<Submission_Name>Parbati Kumar Manna, Hareesh Khattri, Arun Kanuparthi</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-05-29</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Description, Related_Attack_Patterns</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1274" Name="Improper Access Control for Volatile Memory Containing Boot Code" Abstraction="Base" Structure="Simple" Status="Stable">
			<Description>The product conducts a secure-boot process that transfers bootloader code from Non-Volatile Memory (NVM) into Volatile Memory (VM), but it does not have sufficient access control or other protections for the Volatile Memory.</Description>
			<Extended_Description>
			  <xhtml:p>Adversaries could bypass the secure-boot process and execute their own untrusted, malicious boot code.</xhtml:p>
			  <xhtml:p>As a part of a secure-boot process, the read-only-memory (ROM) code for a System-on-Chip (SoC) or other system fetches bootloader code from Non-Volatile Memory (NVM) and stores the code in Volatile Memory (VM), such as dynamic, random-access memory (DRAM) or static, random-access memory (SRAM). The NVM is usually external to the SoC, while the VM is internal to the SoC. As the code is transferred from NVM to VM, it is authenticated by the SoC's ROM code.</xhtml:p>
			  <xhtml:p>If the volatile-memory-region protections or access controls are insufficient to prevent modifications from an adversary or untrusted agent, the secure boot may be bypassed or replaced with the execution of an adversary's code.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
		 <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Primary</Ordinality>
            </Weakness_Ordinality>
		 </Weakness_Ordinalities>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
					<Note>This weakness can be introduced during hardware architecture or design but can be identified later during testing.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Access Control</Scope>
					<Scope>Integrity</Scope>
					<Impact>Modify Memory</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
			  <Detection_Method>
			    <Method>Manual Analysis</Method>
			    <Description>Ensure the volatile memory is lockable or has locks. Ensure the volatile memory is locked for writes from untrusted agents or adversaries. Try modifying the volatile memory from an untrusted agent, and ensure these writes are dropped.
			     </Description>
			    <Effectiveness>High</Effectiveness>
			  </Detection_Method>
			  <Detection_Method>
			    <Method>Manual Analysis</Method>
			    <Description>
			      <xhtml:p>Analyze the device using the following steps:</xhtml:p>
			      <xhtml:ul>
				<xhtml:li>1) Identify all fabric master agents that are active during system Boot Flow when initial code is loaded from Non-volatile storage to volatile memory.</xhtml:li>
				<xhtml:li>2) Identify the volatile memory regions that are used for storing loaded system executable program.</xhtml:li>
				<xhtml:li>3) During system boot, test programming the identified memory regions in step 2 from all the masters identified in step 1.</xhtml:li>
			      </xhtml:ul>
			      <xhtml:p>Only trusted masters should be allowed to write to the memory regions. For example, pluggable device peripherals should not have write access to program load memory regions.</xhtml:p>
			    </Description>
			    <Effectiveness>Moderate</Effectiveness>
			  </Detection_Method>
			</Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Ensure that the design of volatile-memory protections is enough to prevent modification from an adversary or untrusted code.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Testing</Phase>
					<Description>Test the volatile-memory protections to ensure they are safe from modification or untrusted code.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>A typical SoC secure boot's flow includes fetching the next piece of code (i.e., the boot loader) from NVM (e.g., serial, peripheral interface (SPI) flash), and transferring it to DRAM/SRAM volatile, internal memory, which is more efficient.</Intro_Text>
					<Example_Code Nature="bad">The volatile-memory protections or access controls are insufficient.</Example_Code>
					<Body_Text>The memory from where the boot loader executes can be modified by an adversary.</Body_Text>
					<Example_Code Nature="good">A good architecture should define appropriate protections or access controls to prevent modification by an adversary or untrusted agent, once the bootloader is authenticated.</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
			<Observed_Examples>
				<Observed_Example>
					<Reference>CVE-2019-2267</Reference>
					<Description>Locked memory regions may be modified through other interfaces in a secure-boot-loader image due to improper access control.</Description>
					<Link>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-2267</Link>
				</Observed_Example>
			</Observed_Examples>
			<Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-04-25</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Description, Related_Attack_Patterns</Modification_Comment>
				</Modification>
				<Contribution Type="Feedback">
				  <Contribution_Name>Narasimha Kumar V Mangipudi</Contribution_Name>
				  <Contribution_Organization>Lattice Semiconductor</Contribution_Organization>
				  <Contribution_Date>2021-10-20</Contribution_Date>
				  <Contribution_Comment>suggested content improvements</Contribution_Comment>
				</Contribution>
				<Contribution Type="Content">
				  <Contribution_Name>Hareesh Khattri</Contribution_Name>
				  <Contribution_Organization>Intel Corporation</Contribution_Organization>
				  <Contribution_Date>2021-10-22</Contribution_Date>
				  <Contribution_Comment>provided detection method</Contribution_Comment>
				</Contribution>
			</Content_History>
		</Weakness>
      <Weakness ID="1276" Name="Hardware Child Block Incorrectly Connected to Parent System" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>Signals between a hardware IP and the parent system design are incorrectly connected causing security risks.</Description>
			<Extended_Description>
				<xhtml:p>Individual hardware IP must communicate with the parent system in order for the product to function correctly and as intended. If implemented incorrectly, while not causing any apparent functional issues, may cause security issues. For example, if the IP should only be reset by a system-wide hard reset, but instead the reset input is connected to a software-triggered debug mode reset (which is also asserted during a hard reset), integrity of data inside the IP can be violated.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>This weakness is introduced when integrating IP into a parent design.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Impact>Varies by Context</Impact>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Testing</Phase>
					<Description>System-level verification may be used to ensure that components are correctly connected and that design security requirements are not violated due to interactions between various IP blocks.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>Many SoCs use hardware to partition system resources between trusted and un-trusted entities. One example of this concept is the Arm TrustZone, in which the processor and all security-aware IP attempt to isolate resources based on the status of a privilege bit. This privilege bit is part of the input interface in all TrustZone-aware IP. If this privilege bit is accidentally grounded or left unconnected when the IP is instantiated, privilege escalation of all input data may occur.</Intro_Text>
					<Example_Code Nature="bad" Language="Verilog">
					
					<xhtml:p>// IP definition</xhtml:p>
					<xhtml:p>module tz_peripheral(clk, reset, data_in, data_in_security_level, ...);</xhtml:p>
					<xhtml:p style="text-indent: 15px;">input clk, reset;</xhtml:p>
					<xhtml:p style="text-indent: 15px;">input [31:0] data_in;</xhtml:p>
					<xhtml:p style="text-indent: 15px;">input data_in_security_level;</xhtml:p>
					<xhtml:p style="text-indent: 15px;">...</xhtml:p>
					<xhtml:p>endmodule</xhtml:p>
					<xhtml:p>// Instantiation of IP in a parent system</xhtml:p>
					<xhtml:p>module soc(...)</xhtml:p>
					<xhtml:p style="text-indent: 15px;">...</xhtml:p>
					<xhtml:p style="text-indent: 15px;">tz_peripheral u_tz_peripheral(</xhtml:p>
					<xhtml:p style="text-indent: 30px;">.clk(clk),</xhtml:p>
					<xhtml:p style="text-indent: 30px;">.rst(rst),</xhtml:p>
					<xhtml:p style="text-indent: 30px;">.data_in(rdata),</xhtml:p>
					<xhtml:p style="text-indent: 30px;">//Copy-and-paste error or typo grounds data_in_security_level (in this example 0=secure, 1=non-secure) effectively promoting all data to “secure”)</xhtml:p>
					<xhtml:p style="text-indent: 30px;">.data_in_security_level(1'b0),</xhtml:p>
					<xhtml:p style="text-indent: 15px;">);</xhtml:p>
					<xhtml:p style="text-indent: 15px;">...</xhtml:p>
					<xhtml:p>endmodule</xhtml:p>
					</Example_Code>
					<Body_Text>In the Verilog code below, the security level input to the TrustZone aware peripheral is correctly driven by an appropriate signal instead of being grounded.</Body_Text>
					<Example_Code Nature="good" Language="Verilog">
					<xhtml:p>// Instantiation of IP in a parent system</xhtml:p>
					<xhtml:p>module soc(...)</xhtml:p>
					<xhtml:p style="text-indent: 15px;">...</xhtml:p>
					<xhtml:p style="text-indent: 15px;">tz_peripheral u_tz_peripheral(</xhtml:p>
					<xhtml:p style="text-indent: 30px;">.clk(clk),</xhtml:p>
					<xhtml:p style="text-indent: 30px;">.rst(rst),</xhtml:p>
					<xhtml:p style="text-indent: 30px;">.data_in(rdata),</xhtml:p>
					<xhtml:p style="text-indent: 30px;">// This port is no longer grounded, but instead drive by the appropriate signal</xhtml:p>
					<xhtml:p style="text-indent: 30px;">.data_in_security_level(rdata_security_level),</xhtml:p>
					<xhtml:p style="text-indent: 15px;">);</xhtml:p>
					<xhtml:p style="text-indent: 15px;">...</xhtml:p>
					<xhtml:p>endmodule</xhtml:p>
					</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
			<Content_History>
				<Submission>
					<Submission_Name>Nicole Fern</Submission_Name>
					<Submission_Organization>Tortuga Logic</Submission_Organization>
					<Submission_Date>2020-05-22</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Description, Modes_of_Introduction, Name, Potential_Mitigations</Modification_Comment>
				</Modification>
			<Previous_Entry_Name Date="2020-08-20">Hardware Block Incorrectly Connected to Larger System</Previous_Entry_Name>
			</Content_History>
		</Weakness>
      <Weakness ID="1277" Name="Firmware Not Updateable" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>The product does not provide its
			users with the ability to update or patch its
			firmware to address any vulnerabilities or
			weaknesses that may be present.</Description>
			<Extended_Description>Without the ability to
			patch or update firmware, consumers will be
			left vulnerable to exploitation of any known
			vulnerabilities, or any vulnerabilities that
			are discovered in the future. This can expose
			consumers to permanent risk throughout the
			entire lifetime of the device, which could be
			years or decades. Some external protective
			measures and mitigations might be employed to
			aid in preventing or reducing the risk of
			malicious attack, but the root weakness cannot
			be corrected.</Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="1329" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
		 <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Primary</Ordinality>
            </Weakness_Ordinality>
		 </Weakness_Ordinalities>
			<Applicable_Platforms>	
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Requirements</Phase>
					<Note>Requirements development might not consider the importance of updates over the lifetime of the product, or might not choose the ability due to concerns such as expense or speed to market.</Note>
				</Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
					<Note>Lack of planning during architecture development and design, or external pressures such as speed to market, could ignore the capability to update.</Note>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>The weakness can appear through oversight during implementation.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Access Control</Scope>
					<Scope>Authentication</Scope>
					<Scope>Authorization</Scope>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Bypass Protection Mechanism</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
					<Impact>DoS: Crash, Exit, or Restart</Impact>
					<Likelihood>Medium</Likelihood>
					<Note>If an attacker can identify an exploitable vulnerability in one device that has no means of patching, the attack may be used against an entire class of devices.</Note>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
			  <Detection_Method>
			    <Method>Manual Analysis</Method>
			    <Description>Create a new installable boot image of the current build with a minor version number change. Use the standard installation method to update the boot image. Verify that the minor version number has changed. Create a fake image. Verify that the boot updater will not install the fake image and generates an invalid image error message.</Description>
			    <Effectiveness>High</Effectiveness>
			  </Detection_Method>
			  <Detection_Method>
			    <Method>Architecture or Design Review</Method>
			    <Description>Check the consumer or maintainer documentation, the architecture/design documentation, or the original requirements to ensure that the documentation includes details for how to update the firmware.</Description>
			    <Effectiveness>Moderate</Effectiveness>
			  </Detection_Method>
			  <Detection_Method>
			    <Method>Manual Dynamic Analysis</Method>
			    <Description>Determine if there is a lack of a capability to update read-only memory structure. This could manifest as a difference between the latest firmware version and current version within the device.</Description>
			    <Effectiveness>High</Effectiveness>
			  </Detection_Method>
			</Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Requirements</Phase>
					<Description>Specify requirements to provide the ability to update the firmware.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Design the device to allow for updating the firmware.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Implement the necessary functionality to allow the firmware to be updated.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example Demonstrative_Example_ID="DX-145">
					<Intro_Text>A refrigerator has an Internet interface for the official purpose of alerting the manufacturer when that refrigerator detects a fault. Because the device is attached to the Internet, the refrigerator is a target for hackers who may wish to use the device other potentially more nefarious purposes.</Intro_Text>
					<Example_Code Nature="bad" Language="Other">The refrigerator has no means of patching and is hacked becoming a spewer of email spam.</Example_Code>
					<Example_Code Nature="good" Language="Other">The device automatically patches itself and provides considerable more protection against being hacked.</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
			<Observed_Examples>
      			  <Observed_Example>
        		    <Reference>CVE-2020-9054</Reference>
        		    <Description>Chain: network-attached storage (NAS) device has a critical OS command injection (CWE-78) vulnerability that is actively exploited to place IoT devices into a botnet, but some products are "end-of-support" and cannot be patched (CWE-1277). [REF-1097]</Description>
        		    <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-9054</Link>
      			  </Observed_Example>
			  <Observed_Example>
			    <Reference>REF-1095</Reference>
			    <Description>hardware "smart lock" has weak key generation, allowing attackers to steal the key by BLE sniffing, but the device's firmware cannot be upgraded [REF-1095].</Description>
			    <Link>https://www.theregister.com/2019/12/11/f_secure_keywe/</Link>
      			  </Observed_Example>
      			</Observed_Examples>
			<References>
				<Reference External_Reference_ID="REF-1095"/>
				<Reference External_Reference_ID="REF-1096"/>
				<Reference External_Reference_ID="REF-1097"/>
			</References>
			<Notes>
                <Note Type="Terminology">The "firmware" term does not have a single commonly-shared definition, so there may be variations in how this CWE entry is interpreted during mapping.</Note>
            </Notes>
			<Content_History>
				<Submission>
					<Submission_Name>Paul A. Wortman</Submission_Name>
					<Submission_Organization>Wells Fargo</Submission_Organization>
					<Submission_Date>2020-05-13</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Common_Consequences, Demonstrative_Examples, Description, Potential_Mitigations</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-12-10</Modification_Date>
					<Modification_Comment>updated Description, Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Maintenance_Notes</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Maintenance_Notes</Modification_Comment>
				</Modification>
            <Contribution Type="Content">
	      <Contribution_Name>Paul A. Wortman</Contribution_Name>
               <Contribution_Organization>Wells Fargo</Contribution_Organization>
               <Contribution_Date>2021-10-12</Contribution_Date>
               <Contribution_Comment>provided detection methods and observed examples</Contribution_Comment>
            </Contribution>
			</Content_History>
		</Weakness>
      <Weakness ID="1278" Name="Missing Protection Against Hardware Reverse Engineering Using Integrated Circuit (IC) Imaging Techniques" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>Information stored in hardware may be recovered by an attacker with the capability to capture and analyze images of the integrated circuit using techniques such as scanning electron microscopy.</Description>
			<Extended_Description>
				<xhtml:p>The physical structure of a device, viewed at high enough magnification, can reveal the information stored inside. Typical steps in IC reverse engineering involve removing the chip packaging (decapsulation) then using various imaging techniques ranging from high resolution x-ray microscopy to invasive techniques involving removing IC layers and imaging each layer using a scanning electron microscope.</xhtml:p>
				<xhtml:p>The goal of such activities is to recover secret keys, unique device identifiers, and proprietary code and circuit designs embedded in hardware that the attacker has been unsuccessful at accessing through other means. These secrets may be stored in non-volatile memory or in the circuit netlist. Memory technologies such as masked ROM allow easier to extraction of secrets than One-time Programmable (OTP) memory.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="693" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Impact>Varies by Context</Impact>
					<Note>A common goal of malicious actors who reverse engineer ICs is to produce and sell counterfeit versions of the IC.</Note>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>The cost of secret extraction via IC reverse engineering should outweigh the potential value of the secrets being extracted. Threat model and value of secrets should be used to choose the technology used to safeguard those secrets. Examples include IC camouflaging and obfuscation, tamper-proof packaging, active shielding, and physical tampering detection information erasure.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>Consider an SoC design that embeds a secret key in read-only memory (ROM). The key is baked into the design logic and may not be modified after fabrication causing the key to be identical for all devices.  An attacker in possession of the IC can decapsulate and delayer the device. After imaging the layers, computer vision algorithms or manual inspection of the circuit features locate the ROM and reveal the value of the key bits as encoded in the visible circuit structure of the ROM.</Intro_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="37"/>
            <Related_Attack_Pattern CAPEC_ID="545"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1092"/>
				<Reference External_Reference_ID="REF-1129"/>
			</References>
            <Notes>
			    <Note Type="Maintenance">This entry is still under development and will continue to see updates and content improvements. It is more attack-oriented, so it might be more suited for CAPEC.</Note>
			</Notes>
			<Content_History>
				<Submission>
					<Submission_Name>Nicole Fern</Submission_Name>
					<Submission_Organization>Tortuga Logic</Submission_Organization>
					<Submission_Date>2020-05-20</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Description, Modes_of_Introduction, Potential_Mitigations, References, Related_Attack_Patterns</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Maintenance_Notes</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1279" Name="Cryptographic Operations are run Before Supporting Units are Ready" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>Performing cryptographic operations without ensuring that the supporting inputs are ready to supply valid data may compromise the cryptographic result.</Description>
			<Extended_Description>Many cryptographic hardware units depend upon other hardware units to supply information to them to produce a securely encrypted result. For example, a cryptographic unit that depends on an external random-number-generator (RNG) unit for entropy must wait until the RNG unit is producing random numbers. If a cryptographic unit retrieves a private encryption key from a fuse unit, the fuse unit must be up and running before a key may be supplied.
			</Extended_Description>
			<Related_Weaknesses>
			 <Related_Weakness Nature="ChildOf" CWE_ID="665" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Name="Verilog" Prevalence="Undetermined"/>
				<Language Name="VHDL" Prevalence="Undetermined"/>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Processor IP" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>The decision to continue using a cryptographic unit even though the input units to it are not producing valid data will compromise the encrypted result.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Access Control</Scope>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Scope>Accountability</Scope>
					<Scope>Authentication</Scope>
					<Scope>Authorization</Scope>
					<Scope>Non-Repudiation</Scope>
					<Impact>Varies by Context</Impact>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Best practices should be used to design cryptographic systems.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Continuously ensuring that cryptographic inputs are supplying valid information is necessary to ensure that the encrypted output is secure. </Description>
				</Mitigation>
			
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>The following pseudocode illustrates the weak encryption resulting from the use of a pseudo-random-number generator output. </Intro_Text>
					<Example_Code Nature="bad" Language="Other">
					
					<xhtml:p>If random_number_generator_self_test_passed() == TRUE</xhtml:p>
					<xhtml:p>then Seed = get_random_number_from_RNG()</xhtml:p>
					<xhtml:p>else Seed = hardcoded_number</xhtml:p>
					
					</Example_Code>
					<Body_Text>In the example above, first a check of RNG ready is performed. If the check fails, the RNG is ignored and a hard coded value is used instead. The hard coded value severely weakens the encrypted output. </Body_Text>
					<Example_Code Nature="good" Language="Other">
					<xhtml:p>If random_number_generator_self_test_passed() == TRUE</xhtml:p>
					<xhtml:p>then Seed = get_random_number_from_RNG()</xhtml:p>
					<xhtml:p>else enter_error_state()</xhtml:p>	
					</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="97"/>
         </Related_Attack_Patterns>
         <Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-02-12</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Common_Consequences, Demonstrative_Examples, Description, Maintenance_Notes, Modes_of_Introduction, Name, Potential_Mitigations, Related_Attack_Patterns</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Maintenance_Notes</Modification_Comment>
				</Modification>
			<Previous_Entry_Name Date="2020-08-20">Cryptographic Primitives used without Successful Self-Test</Previous_Entry_Name>
			</Content_History>
		</Weakness>
      <Weakness ID="1280" Name="Access Control Check Implemented After Asset is Accessed" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>A product's hardware-based access control check occurs after the asset has been accessed.</Description>
			<Extended_Description>
				<xhtml:p>The product implements a hardware-based access control check. The asset should be accessible only after the check is successful. If, however, this operation is not atomic and the asset is accessed before the check is complete, the security of the system may be compromised.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
                <Related_Weakness Nature="ChildOf" CWE_ID="696" View_ID="1000" Ordinal="Primary"/>
                <Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000"/>
            </Related_Weaknesses>
			<Applicable_Platforms>
				<Language Name="Verilog" Prevalence="Undetermined"/>
				<Language Name="VHDL" Prevalence="Undetermined"/>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Access Control</Scope>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Impact>Modify Memory</Impact>
					<Impact>Read Memory</Impact>
					<Impact>Modify Application Data</Impact>
					<Impact>Read Application Data</Impact>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Bypass Protection Mechanism</Impact>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Implement the access control check first. Access should only be given to asset if agent is authorized. </Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>Assume that the module foo_bar implements a protected register. The register content is the asset. Only transactions made by user id (indicated by signal usr_id) 0x4 are allowed to modify the register contents. The signal grant_access is used to provide access. </Intro_Text>
					<Example_Code Nature="bad" Language="Verilog">
       					<xhtml:div>module foo_bar(data_out, usr_id, data_in, clk, rst_n);
       					<xhtml:p>output reg [7:0] data_out;;</xhtml:p>
       					<xhtml:p>input wire [2:0] usr_id;</xhtml:p>
       					<xhtml:p>input wire [7:0] data_in; </xhtml:p>
       					<xhtml:p>input wire clk, rst_n;</xhtml:p>
       					<xhtml:p>wire grant_access;</xhtml:p>
       					<xhtml:p>always @ (posedge clk or negedge rst_n)</xhtml:p>
       					<xhtml:p>begin</xhtml:p>
       					<xhtml:div style="margin-left:10px">if (!rst_n)<xhtml:br/><xhtml:div style="margin-left:10px">data_out = 0;</xhtml:div>else<xhtml:div style="margin-left:10px">data_out = (grant_access) ? data_in : data_out;<xhtml:br/>assign grant_access = (usr_id == 3’h4) ? 1’b1 : 1’b0;</xhtml:div>end</xhtml:div>endmodule</xhtml:div>
					</Example_Code>
					<Body_Text>This code uses Verilog blocking assignments for data_out and grant_access. Therefore, these assignments happen sequentially (i.e., data_out is updated to new value first, and grant_access is updated the next cycle) and not in parallel. Therefore, the asset data_out is allowed to be modified even before the access control check is complete and grant_access signal is set. Since grant_access does not have a reset value, it will be meta-stable and will randomly go to either 0 or 1.</Body_Text>
					<Example_Code Nature="good" Language="Verilog">
       					<xhtml:p>Flipping the order of the assignment of data_out and grant_access should solve the problem. The correct snippet of code is shown below.</xhtml:p>
       					<xhtml:div>always @ (posedge clk or negedge rst_n)</xhtml:div>
       					<xhtml:div>begin</xhtml:div>
					    <xhtml:div style="margin-left:10px">if (!rst_n)<xhtml:div style="margin-left:10px">data_out = 0;</xhtml:div>else<xhtml:div style="margin-left:10px">assign grant_access = (usr_id == 3’h4) ? 1’b1 : 1’b0;<xhtml:br/>data_out = (grant_access) ? data_in : data_out;</xhtml:div>end</xhtml:div>
       					<xhtml:div>endmodule</xhtml:div>
					</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-02-12</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Applicable_Platforms, Demonstrative_Examples, Description, Related_Attack_Patterns</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1281" Name="Sequence of Processor Instructions Leads to Unexpected Behavior" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>Specific combinations of processor instructions lead to undesirable behavior such as locking the processor until a hard reset performed.</Description>
			<Extended_Description>
				<xhtml:p>If the instruction set architecture (ISA) and processor logic are not designed carefully, and tested thoroughly, certain combinations of instructions may lead to locking the processor or other unexpected and undesirable behavior.  Upon encountering unimplemented instruction opcodes or illegal instruction operands the processor should throw an exception and carry on without negatively impacting security.  However, specific combinations of legal and illegal instructions may cause unexpected behavior with security implications such as allowing unprivileged programs to completely lock the CPU. 
                </xhtml:p>
				<xhtml:p>Some examples are the Pentium f00f bug, MC6800 HCF, the Cyrix comma bug, and more generally other "Halt and Catch Fire" instructions.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="691" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
					<Note>Unexpected behavior from certain instruction combinations can arise from bugs in the ISA</Note>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>Unexpected behavior from certain instruction combinations can arise because of implementation details such as speculative execution, caching etc.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Impact>Varies by Context</Impact>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Testing</Phase>
					<Description>Implement a rigorous testing strategy that incorporates randomization to explore instruction sequences that are unlikely to appear in normal workloads in order to identify halt and catch fire instruction sequences.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Patching and Maintenance</Phase>
					<Description>Patch operating system to avoid running Halt and Catch Fire type sequences or to mitigate the damage caused by unexpected behavior.  See [REF-1108].</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>The Pentium F00F bug is a real-world example of how a sequence of instructions can lock a processor. The “cmpxchg8b” instruction compares contents of registers with a memory location.  The operand is expected to be a memory location, but in the bad code snippet it is the eax register. Because the specified operand is illegal, an exception is generated, which is the correct behavior and not a security issue in itself. However, when prefixed with the “lock” instruction, the processor deadlocks because locked memory transactions require a read and write pair of transactions to occur before the lock on the memory bus is released. The exception causes a read to occur but there is no corresponding write, as there would have been if a legal operand had been supplied to the cmpxchg8b instruction.</Intro_Text>
					<Example_Code Nature="bad" Language="Other">lock cmpxchg8b eax</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
			<Observed_Examples>
				<Observed_Example>
					<Reference>CVE-1999-1476</Reference>
					<Description>A bug in some Intel Pentium processors allow DoS (hang) via an invalid "CMPXCHG8B" instruction, causing a deadlock</Description>
					<Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-1999-1476</Link>
				</Observed_Example>
			</Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="212"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1094"/>
				<Reference External_Reference_ID="REF-1108"/>
			</References>
			<Content_History>
				<Submission>
					<Submission_Name>Nicole Fern</Submission_Name>
					<Submission_Organization>Tortuga Logic</Submission_Organization>
					<Submission_Date>2020-05-15</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Potential_Mitigations</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Name, Observed_Examples</Modification_Comment>
				</Modification>
			<Previous_Entry_Name Date="2021-07-20">Sequence of Processor Instructions Leads to Unexpected Behavior (Halt and Catch Fire)</Previous_Entry_Name>
			</Content_History>
		</Weakness>
      <Weakness ID="1282" Name="Assumed-Immutable Data is Stored in Writable Memory" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>Immutable data, such as a first-stage bootloader, device identifiers, and "write-once" configuration settings are stored in writable memory that can be re-programmed or updated in the field.</Description>
			<Extended_Description>
				<xhtml:p>Security services such as secure boot, authentication of code and data, and device attestation all require assets such as the first stage bootloader, public keys, golden hash digests, etc. which are implicitly trusted. Storing these assets in read-only memory (ROM), fuses, or one-time programmable (OTP) memory provides strong integrity guarantees and provides a root of trust for securing the rest of the system. Security is lost if assets assumed to be immutable can be modified.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
			 <Related_Weakness Nature="ChildOf" CWE_ID="668" View_ID="1000" Ordinal="Primary"/>
			 <Related_Weakness Nature="CanPrecede" CWE_ID="471" View_ID="1000"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>Keys, code, configuration settings, and other data should be programmed in write-once or read-only memory instead of writable memory.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Integrity</Scope>
					<Impact>Varies by Context</Impact>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>All immutable code or data should be programmed into ROM or write-once memory.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>Cryptographic hash functions are commonly used to create unique fixed-length digests used to ensure the integrity of code and keys. A golden digest is stored on the device and compared to the digest computed from the data to be verified. If the digests match, the data has not been maliciously modified. If an attacker can modify the golden digest they then have the ability to store arbitrary data that passes the verification check. Hash digests used to verify public keys and early stage boot code should be immutable, with the strongest protection offered by hardware immutability.</Intro_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <Notes>
        <Note Type="Maintenance">
          This entry is still under development and will continue to
          see updates and content improvements.
        </Note>
        <Note Type="Maintenance">
		  As of CWE 4.3, CWE-1282 and CWE-1233 are being investigated
		  for potential duplication or overlap.
        </Note>
      </Notes>
			<Content_History>
				<Submission>
					<Submission_Name>Nicole Fern</Submission_Name>
					<Submission_Organization>Tortuga Logic</Submission_Organization>
					<Submission_Date>2020-05-15</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Description, Modes_of_Introduction, Name</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Maintenance_Notes</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
			<Previous_Entry_Name Date="2020-08-20">Assumed-Immutable Data Stored in Writable Memory</Previous_Entry_Name>
			</Content_History>
		</Weakness>
      <Weakness ID="1283" Name="Mutable Attestation or Measurement Reporting Data" Abstraction="Base" Structure="Simple" Status="Incomplete">
         <Description>The register contents used for attestation or measurement reporting data to verify boot flow are modifiable by an adversary.</Description>
         <Extended_Description>
            <xhtml:p>A System-on-Chip (SoC) implements secure boot or verified boot. During this boot flow, the SoC often measures the code that it authenticates. The measurement is usually done by calculating the one-way hash of the code binary and extending it to the previous hash. The hashing algorithm should be a Secure One-Way hash function. The final hash, i.e., the value obtained after the completion of the boot flow, serves as the measurement data used in reporting or in attestation. The calculated hash is often stored in registers that can later be read by the party of interest to determine tampering of the boot flow. A common weakness is that the contents in these registers are modifiable by an adversary, thus spoofing the measurement.</xhtml:p>
         </Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
         <Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
         <Modes_Of_Introduction>
            <Introduction>
               <Phase>Architecture and Design</Phase>
               <Note>Such issues can be introduced during hardware architecture or design and can be identified later during Testing or System Configuration phases.</Note>
            </Introduction>
            <Introduction>
               <Phase>Implementation</Phase>
               <Note>If the access-controls which protecting the reporting registers are misconfigured during implementation, this weakness can arise.</Note>
            </Introduction>
         </Modes_Of_Introduction>
         <Common_Consequences>
                <Consequence>
               <Scope>Confidentiality</Scope>
               <Impact>Read Memory</Impact>
               <Impact>Read Application Data</Impact>
            </Consequence>
         </Common_Consequences>
         <Potential_Mitigations>
            <Mitigation>
               <Phase>Architecture and Design</Phase>
               <Description>
                 <xhtml:p>Measurement data should be stored in registers that are read-only or otherwise have access controls that prevent modification by an untrusted agent.</xhtml:p>
               </Description>
            </Mitigation>
         </Potential_Mitigations>
         <Demonstrative_Examples>
            <Demonstrative_Example>
               <Intro_Text>The SoC extends the hash and stores the results in registers. Without protection, an adversary can write their chosen hash values to these registers. Thus, the attacker controls the reported results.</Intro_Text>   
                <Body_Text>
                    <xhtml:p>To prevent the above scenario, the registers should have one or more of the following properties:</xhtml:p>
                    <xhtml:ol>
                        <xhtml:li>Should be Read-Only with respect to an adversary</xhtml:li>
                        <xhtml:li>Cannot be extended or modifiable either directly or indirectly (using a trusted agent as proxy) by an adversary</xhtml:li>
                        <xhtml:li>Should have appropriate access controls or protections</xhtml:li>
                    </xhtml:ol>
                 </Body_Text>
            </Demonstrative_Example>
         </Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
         </Related_Attack_Patterns>
         <References>
            <Reference External_Reference_ID="REF-1107"/>
            <Reference External_Reference_ID="REF-1131"/>
         </References>
         <Notes>
            <Note Type="Maintenance">This entry is still in development and will continue to see updates and content improvements.</Note>
         </Notes>
         <Content_History>
            <Submission>
               <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
               <Submission_Organization>Intel Corporation</Submission_Organization>
               <Submission_Date>2020-04-25</Submission_Date>
            </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated References, Related_Attack_Patterns</Modification_Comment>
				</Modification>
         </Content_History>
      </Weakness>
      <Weakness ID="1290" Name="Incorrect Decoding of Security Identifiers " Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>The product implements a decoding mechanism to decode certain bus-transaction signals to security identifiers. If the decoding is implemented incorrectly, then untrusted agents can now gain unauthorized access to the asset.</Description>
			<Extended_Description>
				<xhtml:p>In a System-On-Chip (SoC), various integrated circuits and hardware engines generate transactions such as to access (reads/writes) assets or perform certain actions (e.g., reset, fetch, compute, etc.). Among various types of message information, a typical transaction is comprised of source identity (to identify the originator of the transaction) and a destination identity (to route the transaction to the respective entity). Sometimes the transactions are qualified with a security identifier. The security identifier helps the destination agent decide on the set of allowed actions (e.g., access an asset for read and writes). A decoder decodes the bus transactions to map security identifiers into necessary access-controls/protections.</xhtml:p>
				<xhtml:p>A common weakness that can exist in this scenario is incorrect decoding because an untrusted agent’s security identifier is decoded into a trusted agent’s security identifier. Thus, an untrusted agent previously without access to an asset can now gain access to the asset.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
                <Related_Weakness Nature="ChildOf" CWE_ID="1294" View_ID="1194" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Bus/Interface IP" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
            </Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Scope>Access Control</Scope>
					<Impact>Modify Memory</Impact>
					<Impact>Read Memory</Impact>
					<Impact>DoS: Resource Consumption (Other)</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Quality Degradation</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Security identifier decoders must be reviewed for design consistency and common weaknesses.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Access and programming flows must be tested in pre-silicon and post-silicon testing in order to check for this weakness.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
                    <Intro_Text>
                        <xhtml:p>
                            Consider a system that has four bus masters and a decoder. The table below provides bus masters as well as their security identifiers and trust assumptions:
                        </xhtml:p>
                        <xhtml:table>
                            <xhtml:tr>
                                <xhtml:td>
                                    Bus Master
                                </xhtml:td>
                                <xhtml:td>
                                    Security Identifier Decoding
                                </xhtml:td>
                                <xhtml:td>
                                    Trust Assumptions
                                </xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>
                                    Master_0
                                </xhtml:td>
                                <xhtml:td>
                                    "00"
                                </xhtml:td>
                                <xhtml:td>
                                    Untrusted
                                </xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>
                                    Master_1
                                </xhtml:td>
                                <xhtml:td>
                                    "01"
                                </xhtml:td>
                                <xhtml:td>
                                    Trusted
                                </xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>
                                    Master_2
                                </xhtml:td>
                                <xhtml:td>
                                    "10"
                                </xhtml:td>
                                <xhtml:td>
                                    Untrusted
                                </xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>
                                    Master_3
                                </xhtml:td>
                                <xhtml:td>
                                    "11"
                                </xhtml:td>
                                <xhtml:td>
                                    Untrusted
                                </xhtml:td>
                            </xhtml:tr>
                        </xhtml:table>
                        <xhtml:p>
                            The decoder is supposed to decode every bus transaction and assign a corresponding security identifier. The security identifier is used to determine accesses to the assets.
                        </xhtml:p>
                        <xhtml:p>
                            The bus transaction that contains the security information is Bus_transaction [15:14], and the bits 15 through 14 contain the security identifier in formation.
                        </xhtml:p>
                        <xhtml:p>
                            The assets are the AES-Key register’s AES key for encryption or decryption. The key is128 bits implemented as a set of four 32-bit registers. The key registers are assets, and register AES_KEY_ACCESS_POLICY is defined to provide the necessary access controls.
The access-policy register defines which agents with a security identifier in the transaction can access the AES-key registers. The size of the security identifier is 4 bits (i.e., bit 3 through 0. Each bit in these 4 bits defines a security identifier. There are only 4 security identifiers that are allowed accesses to the AES-key registers. The number of the bit when set (i.e., “1”) allows respective action from an agent whose identity matches the number of the bit and, if “0” (i.e., Clear), disallows the respective action to that corresponding agent.
                        </xhtml:p>
                        <xhtml:table>
                            <xhtml:tr>
                                <xhtml:td>
                                    Register
                                </xhtml:td>
                                <xhtml:td>
                                    Field description
                                </xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>
                                    AES_ENC_DEC_KEY_0
                                </xhtml:td>
                                <xhtml:td>
                                    AES key [0:31] for encryption or decryption
Default 0x00000000
                                </xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>
                                    AES_ENC_DEC_KEY_1
                                </xhtml:td>
                                <xhtml:td>
                                    AES key [32:63] for encryption or decryption
Default 0x00000000
                                </xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>
                                    AES_ENC_DEC_KEY_2
                                </xhtml:td>
                                <xhtml:td>
                                    AES key [64:95] for encryption or decryption
Default 0x00000000
                                </xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>
                                    AES_ENC_DEC_KEY_3
                                </xhtml:td>
                                <xhtml:td>
                                    AES key [96:127] for encryption or decryption
Default 0x00000000
                                </xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>
                                    AES_KEY_ACCESS_POLICY
                                </xhtml:td>
                                <xhtml:td>
                                    [31:4] Default 0x000000
[3:0] – 0x02 agent with Security Identifier “1” has access to AES_ENC_DEC_KEY_0 through AES_ENC_DEC_KEY_4 registers

                                </xhtml:td>
                            </xhtml:tr>
                        </xhtml:table>
                        <xhtml:br/>
                        <xhtml:div>
                            Pseudo Code
                            <xhtml:br/>
                                If (AES_KEY_ACCESS_POLICY[Security_Identifier] == “1”)
                            <xhtml:br/>
                            <xhtml:div style="margin-left:10px;">
                                Allow access to AES-Key registers
                            </xhtml:div>
                            <xhtml:br/>
                                Else
                            <xhtml:br/>
                            <xhtml:div style="margin-left:10px;">
                                Deny access to AES-Key registers
                            </xhtml:div>
                        </xhtml:div>
                    </Intro_Text>
                    <Example_Code Nature="bad" Language="Other">
                        <xhtml:div>
                            Below is a decoder’s Pseudo code that only checks for bit [14] of the bus transaction to determine what Security Identifier it must assign. 
                            <xhtml:br/>
                            If (Bus_transaction[14] == “1”) 
                            <xhtml:br/>
                            <xhtml:div style="margin-left:10px;">
                                Security_Identifier == “1”
                            </xhtml:div>
                            <xhtml:br/>
                                Else
                            <xhtml:br/>
                            <xhtml:div style="margin-left:10px;">
                                Security_Identifier == “0”
                            </xhtml:div>
                        </xhtml:div>
                    </Example_Code>
					<Body_Text>Upon close observation of the security identifiers and the above code, it looks like the Master_3, an untrusted agent, has access to the AES-Key registers in addition to the intended trusted Master_1 because both have their bit “0” set to “1”.</Body_Text>
                    <Example_Code Nature="good" Language="Other">
                        <xhtml:div>
                            The decoder should check for the entire size of the security identifier in the bus-transaction signal to assign a corresponding security identifier. The following is good Pseudo code:
                            <xhtml:br/>
                            If (Bus_transaction[15:14] == “00”) 
                            <xhtml:br/>
                            <xhtml:div style="margin-left:10px;">
                                Security_Identifier == “0”
                            </xhtml:div>
                            <xhtml:br/>
                            If (Bus_transaction[15:14] == “01”) 
                            <xhtml:br/>
                            <xhtml:div style="margin-left:10px;">
                                Security_Identifier == “1”
                            </xhtml:div>
                            <xhtml:br/>
                            If (Bus_transaction[15:14] == “10”) 
                            <xhtml:br/>
                            <xhtml:div style="margin-left:10px;">
                                Security_Identifier == “2”
                            </xhtml:div>
                            <xhtml:br/>
                            If (Bus_transaction[15:14] == “11”) 
                            <xhtml:br/>
                            <xhtml:div style="margin-left:10px;">
                                Security_Identifier == “3”
                            </xhtml:div>
                        </xhtml:div>
                    </Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="629"/>
         </Related_Attack_Patterns>
         <Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-04-29</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1291" Name="Public Key Re-Use for Signing both Debug and Production Code" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>The same public key is used for signing both debug and production code.</Description>
			<Extended_Description>
				<xhtml:p>A common usage of public-key cryptography is to verify the integrity and authenticity of another entity (for example a firmware binary). If a company wants to ensure that its firmware runs only on its own hardware, before the firmware runs, an encrypted hash of the firmware image will be decrypted with the public key and then verified against the now-computed hash of the firmware image. This means that the public key forms the root of trust, which necessitates that the public key itself must be protected and used properly.</xhtml:p>
				<xhtml:p>During the development phase, debug firmware enables many hardware debug hooks, debug modes, and debug messages for testing. Those debug facilities provide significant, additional views about the firmware’s capability and, in some cases, additional capability into the chip or SoC. If compromised, these capabilities could be exploited by an attacker to take full control of the system.</xhtml:p>
				<xhtml:p>Once the product exits the manufacturing stage and enters production, it is good practice to use a different public key. Debug firmware images are known to leak. With the debug key being reused as the production key, the debug image will also work on the production image. Thus, it will open all the internal, debug capabilities to the attacker.</xhtml:p>
				<xhtml:p>If a different public key is used for the production image, even if the attacker gains access to the debug firmware image, they will not be able to run it on a production machine. Thus, damage will be limited to the intellectual property leakage resulting from the debug image.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="693" View_ID="1000" Ordinal="Primary"/>
			  <Related_Weakness Nature="PeerOf" CWE_ID="321" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Scope>Access Control</Scope>
					<Scope>Accountability</Scope>
					<Scope>Authentication</Scope>
					<Scope>Authorization</Scope>
					<Scope>Non-Repudiation</Scope>
					<Scope>Other</Scope>
					<Impact>Read Memory</Impact>
					<Impact>Modify Memory</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Varies by Context</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
				<Detection_Method>
					<Method>Architecture or Design Review</Method>
					<Description>
						<xhtml:p>Compare the debug key with the production key to make sure that they are not the same.</xhtml:p>
					</Description>
					<Effectiveness>High</Effectiveness>
					</Detection_Method>
				<Detection_Method>
					<Method>Dynamic Analysis with Manual Results Interpretation</Method>
					<Description>
						<xhtml:p>Compare the debug key with the production key to make sure that they are not the same.</xhtml:p>
					</Description>
					<Effectiveness>High</Effectiveness>
				</Detection_Method>
			</Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Use different keys for Production and Debug</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>This example illustrates the danger of using the same public key for debug and production.</Intro_Text>
					<Example_Code Nature="bad" Language="Other">
					    <xhtml:div/>Suppose the product design requires frugality of silicon real estate. Assume that originally the architecture allows just enough storage for two 2048-bit RSA keys in the fuse: one to be used for debug and the other for production. However, in the meantime, a business decision is taken to make the security future-proof beyond 2030, which means the architecture needs to use the NIST-recommended 3072-bit keys instead of the originally-planned 2048-bit keys. This means that, at most, one key can be fully stored in the fuses, not two. So the product design team decides to use the same public key for debug and production.</Example_Code>
					<Example_Code Nature="informative" Language="Other">
					    <xhtml:div/>Increase the storage so that two different keys of the required size can be stored.</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
			<Content_History>
				<Submission>
					<Submission_Name>Parbati Kumar Manna, Hareesh Khattri, Arun Kanuparthi</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-05-26</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1292" Name="Incorrect Conversion of Security Identifiers" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>The product implements a conversion mechanism to map certain bus-transaction signals to security identifiers. However, if the conversion is incorrectly implemented, untrusted agents can gain unauthorized access to the asset.</Description>
			<Extended_Description>
				<xhtml:p>In a System-On-Chip (SoC), various integrated circuits and hardware engines generate transactions such as to access (reads/writes) assets or perform certain actions (e.g., reset, fetch, compute, etc.). Among various types of message information, a typical transaction is comprised of source identity (to identify the originator of the transaction) and a destination identity (to route the transaction to the respective entity). Sometimes the transactions are qualified with a security identifier. This security identifier helps the destination agent decide on the set of allowed actions (e.g., access an asset for read and writes).</xhtml:p>
				<xhtml:p>A typical bus connects several leader and follower agents. Some follower agents implement bus protocols differently from leader agents. A protocol conversion happens at a bridge to seamlessly connect different protocols on the bus. One example is a system that implements a leader with the Advanced High-performance Bus (AHB) protocol and a follower with the Open-Core Protocol (OCP). A bridge AHB-to-OCP is needed to translate the transaction from one form to the other.</xhtml:p>
				<xhtml:p>A common weakness that can exist in this scenario is that this conversion between protocols is implemented incorrectly, whereupon an untrusted agent may gain unauthorized access to an asset.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
                <Related_Weakness Nature="ChildOf" CWE_ID="1294" View_ID="1194" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Bus/Interface IP" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
					<Note>Such issues could be introduced during hardware architecture and design, then identified later during Testing or System Configuration phases.  </Note>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>Such issues could be introduced during hardware implementation, then identified later during Testing or System Configuration phases.  </Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Scope>Access Control</Scope>
					<Impact>Modify Memory</Impact>
					<Impact>Read Memory</Impact>
					<Impact>DoS: Resource Consumption (Other)</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Quality Degradation</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Security identifier decoders must be reviewed for design inconsistency and common weaknesses.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
                    <Description>Access and programming flows must be tested in pre-silicon and post-silicon testing.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>
                        <xhtml:p>
                            Consider a system that supports AHB. Let us assume we have a follower agent that only understands OCP. To connect this follower to the leader, a bridge is introduced, i.e., AHB to OCP.
                        </xhtml:p>
                        <xhtml:p>
                            The follower has assets to protect accesses from untrusted leaders, and it employs access controls based on policy, (e.g., AES-Key registers for encryption or decryption). The key is 128 bits implemented as a set of four 32-bit registers. The key registers are assets, and register AES_KEY_ACCESS_POLICY is defined to provide the necessary access controls. 
                        </xhtml:p>
                        <xhtml:p>
                            The AES_KEY_ACCESS_POLICY access-policy register defines which agents with a security identifier in the transaction can access the AES-key registers. The implemented AES_KEY_ACCESS_POLICY has 4 bits where each bit when “Set” allows access to the AES-Key registers to the corresponding agent that has the security identifier. The other bits from 31 through 4 are reserved and not used. 
                        </xhtml:p>
                        <xhtml:table>
                            <xhtml:tr>
                                <xhtml:td>
                                    Register
                                </xhtml:td>
                                <xhtml:td>
                                    Field Description
                                </xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>
                                    AES_ENC_DEC_KEY_0
                                </xhtml:td>
                                <xhtml:td>
                                    AES key [0:31] for encryption or decryption Default 0x00000000
                                </xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>
                                    AES_ENC_DEC_KEY_1
                                </xhtml:td>
                                <xhtml:td>
                                    AES key [32:63] for encryption or decryption Default 0x00000000
                                </xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>
                                    AES_ENC_DEC_KEY_2
                                </xhtml:td>
                                <xhtml:td>
                                    AES key [64:95] for encryption or decryption Default 0x00000000
                                </xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>
                                    AES_ENC_DEC_KEY_3
                                </xhtml:td>
                                <xhtml:td>
                                    AES key [96:127] for encryption or decryption Default 0x00000000
                                </xhtml:td>
                            </xhtml:tr>
                            <xhtml:tr>
                                <xhtml:td>
                                    AES_KEY_ACCESS_POLICY
                                </xhtml:td>
                                <xhtml:td>
                                    [31:4] Default 0x000000 [3:0] – 0x02 agent with Security Identifier “1” has access to AES_ENC_DEC_KEY_0 through AES_ENC_DEC_KEY_4 registers
                                </xhtml:td>
                            </xhtml:tr>
                        </xhtml:table>
                        <xhtml:p>
                            During conversion of the AHB-to-OCP transaction, the security identifier information must be preserved and passed on to the follower correctly.
                        </xhtml:p>
                    </Intro_Text>
                    <Example_Code Nature="bad" Language="Other">
                        In AHB-to-OCP bridge, the security identifier information conversion is done incorrectly.
                    </Example_Code>
					<Body_Text>Because of the incorrect conversion, the security identifier information is either lost or could be modified in such a way that an untrusted leader can access the AES-Key registers.</Body_Text>
					<Example_Code Nature="good" Language="Other">The conversion of the signals from one protocol (AHB) to another (OCP) must be done while preserving the security identifier correctly.</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="629"/>
         </Related_Attack_Patterns>
         <Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-04-29</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1294" Name="Insecure Security Identifier Mechanism" Abstraction="Class" Structure="Simple" Status="Incomplete">
			<Description>The System-on-Chip (SoC) implements a Security Identifier mechanism to differentiate what actions are allowed or disallowed when a transaction originates from an entity. However, the Security Identifiers are not correctly implemented.</Description>
			<Extended_Description>
                <xhtml:p>Systems-On-Chip (Integrated circuits and hardware
                    engines) implement Security Identifiers to
                    differentiate/identify actions originated from various
                    agents. These actions could be 'read', 'write', 'program',
                    'reset', 'fetch', 'compute', etc. Security identifiers are
                    generated and assigned to every agent in the System (SoC)
                    that is either capable of generating an action or receiving
                    an action from another agent. Every agent could be assigned
                    a unique, Security Identifier based on its trust level or
                    privileges.</xhtml:p>
                <xhtml:p>A broad class of flaws can exist in the Security
                    Identifier process, including but not limited to missing
                    security identifiers, improper conversion of security
                    identifiers, incorrect generation of security identifiers,
                    etc.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Bus/Interface IP" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
            </Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
					<Note>Such issues could be introduced during hardware architecture and design, then identified later during Testing or System Configuration phases.  </Note>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>Such issues could be introduced during hardware implementation, then identified later during Testing or System Configuration phases.  </Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Scope>Access Control</Scope>
					<Impact>Modify Memory</Impact>
					<Impact>Read Memory</Impact>
					<Impact>DoS: Resource Consumption (Other)</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Quality Degradation</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Security Identifier Decoders must be reviewed for design inconsistency and common weaknesses.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
                    <Description>Access and programming flows must be tested in pre-silicon and post-silicon testing.</Description>
				</Mitigation>
			</Potential_Mitigations>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <Notes>
			  <Note Type="Maintenance">This entry is still under development and will continue to see updates and content improvements.</Note>
			</Notes>
			<Content_History>
				<Submission>
					<Submission_Name>CWE Content Team</Submission_Name>
					<Submission_Organization>MITRE</Submission_Organization>
					<Submission_Date>2020-07-17</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1295" Name="Debug Messages Revealing Unnecessary Information" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>The product fails to adequately prevent the revealing of unnecessary and potentially sensitive system information within debugging messages.</Description>
			<Extended_Description>
				<xhtml:p>Debug messages are messages that help troubleshoot an issue by revealing the internal state of the system. For example, debug data in design can be exposed through internal memory array dumps or boot logs through interfaces like UART via TAP commands, scan chain, etc. Thus, the more information contained in a debug message, the easier it is to debug. However, there is also the risk of revealing information that could help an attacker either decipher a vulnerability, and/or gain a better understanding of the system. Thus, this extra information could lower the “security by obscurity” factor. While “security by obscurity” alone is insufficient, it can help as a part of “Defense-in-depth”. </xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="200" View_ID="1000" Ordinal="Primary"/>
				<Related_Weakness Nature="PeerOf" CWE_ID="209" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Scope>Access Control</Scope>
					<Scope>Accountability</Scope>
					<Scope>Authentication</Scope>
					<Scope>Authorization</Scope>
					<Scope>Non-Repudiation</Scope>
					<Impact>Read Memory</Impact>
					<Impact>Bypass Protection Mechanism</Impact>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Varies by Context</Impact>
					<Likelihood>Medium</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Ensure that a debug message does not reveal any unnecessary information during the debug process for the intended response.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>This example here shows how an attacker can take advantage of unnecessary information in debug messages.</Intro_Text>
					<Body_Text>Example 1: Suppose in response to a Test Access Port (TAP) chaining request the debug message also reveals the current TAP hierarchy (the full topology) in addition to the success/failure message.</Body_Text>
					<Body_Text>Example 2: In response to a password-filling request, the debug message, instead of a simple Granted/Denied response, prints an elaborate message, “The user-entered password does not match the actual password stored in &lt;directory name&gt;.”</Body_Text>
					<Body_Text>The result of the above examples is that the user is able to gather additional unauthorized information about the system from the debug messages.</Body_Text>
					<Body_Text>The solution is to ensure that Debug messages do not reveal additional details.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
			<Observed_Examples>
				<Observed_Example>
					<Reference>CVE-2017-18326</Reference>
					<Description>modem debug messages include cryptographic keys</Description>
					<Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-18326</Link>
				</Observed_Example>
			</Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="121"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1112"/>
			</References>
			<Content_History>
				<Submission>
					<Submission_Name>Parbati Kumar Manna, Hareesh Khattri, Arun Kanuparthi</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-05-31</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Observed_Examples, Related_Attack_Patterns, Relationships</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1296" Name="Incorrect Chaining or Granularity of Debug Components" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>The product's debug components contain incorrect chaining or granularity of debug components.</Description>
			<Extended_Description>
				<xhtml:p>For debugging and troubleshooting a chip, several hardware design elements are often implemented, including:</xhtml:p>
				<xhtml:ul>
				<xhtml:li>Various Test Access Ports (TAPs) allow boundary scan commands to be executed.</xhtml:li>
				<xhtml:li>For scanning the internal components of a chip, there are scan cells that allow the chip to be used as a "stimulus and response" mechanism.</xhtml:li>
				<xhtml:li>Chipmakers might create custom methods to observe the internal components of their chips by placing various tracing hubs within their chip and creating hierarchical or interconnected structures among those hubs.</xhtml:li>
				</xhtml:ul>
				<xhtml:p>Logic errors during design or synthesis could misconfigure the interconnection of the debug components, which could allow unintended access permissions.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>	
				<Language Name="Verilog" Prevalence="Undetermined"/>
				<Language Name="VHDL" Prevalence="Undetermined"/>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Processor IP" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Access Control</Scope>
					<Scope>Authentication</Scope>
					<Scope>Authorization</Scope>
					<Scope>Availability</Scope>
					<Scope>Accountability</Scope>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Bypass Protection Mechanism</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
					<Impact>Modify Memory</Impact>
					<Impact>Modify Files or Directories</Impact>
					<Likelihood>Medium</Likelihood>
					<Note>Depending on the access to debug component(s) erroneously granted, an attacker could use the debug component to gain additional understanding about the system to further an attack and/or execute other commands. This could compromise any security property, including the ones listed above.</Note>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
				<Detection_Method>
				<Method>Architecture or Design Review</Method>
				<Description>Appropriate Post-Si tests should be carried out at various authorization levels to ensure that debug components are properly chained and accessible only to users with appropriate credentials.</Description>
				<Effectiveness>High</Effectiveness>
				</Detection_Method>
				<Detection_Method>
				<Method>Dynamic Analysis with Manual Results Interpretation</Method>
				<Description>Appropriate Post-Si tests should be carried out at various authorization levels to ensure that debug components are properly chained and accessible only to users with appropriate credentials.</Description>
				<Effectiveness>High</Effectiveness>
				</Detection_Method>
			</Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Ensure that debug components are properly chained and their granularity is maintained at different authentication levels.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>The following example shows how an attacker can take advantage of incorrect chaining or missing granularity of debug components.</Intro_Text>
					<Body_Text>In a System-on-Chip (SoC), the user might be able to access the SoC-level TAP with a certain level of authorization. However, this access should not also grant access to all of the internal TAPs (e.g., Core). Separately, if any of the internal TAPs is also stitched to the TAP chain when it should not be because of a logic error, then an attacker can access the internal TAPs as well and execute commands there.</Body_Text>
					<Body_Text>As a related example, suppose there is a hierarchy of TAPs (TAP_A is connected to TAP_B and TAP_C, then TAP_B is connected to TAP_D and TAP_E, then TAP_C is connected to TAP_F and TAP_G, etc.).  Architecture mandates that the user have one set of credentials for just accessing TAP_A, another set of credentials for accessing TAP_B and TAP_C, etc. However, if, during implementation, the designer mistakenly implements a daisy-chained TAP where all the TAPs are connected in a single TAP chain without the hierarchical structure, the correct granularity of debug components is not implemented and the attacker can gain unauthorized access.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
			<Observed_Examples>
				<Observed_Example>
					<Reference>CVE-2017-18347</Reference>
					<Description>Incorrect access control in RDP Level 1 on STMicroelectronics STM32F0 series devices allows physically present attackers to extract the device's protected firmware via a special sequence of Serial Wire Debug (SWD) commands because there is a race condition between full initialization of the SWD interface and the setup of flash protection. </Description>
					<Link>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-18347</Link>
				</Observed_Example>
				<Observed_Example>
					<Reference>CVE-2020-1791</Reference>
					<Description>There is an improper authorization vulnerability in several smartphones.  The system has a logic-judging error, and, under certain scenarios, a successful exploit could allow the attacker to switch to third desktop after a series of operations in ADB mode. (Vulnerability ID: HWPSIRT-2019-10114).</Description>
					<Link>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-1791</Link>
				</Observed_Example>
			</Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <Notes>
			  <Note Type="Maintenance">This entry is still under development and will continue to see updates and content improvements.</Note>
			</Notes>
			<Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-05-31</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1297" Name="Unprotected Confidential Information on Device is Accessible by OSAT Vendors" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>The product does not adequately protect confidential information on the device from being accessed by Outsourced Semiconductor Assembly and Test (OSAT) vendors.</Description>
			<Extended_Description>
				<xhtml:p>In contrast to complete vertical integration of architecting, designing, manufacturing, assembling, and testing chips all within a single organization, an organization can choose to simply architect and design a chip before outsourcing the rest of the process to OSAT entities (e.g., external foundries and test houses). In the latter example, the device enters an OSAT facility in a much more vulnerable pre-production stage where many debug and test modes are accessible. Therefore, the chipmaker must place a certain level of trust with the OSAT. To counter this, the chipmaker often requires the OSAT partner to enter into restrictive non-disclosure agreements (NDAs). Nonetheless, OSAT vendors likely have many customers, which increases the risk of accidental sharing of information. There may also be a security vulnerability in the information technology (IT) system of the OSAT facility. Alternatively, a malicious insider at the OSAT facility may carry out an insider attack. Considering these factors, it behooves the chipmaker to minimize any confidential information in the device that may be accessible to the OSAT vendor.</xhtml:p>
				<xhtml:p>Logic errors during design or synthesis could misconfigure the interconnection of the debug components, which could provide improper authorization to sensitive information.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="285" View_ID="1000"/>
			</Related_Weaknesses>
			<Applicable_Platforms>	
				<Language Name="Verilog" Prevalence="Undetermined"/>
				<Language Name="VHDL" Prevalence="Undetermined"/>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Processor IP" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Access Control</Scope>
					<Scope>Authentication</Scope>
					<Scope>Authorization</Scope>
					<Scope>Availability</Scope>
					<Scope>Accountability</Scope>
					<Scope>Non-Repudiation</Scope>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Bypass Protection Mechanism</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
					<Impact>Modify Memory</Impact>
					<Impact>Modify Files or Directories</Impact>
					<Likelihood>Medium</Likelihood>
					<Note>The impact depends on the confidential information itself and who is inadvertently granted access. For example, if the confidential information is a key that can unlock all the parts of a generation, the impact could be severe.</Note>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
				<Detection_Method>
				<Method>Architecture or Design Review</Method>
				<Description>Appropriate Post-Si tests should be carried out to ensure that residual confidential information is not left on parts leaving one facility for another facility.</Description>
				<Effectiveness>High</Effectiveness>
				</Detection_Method>
				<Detection_Method>
				<Method>Dynamic Analysis with Manual Results Interpretation</Method>
				<Description>Appropriate Post-Si tests should be carried out to ensure that residual confidential information is not left on parts leaving one facility for another facility.</Description>
				<Effectiveness>Moderate</Effectiveness>
				</Detection_Method>
			</Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>
					<xhtml:ul>
						<xhtml:li>•	Ensure that when an OSAT vendor is allowed to access test interfaces necessary for preproduction and returned parts, the vendor only pulls the minimal information necessary. Also, architect the product in such a way that, when an “unlock device” request comes, it only unlocks that specific part and not all the parts for that product line.</xhtml:li>
						<xhtml:li>•	Ensure that the product’s non-volatile memory (NVM) is scrubbed of all confidential information and secrets before handing it over to an OSAT.</xhtml:li>
						<xhtml:li>•	Arrange to secure all communication between an OSAT facility and the chipmaker.</xhtml:li>
						</xhtml:ul>
				</Description>
				<Effectiveness>Moderate</Effectiveness>
				</Mitigation>
			</Potential_Mitigations>
			
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>The following example shows how an attacker can take advantage of a piece of confidential information that has not been protected from the OSAT.</Intro_Text>
					<Body_Text>Suppose the preproduction device contains NVM (a storage medium that by definition/design can retain its data without power), and this NVM contains a key that can unlock all the parts for that generation.  An OSAT facility accidentally leaks the key.</Body_Text>
					<Body_Text>Compromising a key that can unlock all the parts of a generation can be devastating to a chipmaker.</Body_Text>
					<Body_Text>The likelihood of such a compromise can be reduced by ensuring all memories on the preproduction device are properly scrubbed.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1113"/>
				<Reference External_Reference_ID="REF-1114"/>
			</References>
			<Notes>
			  <Note Type="Maintenance">This entry is still under development and will continue to see updates and content improvements.</Note>
			</Notes>
			<Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-05-29</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1298" Name="Hardware Logic Contains Race Conditions" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>A race condition in the hardware logic results in undermining security guarantees of the system.</Description>
			<Extended_Description>
				<xhtml:p>A race condition in logic circuits typically occurs when a logic gate gets inputs from signals that have traversed different paths while originating from the same source. Such inputs to the gate can change at slightly different times in response to a change in the source signal. This results in a timing error or a glitch (temporary or permanent) that causes the output to change to an unwanted state before settling back to the desired state. If such timing errors occur in access control logic or finite state machines that are implemented in security sensitive flows, an attacker might exploit them to circumvent existing protections.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="362" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Name="Verilog" Prevalence="Undetermined"/>
                <Language Name="VHDL" Prevalence="Undetermined"/>
                <Technology Class="System on Chip" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Access Control</Scope>
					<Impact>Bypass Protection Mechanism</Impact>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Alter Execution Logic</Impact>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Adopting design practices that encourage designers to recognize and eliminate race conditions, such as Karnaugh maps, could result in the decrease in occurrences of race conditions.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Logic redundancy can be implemented along security critical paths to prevent race conditions. To avoid metastability, it is a good practice in general to default to a secure state in which access is not given to untrusted agents.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>The code below shows a 2x1 multiplexor using logic gates. Though the code shown below results in the minimum gate solution, it is disjoint and causes glitches.</Intro_Text>
					<Example_Code Nature="bad" Language="Verilog">
						// 2x1 Multiplexor using logic-gates<xhtml:br/>
                        <xhtml:br/>
						module glitchEx(<xhtml:br/>
						<xhtml:div style="margin-left:10px;">
							input wire in0, in1, sel,<xhtml:br/>
							output wire z<xhtml:br/>
						</xhtml:div>
						);<xhtml:br/>
                        <xhtml:br/>
						wire not_sel;<xhtml:br/>
						wire and_out1, and_out2;<xhtml:br/>
						<xhtml:br/>
						assign not_sel = ~sel;<xhtml:br/>
						assign and_out1 = not_sel &amp; in0;<xhtml:br/>
						assign and_out2 = sel &amp; in1;<xhtml:br/>
                        <xhtml:br/>
						// Buggy line of code:<xhtml:br/>
						assign z = and_out1 | and_out2; // glitch in signal z<xhtml:br/>
						<xhtml:br/>
						endmodule<xhtml:br/>
					</Example_Code>
					<Body_Text>The buggy line of code, commented above, results in signal 'z' periodically changing to an unwanted state. Thus, any logic that references signal 'z' may access it at a time when it is in this unwanted state. This line should be replaced with the line shown below in the Good Code Snippet which results in signal 'z' remaining in a continuous, known, state. Reference for the above code, along with waveforms for simulation can be found in the references below.</Body_Text>
					<Example_Code Nature="good" Language="Verilog">
						assign z &lt;= and_out1 or and_out2 or (in0 and in1);
					</Example_Code>
					<Body_Text>This line of code removes the glitch in signal z.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="26"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1115"/>
				<Reference External_Reference_ID="REF-1116"/>
			</References>
			<Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-02-10</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1299" Name="Missing Protection Mechanism for Alternate Hardware Interface" Abstraction="Base" Structure="Simple" Status="Draft">
            <Description>The lack of protections on alternate paths to access
                control-protected assets (such as unprotected shadow registers
                and other external facing unguarded interfaces) allows an
                attacker to bypass existing protections to the asset that are
		only performed against the primary path.</Description>
			<Extended_Description>
                <xhtml:p>An asset inside a chip might have access-control
                    protections through one interface. However, if all paths to
                    the asset are not protected, an attacker might compromise
                    the asset through alternate paths. These alternate paths
                    could be through shadow or mirror registers inside the IP
                    core, or could be paths from other external-facing
                    interfaces to the IP core or SoC.</xhtml:p>
                <xhtml:p>Consider an SoC with various interfaces such as UART,
                    SMBUS, PCIe, USB, etc. If access control is implemented for
                    SoC internal registers only over the PCIe interface, then
                    an attacker could still modify the SoC internal registers
                    through alternate paths by coming through interfaces such
                    as UART, SMBUS, USB, etc. </xhtml:p>
                <xhtml:p>Alternatively, attackers might be able to bypass
                    existing protections by exploiting unprotected, shadow
                    registers. Shadow registers and mirror registers typically
                    refer to registers that can be accessed from multiple
                    addresses. Writing to or reading from the aliased/mirrored
                    address has the same effect as writing to the address of
                    the main register. They are typically implemented within an
                    IP core or SoC to temporarily hold certain data. These data
                    will later be updated to the main register, and both
                    registers will be in synch. If the shadow registers are not
                    access-protected, attackers could simply initiate
                    transactions to the shadow registers and compromise system
                    security. </xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="PeerOf" CWE_ID="1191" View_ID="1194" Ordinal="Primary"/>
				<Related_Weakness Nature="ChildOf" CWE_ID="420" View_ID="1000" Ordinal="Primary"/>
				<Related_Weakness Nature="ChildOf" CWE_ID="288" View_ID="1000"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Microcontroller IP" Prevalence="Undetermined"/>
				<Technology Name="Processor IP" Prevalence="Undetermined"/>
				<Technology Name="Bus/Interface IP" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
            </Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Scope>Access Control</Scope>
					<Impact>Modify Memory</Impact>
					<Impact>Read Memory</Impact>
					<Impact>DoS: Resource Consumption (Other)</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Quality Degradation</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Requirements</Phase>
                    <Description>Protect assets from accesses against all potential interfaces and alternate paths. </Description>
                    <Effectiveness>Defense in Depth</Effectiveness>
				</Mitigation>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
                    <Description>Protect assets from accesses against all potential interfaces and alternate paths. </Description>
                    <Effectiveness>Defense in Depth</Effectiveness>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
                    <Description>Protect assets from accesses against all potential interfaces and alternate paths. </Description>
                    <Effectiveness>Defense in Depth</Effectiveness>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
                    <Intro_Text>
                        <xhtml:p>
                            Register SECURE_ME is located at address 0xF00. A
                            mirror of this register called COPY_OF_SECURE_ME is
                            at location 0x800F00. The register SECURE_ME is
                            protected from malicious agents and only allows
                            access to select, while COPY_OF_SECURE_ME is not. 
                        </xhtml:p>
                        <xhtml:p>
                            Access control is implemented using an allowlist (as
                            indicated by acl_oh_allowlist). The identity of the
                            initiator of the transaction is indicated by the
                            one hot input, incoming_id. This is checked against
                            the acl_oh_allowlist (which contains a list of
                            initiators that are allowed to access the asset). 
                        </xhtml:p>
                        <xhtml:p>
                            Though this example is shown in Verilog, it will
                            apply to VHDL as well. 
                        </xhtml:p>
                    </Intro_Text>
                    <Example_Code Nature="informative" Language="Verilog">
                        module foo_bar(data_out, data_in, incoming_id, address, clk, rst_n);<xhtml:br/>
                        output [31:0] data_out;<xhtml:br/>
                        input [31:0] data_in, incoming_id, address;<xhtml:br/>
                        input clk, rst_n;<xhtml:br/>
                        wire write_auth, addr_auth;<xhtml:br/>
                        reg [31:0] data_out, acl_oh_allowlist, q;<xhtml:br/>
                        assign write_auth = | (incoming_id &amp; acl_oh_allowlist) ? 1 : 0; <xhtml:br/>
                        always @*<xhtml:br/>
                        <xhtml:div style="margin-left:10px;">
                            acl_oh_allowlist &lt;= 32’h8312; <xhtml:br/>
                        </xhtml:div>
                        assign addr_auth = (address == 32’hF00) ? 1: 0;<xhtml:br/>
                        always @ (posedge clk or negedge rst_n)<xhtml:br/>
                        <xhtml:div style="margin-left:10px;">
                            if (!rst_n)<xhtml:br/>
                            <xhtml:div style="margin-left:10px;">
                                begin<xhtml:br/>
                                <xhtml:div style="margin-left:10px;">
                                    q &lt;= 32’h0;<xhtml:br/>
                                    data_out &lt;= 32’h0;<xhtml:br/>
                                </xhtml:div>
                                end<xhtml:br/>
                            </xhtml:div>
                            else<xhtml:br/>
                            <xhtml:div style="margin-left:10px;">
                                begin<xhtml:br/>
                                <xhtml:div style="margin-left:10px;">
                                    q &lt;= (addr_auth &amp; write_auth) ? data_in: q;<xhtml:br/>
                                    data_out &lt;= q;<xhtml:br/>
                                </xhtml:div>
                                end<xhtml:br/>
                            </xhtml:div>
                            end<xhtml:br/>
                        </xhtml:div>
                        endmodule<xhtml:br/>
                    </Example_Code>
					<Example_Code Nature="bad" Language="Verilog">assign addr_auth = (address == 32’hF00) ? 1: 0;</Example_Code>
                    <Body_Text>The bugged line of code is repeated in the Bad
                        example above. Weakness arises from the fact that the
                        SECURE_ME register can be modified by writing to the
                        shadow register COPY_OF_SECURE_ME, the address of
                        COPY_OF_SECURE_ME should also be included in the check.
                        That buggy line of code should instead be replaced as
                        shown in the Good Code Snippet below. 
                    </Body_Text>
					<Example_Code Nature="good" Language="Verilog">assign addr_auth = (address == 32’hF00 || address == 32’h800F00) ? 1: 0;</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
			<Observed_Examples>
				<Observed_Example>
					<Reference>CVE-2017-18293</Reference>
                    <Description>When GPIO is protected by blocking access
                        to corresponding GPIO resource registers,
                        protection can be bypassed by writing to the
                        corresponding banked GPIO registers instead.
                    </Description>
		    <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-18293</Link>
				</Observed_Example>
				<Observed_Example>
				  <Reference>CVE-2020-15483</Reference>
				  <Description>monitor device allows access to physical UART debug port without authentication</Description>
				  <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15483</Link>
				</Observed_Example>
			</Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
            <Related_Attack_Pattern CAPEC_ID="554"/>
         </Related_Attack_Patterns>
         <Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna, Narasimha Kumar V Mangipudi</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2019-10-02</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-12-10</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Observed_Examples, Related_Attack_Patterns</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1300" Name="Improper Protection of Physical Side Channels" Abstraction="Base" Structure="Simple" Status="Stable">

	<Description>The device does not contain sufficient protection
	mechanisms to prevent physical side channels from exposing
	sensitive information due to patterns in physically observable
	phenomena such as variations in power consumption,
	electromagnetic emissions (EME), or acoustic emissions.</Description>
			
	<Extended_Description>
	  <xhtml:p>An adversary could monitor and measure physical
	  phenomena to detect patterns and make inferences, even if it
	  is not possible to extract the information in the digital
	  domain.</xhtml:p>
	  <xhtml:p>Physical side channels have been well-studied for
	  decades in the context of breaking implementations of
	  cryptographic algorithms or other attacks against security
	  features. These side channels may be easily observed by an
	  adversary with physical access to the device, or using a
	  tool that is in close proximity.  If the adversary can
	  monitor hardware operation and correlate its data processing
	  with power, EME, and acoustic measurements, the adversary
	  might be able to recover of secret keys and data.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="203" View_ID="1000" Ordinal="Primary"/>
				<Related_Weakness Nature="ChildOf" CWE_ID="203" View_ID="1194" Ordinal="Primary"/>
			</Related_Weaknesses>
		 <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Primary</Ordinality>
            </Weakness_Ordinality>
            <Weakness_Ordinality>
               <Ordinality>Resultant</Ordinality>
            </Weakness_Ordinality>
		 </Weakness_Ordinalities>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Impact>Read Memory</Impact>
					<Impact>Read Application Data</Impact>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
			  <Detection_Method>
				<Method>Manual Analysis</Method>
				<Description>Perform a set of leakage detection tests such as the procedure outlined in the Test Vector Leakage Assessment (TVLA) test requirements for AES [REF-1230].  TVLA is the basis for the ISO standard 17825 [REF-1229]. A separate methodology is provided by [REF-1228]. Note that sole reliance on this method might not yield expected results [REF-1239] [REF-1240].</Description>
				<Effectiveness>Moderate</Effectiveness>
			  </Detection_Method>
			  <Detection_Method>
				<Method>Manual Analysis</Method>
				<Description>
				  <xhtml:p>Post-silicon, perform full side-channel attacks (penetration testing) covering as many known leakage models as possible against test code.</xhtml:p></Description>
				  <Effectiveness>Moderate</Effectiveness>
				</Detection_Method>
			  <Detection_Method>
				<Method>Manual Analysis</Method>
				<Description>
				  <xhtml:p>Pre-silicon - while the aforementioned TVLA methods can be performed post-silicon, models of device power consumption or other physical emanations can be built from information present at various stages of the hardware design process before fabrication. TVLA or known side-channel attacks can be applied to these simulated traces and countermeasures applied before tape-out.  Academic research in this field includes [REF-1231] [REF-1232] [REF-1233].</xhtml:p></Description>
				  <Effectiveness>Moderate</Effectiveness>
				</Detection_Method>
			  </Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Apply blinding or masking techniques to implementations of cryptographic algorithms.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Add shielding or tamper-resistant protections to the device to increase the difficulty of obtaining measurements of the side-channel.</Description>
				</Mitigation>
			</Potential_Mitigations>
		<Demonstrative_Examples>
		  <Demonstrative_Example>
		    <Intro_Text>Consider a device that checks a
		    passcode to unlock the screen.</Intro_Text>
		    <Example_Code Nature="bad">As each character of
		    the PIN number is entered, a correct character
		    exhibits one current pulse shape while an
		    incorrect character exhibits a different current
		    pulse shape.</Example_Code>
		    <Body_Text>PIN numbers used to unlock a cell phone
		    should not exhibit any characteristics about
		    themselves. This creates a side channel. An
		    attacker could monitor the pulses using an
		    oscilloscope or other method. Once the first
		    character is correctly guessed (based on the
		    oscilloscope readings), they can then move to the
		    next character, which is much more efficient than
		    the brute force method of guessing every possible
		    sequence of characters.</Body_Text>
		    <Example_Code Nature="good">Rather than comparing
		    each character to the correct PIN value as it is
		    entered, the device could accumulate the PIN in a
		    register, and do the comparison all at once at the
		    end. Alternatively, the components for the
		    comparison could be modified so that the current
		    pulse shape is the same regardless of the
		    correctness of the entered
		    character.</Example_Code>
		  </Demonstrative_Example>
		  <Demonstrative_Example>
			<Intro_Text>Consider the device vulnerability CVE-2021-3011, which affects certain microcontrollers [REF-1221]. The Google Titan Security Key is used for two-factor authentication using cryptographic algorithms. The device uses an internal secret key for this purpose and exchanges information based on this key for the authentication. If this internal secret key and the encryption algorithm were known to an adversary, the key function could be duplicated, allowing the adversary to masquerade as the legitimate user.</Intro_Text>
			<Example_Code Nature="bad">The local method of extracting the secret key consists of plugging the key into a USB port and using electromagnetic (EM) sniffing tools and computers.</Example_Code>
			<Example_Code Nature="good">Several solutions could have been considered by the manufacturer. For example, the manufacturer could shield the circuitry in the key or add randomized delays, indirect calculations with random values involved, or randomly ordered calculations to make extraction much more difficult or a combination of these techniques.</Example_Code>
		  </Demonstrative_Example>
		</Demonstrative_Examples>
		<Observed_Examples>
		  <Observed_Example>
		    <Reference>CVE-2021-3011</Reference>
		    <Description>electromagnetic-wave side-channel in security-related microcontrollers allows extraction of private key</Description>
		    <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-3011</Link>
		  </Observed_Example>
		  <Observed_Example>
		    <Reference>CVE-2013-4576</Reference>
		    <Description>message encryption software uses certain instruction sequences that allows RSA key extraction using a chosen-ciphertext attack and acoustic cryptanalysis</Description>
		    <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2013-4576</Link>
		  </Observed_Example>
		  <Observed_Example>
		    <Reference>CVE-2020-28368</Reference>
		    <Description>virtualization product allows recovery of AES keys from the guest OS using a side channel attack against a power/energy monitoring interface.</Description>
		    <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-28368</Link>
		  </Observed_Example>
		  <Observed_Example>
		    <Reference>CVE-2019-18673</Reference>
		    <Description>power consumption varies based on number of pixels being illuminated in a display, allowing reading of secrets such as the PIN by using the USB interface to measure power consumption</Description>
		    <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-18673</Link>
		  </Observed_Example>
		</Observed_Examples>
		<Functional_Areas>
            	  <Functional_Area>Power</Functional_Area>
         	</Functional_Areas>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="189"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1117"/>
				<Reference External_Reference_ID="REF-1118"/>
				<Reference External_Reference_ID="REF-1119"/>
				<Reference External_Reference_ID="REF-1120"/>
				<Reference External_Reference_ID="REF-1055"/>
				<Reference External_Reference_ID="REF-1218"/>
				<Reference External_Reference_ID="REF-1221"/>
				<Reference External_Reference_ID="REF-1228"/>
				<Reference External_Reference_ID="REF-1229"/>
				<Reference External_Reference_ID="REF-1230"/>
				<Reference External_Reference_ID="REF-1231" Section="pp. 305-319"/>
				<Reference External_Reference_ID="REF-1232" Section="pp. 123-130"/>
				<Reference External_Reference_ID="REF-1233"/>
				<Reference External_Reference_ID="REF-1234"/>
				<Reference External_Reference_ID="REF-1235"/>
				<Reference External_Reference_ID="REF-1239"/>
				<Reference External_Reference_ID="REF-1240"/>
			</References>
			<Content_History>
				<Submission>
					<Submission_Name>Nicole Fern</Submission_Name>
					<Submission_Organization>Tortuga Logic</Submission_Organization>
					<Submission_Date>2020-05-29</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Functional_Areas, Maintenance_Notes</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
				<Contribution Type="Content">
				  <Contribution_Name>Anders Nordstrom, Alric Althoff</Contribution_Name>
				  <Contribution_Organization>Tortuga Logic</Contribution_Organization>
				  <Contribution_Date>2021-10-11</Contribution_Date>
				  <Contribution_Comment>Provided detection methods, observed examples, and references</Contribution_Comment>
				</Contribution>
				<Contribution Type="Content">
				  <Contribution_Name>Nicole Fern</Contribution_Name>
				  <Contribution_Organization>Riscure</Contribution_Organization>
				  <Contribution_Date>2021-10-13</Contribution_Date>
				  <Contribution_Comment>Provided detection methods, observed examples, and references</Contribution_Comment>
				</Contribution>
			</Content_History>
		</Weakness>
      <Weakness ID="1301" Name="Insufficient or Incomplete Data Removal within Hardware Component" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>The product's data removal process does not completely delete all data and potentially sensitive information within hardware components.</Description>
			<Extended_Description>
				<xhtml:p>Physical properties of hardware devices, such as remanence of magnetic media, residual charge of ROMs/RAMs, or screen burn-in may still retain sensitive data after a data removal process has taken place and power is removed.</xhtml:p>
				<xhtml:p>Recovering data after erasure or overwriting is possible due to a phenomenon called data remanence. For example, if the same value is written repeatedly to a memory location, the corresponding memory cells can become physically altered to a degree such that even after the original data is erased that data can still be recovered through physical characterization of the memory cells.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="226" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Impact>Read Memory</Impact>
					<Impact>Read Application Data</Impact>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Apply blinding or masking techniques to implementations of cryptographic algorithms.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Alter the method of erasure, add protection of media, or destroy the media to protect the data.</Description>
				</Mitigation>
			</Potential_Mitigations>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="37"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1117"/>
				<Reference External_Reference_ID="REF-1118"/>
				<Reference External_Reference_ID="REF-1119"/>
				<Reference External_Reference_ID="REF-1120"/>
				<Reference External_Reference_ID="REF-1055"/>
			</References>
			<Notes>
			  <Note Type="Maintenance">This entry is still under development and will continue to see updates and content improvements.</Note>
			</Notes>
			<Content_History>
				<Submission>
					<Submission_Name>Nicole Fern</Submission_Name>
					<Submission_Organization>Tortuga Logic</Submission_Organization>
					<Submission_Date>2020-05-29</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-12-10</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1302" Name="Missing Security Identifier" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>The product implements a security identifier mechanism to differentiate what actions are allowed or disallowed when a transaction originates from an entity. A transaction is sent without a security identifier.</Description>
			<Extended_Description>
				<xhtml:p>In a System-On-Chip (SoC), various integrated circuits and hardware engines generate transactions such as to access (reads/writes) assets or perform certain actions (e.g., reset, fetch, compute). A typical transaction is comprised of source identity (to identify the originator of the transaction) and a destination identity (to route the transaction to the respective entity) in addition to much more information in the message. Sometimes the transactions are qualified with a Security Identifier.  This Security Identifier helps the destination agent decide on the set of allowed or disallowed actions.</xhtml:p>
				<xhtml:p>A common weakness that can exist in such transaction schemes is that the source agent fails to include the necessary, security identifier with the transaction.  Because of the missing security identifier, the destination agent might drop the message, thus resulting in Denial-of-Service (DoS), or get confused in its attempt to execute the given action, which confusion could result in privilege escalation or a gain of unintended access.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="1294" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
					<Note>Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.</Note>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Scope>Access Control</Scope>
					<Impact>Modify Memory</Impact>
					<Impact>Read Memory</Impact>
					<Impact>DoS: Crash, Exit, or Restart</Impact>
					<Impact>Bypass Protection Mechanism</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Transaction details must be reviewed for design inconsistency and common weaknesses.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Security identifier definition and programming flow must be tested in pre-silicon and post-silicon testing.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>
						<xhtml:p>Consider a system with a register for storing AES key for encryption or decryption. The key is of 128 bits implemented as a set of four 32-bit registers.  The key registers are assets, and the register AES_KEY_ACCESS_POLICY is defined to provide the necessary access controls.</xhtml:p>
						<xhtml:p>The access-policy register defines which agents with a security identifier in the transaction can access the AES-key registers. Each bit in this 32-bit register defines a security identifier. There could be a maximum of 32 security identifiers that are allowed accesses to the AES-key registers. The number of the bit when set (i.e., “1”) allows for a respective action from an agent whose identity matches the number of the bit; if set to “0” (i.e., Clear), it disallows the respective action to that corresponding agent.</xhtml:p>
					</Intro_Text>
					<Example_Code Nature="bad">
						<xhtml:table>
							<xhtml:tr>
								<xhtml:th>Register</xhtml:th>
								<xhtml:th>Field description</xhtml:th>
							</xhtml:tr>
							<xhtml:tr>
								<xhtml:td>AES_ENC_DEC_KEY_0</xhtml:td>
								<xhtml:td>AES key [0:31] for encryption or decryption, Default 0x00000000</xhtml:td>
							</xhtml:tr>
							<xhtml:tr>
								<xhtml:td>AES_ENC_DEC_KEY_1</xhtml:td>
								<xhtml:td>AES key [32:63] for encryption or decryption, Default 0x00000000</xhtml:td>
							</xhtml:tr>
							<xhtml:tr>
								<xhtml:td>AES_ENC_DEC_KEY_2</xhtml:td>
								<xhtml:td>AES key [64:95] for encryption or decryption, Default 0x00000000</xhtml:td>
							</xhtml:tr>
							<xhtml:tr>
								<xhtml:td>AES_ENC_DEC_KEY_4</xhtml:td>
								<xhtml:td>AES key [96:127] for encryption or decryption, Default 0x00000000</xhtml:td>
							</xhtml:tr>
							<xhtml:tr>
								<xhtml:td>AES_KEY_ACCESS_POLICY</xhtml:td>
								<xhtml:td>[31:0] Default 0x00000004 – agent with Security Identifier “2” has access to AES_ENC_DEC_KEY_0 through AES_ENC_DEC_KEY_4 registers</xhtml:td>
							</xhtml:tr>
						</xhtml:table>
					</Example_Code>
					<Body_Text>The originator sends a transaction with no security identifier, i.e., meaning the value is “0” or NULL. The AES-Key-access register does not allow the necessary action and drops the transaction because the originator failed to include the required security identifier.</Body_Text>
					<Example_Code Nature="good">
						<xhtml:table>
							<xhtml:tr>
								<xhtml:th>Register</xhtml:th>
								<xhtml:th>Field description</xhtml:th>
							</xhtml:tr>
							<xhtml:tr>
								<xhtml:td>AES_ENC_DEC_KEY_0</xhtml:td>
								<xhtml:td>AES key [0:31] for encryption or decryption, Default 0x00000000</xhtml:td>
							</xhtml:tr>
							<xhtml:tr>
								<xhtml:td>AES_ENC_DEC_KEY_1</xhtml:td>
								<xhtml:td>AES key [32:63] for encryption or decryption, Default 0x00000000</xhtml:td>
							</xhtml:tr>
							<xhtml:tr>
								<xhtml:td>AES_ENC_DEC_KEY_2</xhtml:td>
								<xhtml:td>AES key [64:95] for encryption or decryption, Default 0x00000000</xhtml:td>
							</xhtml:tr>
							<xhtml:tr>
								<xhtml:td>AES_ENC_DEC_KEY_4</xhtml:td>
								<xhtml:td>AES key [96:127] for encryption or decryption, Default 0x00000000</xhtml:td>
							</xhtml:tr>
							<xhtml:tr>
								<xhtml:td>AES_KEY_ACCESS_POLICY</xhtml:td>
								<xhtml:td>[31:0] Default 0x00000002 – agent with security identifier “2” has access to AES_ENC_DEC_KEY_0 through AES_ENC_DEC_KEY_4 registers</xhtml:td>
							</xhtml:tr>
						</xhtml:table>
					</Example_Code>
					<Body_Text>The originator should send a transaction with Security Identifier “2” which will allow access to the AES-Key-access register and allow encryption and decryption operations.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
         </Related_Attack_Patterns>
         <Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-02-14</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1303" Name="Non-Transparent Sharing of Microarchitectural Resources" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>Hardware structures shared across execution contexts (e.g., caches and branch predictors) can violate the expected architecture isolation between contexts.</Description>
			<Extended_Description>
				<xhtml:p>Modern processors use techniques such as out-of-order execution, speculation, prefetching, data forwarding, and caching to increase performance. Details about the implementation of these techniques are hidden from the programmer’s view. This is problematic when the hardware implementation of these techniques results in resources being shared across supposedly isolated contexts. Contention for shared resources between different contexts opens covert channels that allow malicious programs executing in one context to recover information from another context.</xhtml:p>
				
				<xhtml:p>Some examples of shared micro-architectural resources that have been used to leak information between contexts are caches, branch prediction logic, and load or store buffers. Speculative and out-of-order execution provides an attacker with increased control over which data is leaked through the covert channel.</xhtml:p>
				
				<xhtml:p>If the extent of resource sharing between contexts in the design microarchitecture is undocumented, it is extremely difficult to ensure system assets are protected against disclosure.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="1189" View_ID="1000" Ordinal="Primary"/>
				<Related_Weakness Nature="ChildOf" CWE_ID="203" View_ID="1000"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
					<Note>Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.</Note>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Impact>Read Application Data</Impact>
					<Impact>Read Memory</Impact>
					<Note>Microarchitectural side-channels have been used to leak specific information such as cryptographic keys, and Address Space Layout Randomization (ALSR) offsets as well as arbitrary memory.</Note>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Microarchitectural covert channels can be addressed using a mixture of hardware and software mitigation techniques. These include partitioned caches, new barrier and flush instructions, and disabling high resolution performance counters and timers.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Requirements</Phase>
					<Description>Microarchitectural covert channels can be addressed using a mixture of hardware and software mitigation techniques. These include partitioned caches, new barrier and flush instructions, and disabling high resolution performance counters and timers.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>
						<xhtml:p>Secure programs perform bounds checking before accessing an array if the source of the array index is provided by an untrusted source such as user input. In the code below, data from array1 will not be accessed if x is out of bounds. However, if this code executes on a processor that performs speculative execution the outcome of the if statement could be mis-predicted and the access on the next line will occur with a value of x that can point to arbitrary locations in the program’s memory (out-of-bounds).</xhtml:p>
						<xhtml:p>Even though the processor rolls back the architectural effects of the mis-predicted branch, the memory accesses alter data cache state, which is not rolled back after the branch is resolved. The cache state can reveal array1[x] thereby providing a mechanism to recover any word in this program’s memory space.</xhtml:p>
					</Intro_Text>
					<Example_Code Nature="bad">
						if (x &lt; array1_size)
    						y = array2[array1[x] * 4096];
					</Example_Code>
					<Body_Text>Code snippet is from the Spectre paper: https://spectreattack.com/spectre.pdf.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="663"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1121"/>
				<Reference External_Reference_ID="REF-1122"/>
				<Reference External_Reference_ID="REF-1123"/>
				<Reference External_Reference_ID="REF-1124"/>
			 </References>
			<Content_History>
				<Submission>
					<Submission_Name>Nicole Fern</Submission_Name>
					<Submission_Organization>Tortuga Logic</Submission_Organization>
					<Submission_Date>2020-05-08</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1304" Name="Improperly Preserved Integrity of Hardware Configuration State During a Power Save/Restore Operation" Abstraction="Base" Structure="Simple" Status="Draft">
            <Description>The product performs a power save/restore
            operation, but it does not ensure that the integrity of
            the configuration state is maintained and/or verified between
	    the beginning and ending of the operation.</Description>
			<Extended_Description>
                <xhtml:p>Before powering down, the Intellectual
                Property (IP) saves current state (S) to persistent
                storage such as flash or always-on memory in order to
                optimize the restore operation.  During this process,
                an attacker with access to the persistent storage may
                alter (S) to a configuration that could potentially
                modify privileges, disable protections, and/or cause
                damage to the hardware. If the IP does not validate
                the configuration state stored in persistent memory,
                upon regaining power or becoming operational again,
                the IP could be compromised through the activation of
                an unwanted/harmful configuration.
                </xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000"/>
				<Related_Weakness Nature="PeerOf" CWE_ID="345" View_ID="1000"/>
				<Related_Weakness Nature="PeerOf" CWE_ID="1271" View_ID="1194"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
            </Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
                    <Note>Weakness introduced via missing internal integrity guarantees during power save/restore</Note>
				</Introduction>
				<Introduction>
					<Phase>Integration</Phase>
					<Note>Weakness introduced via missing external integrity verification during power save/restore</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
                    <Impact>DoS: Instability</Impact>
                    <Impact>DoS: Crash, Exit, or Restart</Impact>
                    <Impact>DoS: Resource Consumption (Other)</Impact>
                    <Impact>Gain Privileges or Assume Identity</Impact>
                    <Impact>Bypass Protection Mechanism</Impact>
                    <Impact>Alter Execution Logic</Impact>
                    <Impact>Quality Degradation</Impact>
                    <Impact>Unexpected State</Impact>
                    <Impact>Reduce Maintainability</Impact>
                    <Impact>Reduce Performance</Impact>
                    <Impact>Reduce Reliability</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
                    <Description>Inside the IP, incorporate integrity checking
                        on the configuration state via a cryptographic
                        hash. The hash can be protected inside the IP such as
                        by storing it in internal registers which never lose
                        power. Before powering down, the IP performs a hash of
                        the configuration and saves it in these persistent
                        registers. Upon restore, the IP performs a hash of the
                        saved configuration and compares it with the
                        saved hash. If they do not match, then the IP should
                        not trust the configuration.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Integration</Phase>
                    <Description>Outside the IP, incorporate integrity checking
                        of the configuration state via a trusted agent. Before
                        powering down, the trusted agent performs a hash of the
                        configuration and saves the hash in persistent storage.
                        Upon restore, the IP requests the trusted agent
                        validate its current configuration. If the
                        configuration hash is invalid, then the IP should not
                        trust the configuration.
                    </Description>
				</Mitigation>
				<Mitigation>
					<Phase>Integration</Phase>
                    <Description>Outside the IP, incorporate a protected
                        environment that prevents undetected modification of
                        the configuration state by untrusted agents. Before
                        powering down, a trusted agent saves the IP’s
                        configuration state in this protected location that
                        only it is privileged to. Upon restore, the trusted
                        agent loads the saved state into the IP.
                    </Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
                    <Intro_Text>The following pseudo code demonstrates the
                        power save/restore workflow which may lead to weakness
                        through a lack of validation of the config state after
                        restore.
                    </Intro_Text>
					<Example_Code Nature="bad" Language="C">
						void save_config_state()<xhtml:br/>
						{<xhtml:br/>
						<xhtml:div style="margin-left:10px;">
							void* cfg;<xhtml:br/>
							<xhtml:br/>
							cfg = get_config_state();<xhtml:br/>
							save_config_state(cfg);<xhtml:br/>
							<xhtml:br/>
							go_to_sleep();<xhtml:br/>
						</xhtml:div>
						}<xhtml:br/>
						<xhtml:br/>
						void restore_config_state()<xhtml:br/>
						{<xhtml:br/>
						<xhtml:div style="margin-left:10px;">
							void* cfg;<xhtml:br/>
							cfg = get_config_file();<xhtml:br/>
							load_config_file(cfg);<xhtml:br/>
						</xhtml:div>
						}<xhtml:br/>
					</Example_Code>
					<Body_Text>The following pseudo-code is the proper workflow for the integrity checking mitigation:</Body_Text>
                    <Example_Code Nature="good" Language="C">
						void save_config_state()<xhtml:br/>
						{<xhtml:br/>
						<xhtml:div style="margin-left:10px;">
							void* cfg;<xhtml:br/>
							void* sha;<xhtml:br/>
							<xhtml:br/>
							cfg = get_config_state();<xhtml:br/>
							save_config_state(cfg);<xhtml:br/>
							<xhtml:br/>
							// save hash(cfg) to trusted location<xhtml:br/>
							sha = get_hash_of_config_state(cfg);<xhtml:br/>
							save_hash(sha); <xhtml:br/>
							<xhtml:br/>
							go_to_sleep();<xhtml:br/>
						</xhtml:div>
						}<xhtml:br/>
						<xhtml:br/>
						void restore_config_state()<xhtml:br/>
						{<xhtml:br/>
						<xhtml:div style="margin-left:10px;">
							void* cfg;<xhtml:br/>
							void* sha_1, sha_2;<xhtml:br/>
							<xhtml:br/>
							cfg = get_config_file();<xhtml:br/>
							// restore hash of config from trusted memory<xhtml:br/>
							sha_1 = get_persisted_sha_value();<xhtml:br/>
							<xhtml:br/>
							sha_2 = get_hash_of_config_state(cfg);<xhtml:br/>
							if (sha_1 != sha_2)<xhtml:br/>
							<xhtml:div style="margin-left:10px;">
								assert_error_and_halt();<xhtml:br/>
							</xhtml:div>
							<xhtml:br/>
							load_config_file(cfg);<xhtml:br/>
						</xhtml:div>
						}<xhtml:br/>
                    </Example_Code>
                    <Body_Text>It must be noted that in the previous example of
                        good pseudo code, the memory (where the hash of the
                        config state is stored) must be trustworthy while the
                        hardware is between the power save and restore states.
                    </Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
			<Functional_Areas>
            	<Functional_Area>Power</Functional_Area>
         	</Functional_Areas>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="176"/>
         </Related_Attack_Patterns>
         <Content_History>
				<Submission>
					<Submission_Organization>Accellera Systems Initiative</Submission_Organization>
					<Submission_Date>2020-07-16</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Functional_Areas</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1310" Name="Missing Ability to Patch ROM Code" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>Missing an ability to patch ROM code may leave a System or System-on-Chip (SoC) in a vulnerable state.</Description>
			<Extended_Description>
				<xhtml:p>A System or System-on-Chip (SoC) that implements a boot process utilizing security mechanisms such as Root-of-Trust (RoT) typically starts by executing code from a Read-only-Memory (ROM) component. The code in ROM is immutable, hence any security vulnerabilities discovered in the ROM code can never be fixed for the systems that are already in use.</xhtml:p>
				
				<xhtml:p>A common weakness is that the ROM does not have the ability to patch if security vulnerabilities are uncovered after the system gets shipped.  This leaves the system in a vulnerable state where an adversary can compromise the SoC.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="1329" View_ID="1000" Ordinal="Primary"/>
				<Related_Weakness Nature="PeerOf" CWE_ID="1277" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
					<Note>This issue could be introduced during hardware architecture and design and can be identified later during Testing.</Note>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>This issue could be introduced during implementation and can be identified later during Testing.</Note>
                </Introduction>
                <Introduction>
                    <Phase>Integration</Phase>
                    <Note>This issue could be introduced during integration and can be identified later during Testing.</Note>
                </Introduction>
                <Introduction>
                    <Phase>Manufacturing</Phase>
                    <Note>This issue could be introduced during manufacturing and can be identified later during Testing.</Note>
                </Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
                    <Scope>Other</Scope>
                    <Impact>Varies by Context</Impact>
                    <Impact>Reduce Maintainability</Impact>
                    <Likelihood>High</Likelihood>
					<Note>A consequence of this is that the system is unable to be patched and leaves it in a vulnerable state.</Note>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Phase>Implementation</Phase>
					<Description>
					  <xhtml:ul>
					    <xhtml:li>1. Secure patch support to allow ROM code to be patched at next boot.</xhtml:li>
					    <xhtml:li>2. Support patches that can be programmed in-field or during manufacturing through hardware fuses. This feature can be used to do limited patching of device after shipping or for next batch of silicon devices manufactured without changing the full device ROM.</xhtml:li>
					  </xhtml:ul>
                    </Description>
                    <Effectiveness>Moderate</Effectiveness>
                    <Effectiveness_Notes>
                        Some part of the hardware initialization or signature verification done to authenticate patches will always be "not patchable."  Hardware-fuse-based patches will also have limitations in terms of size and the number of patches that can be supported.
                    </Effectiveness_Notes>
				</Mitigation>
            </Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example Demonstrative_Example_ID="DX-146">
					<Intro_Text>
						<xhtml:p>A System-on-Chip (SOC) implements a Root-of-Trust (RoT) in ROM to boot secure code. However, at times this ROM code might have security vulnerabilities and need to be patched. Since ROM is immutable, it can be impossible to patch.</xhtml:p>
					</Intro_Text>
					<Body_Text>ROM does not have built-in application-programming interfaces (APIs) to patch if the code is vulnerable. Implement mechanisms to patch the vulnerable ROM code.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
			<References>
				<Reference External_Reference_ID="REF-1121"/>
				<Reference External_Reference_ID="REF-1122"/>
				<Reference External_Reference_ID="REF-1123"/>
				<Reference External_Reference_ID="REF-1124"/>
			 </References>
			<Content_History>
				<Submission>
					<Submission_Name>Narasimha Kumar V Mangipudi</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-04-25</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Maintenance_Notes</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples, Maintenance_Notes</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1311" Name="Improper Translation of Security Attributes by Fabric Bridge" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>The bridge incorrectly translates security attributes from either trusted to untrusted or from untrusted to trusted when converting from one fabric protocol to another.</Description>
			<Extended_Description>
				<xhtml:p>A bridge allows IP blocks supporting different fabric protocols to be integrated into the system.  Fabric end-points or interfaces usually have dedicated signals to transport security attributes. For example, HPROT signals in AHB, AxPROT signals in AXI, and MReqInfo and SRespInfo signals in OCP.</xhtml:p>
				<xhtml:p>The values on these signals are used to indicate the security attributes of the transaction. These include the immutable hardware identity of the controller initiating the transaction, privilege level, and type of transaction (e.g., read/write, cacheable/non-cacheable, posted/non-posted).</xhtml:p>
				<xhtml:p>A weakness can arise if the bridge IP block, which translates the signals from the protocol used in the IP block endpoint to the protocol used by the central bus, does not properly translate the security attributes. As a result, the identity of the initiator could be translated from untrusted to trusted or vice-versa. This could result in access-control bypass, privilege escalation, or denial of service.</xhtml:p>
			</Extended_Description>
         <Related_Weaknesses>
            <Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
         </Related_Weaknesses>
			<Applicable_Platforms>	
				<Language Name="Verilog" Prevalence="Undetermined"/>
                <Language Name="VHDL" Prevalence="Undetermined"/>
                <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Access Control</Scope>
					<Impact>Modify Memory</Impact>
					<Impact>Read Memory</Impact>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Bypass Protection Mechanism</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>The translation must map signals in such a way that untrusted agents cannot map to trusted agents or vice-versa.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Ensure that the translation maps signals in such a way that untrusted agents cannot map to trusted agents or vice-versa.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>
						<xhtml:p>The bridge interfaces between OCP and AHB end points. OCP uses MReqInfo signal to indicate security attributes, whereas AHB uses HPROT signal to indicate the security attributes. The width of MReqInfo can be customized as needed. In this example, MReqInfo is 5-bits wide and carries the privilege level of the OCP controller.</xhtml:p>
						<xhtml:p>The values 5’h11, 5’h10, 5’h0F, 5’h0D, 5’h0C, 5’h0B, 5’h09, 5’h08, 5’h04, and 5’h02 in MReqInfo indicate that the request is coming from a privileged state of the OCP bus controller. Values 5’h1F, 5’h0E, and 5’h00 indicate untrusted, privilege state.</xhtml:p>
						<xhtml:p>Though HPROT is a 5-bit signal, we only consider the lower, two bits in this example. HPROT values 2’b00 and 2’b10 are considered trusted, and 2’b01 and 2’b11 are considered untrusted.</xhtml:p>
						<xhtml:p>The OCP2AHB bridge is expected to translate trusted identities on the controller side to trusted identities on the responder side.  Similarly, it is expected to translate untrusted identities on the controller side to untrusted identities on the responder side.</xhtml:p>
					</Intro_Text>
					<Example_Code Nature="bad" Language="Verilog">
						<xhtml:div>module ocp2ahb 
						<xhtml:br/>( 
						<xhtml:br/>  ahb_hprot, 
						<xhtml:br/>  ocp_mreqinfo 
						<xhtml:br/>); 
						<xhtml:br/>
						<xhtml:br/>output [1:0] ahb_hprot;        // output is 2 bit signal for AHB HPROT
						<xhtml:br/>input [4:0] ocp_mreqinfo;      // input is 5 bit signal from OCP MReqInfo
						<xhtml:br/>wire [6:0] p0_mreqinfo_o_temp; // OCP signal that transmits hardware identity of bus controller
						<xhtml:br/>
						<xhtml:br/>wire y;
						<xhtml:br/>reg [1:0] ahb_hprot;
						<xhtml:br/>
						<xhtml:br/>// hardware identity of bus controller is in bits 5:1 of p0_mreqinfo_o_temp signal
						<xhtml:br/>assign p0_mreqinfo_o_temp[6:0] = {1'b0, ahb_hprot[4:0], y};
						<xhtml:br/>
						<xhtml:br/>always @*
						<xhtml:br/>
						<xhtml:br/>begin
						<xhtml:br/>  case (p0_mreqinfo_o_temp[4:2])
						<xhtml:br/>    000: ahb_hprot = 2'b11;    // OCP MReqInfo to AHB HPROT mapping
						<xhtml:br/>    001: ahb_hprot = 2'b00;
						<xhtml:br/>    010: ahb_hprot = 2'b00;
						<xhtml:br/>    011: ahb_hprot = 2'b01;
						<xhtml:br/>    100: ahb_hprot = 2'b00;
						<xhtml:br/>    101: ahb_hprot = 2'b00;
						<xhtml:br/>    110: ahb_hprot = 2'b10;
						<xhtml:br/>    111: ahb_hprot = 2'b00;
						<xhtml:br/>  endcase
						<xhtml:br/>end
						<xhtml:br/>endmodule
						</xhtml:div>
					</Example_Code>
					<Body_Text>Logic in the case statement only checks for MReqInfo bits 4:2, i.e., hardware-identity bits 3:1. When ocp_mreqinfo is 5’h1F or 5’h0E, p0_mreqinfo_o_temp[2] will be 1. As a result, untrusted IDs from OCP 5’h1F and 5’h0E get translated to trusted ahb_hprot values 2’b00.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
            <Related_Attack_Pattern CAPEC_ID="233"/>
         </Related_Attack_Patterns>
         <Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Manna</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-05-24</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1312" Name="Missing Protection for Mirrored Regions in On-Chip Fabric Firewall" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>The firewall in an on-chip fabric protects the main addressed region, but it does not protect any mirrored memory or memory-mapped-IO (MMIO) regions.</Description>
			<Extended_Description>
				<xhtml:p>Few fabrics mirror memory and address ranges, where mirrored regions contain copies of the original data. This redundancy is used to achieve fault tolerance. Whatever protections the fabric firewall implements for the original region should also apply to the mirrored regions. If not, an attacker could bypass existing read/write protections by reading from/writing to the mirrored regions to leak or corrupt the original data.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
              <Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
				<Related_Weakness Nature="PeerOf" CWE_ID="1251" View_ID="1194"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Access Control</Scope>
					<Impact>Modify Memory</Impact>
					<Impact>Read Memory</Impact>
					<Impact>Bypass Protection Mechanism</Impact>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
				<Detection_Method>
					<Method>Manual Dynamic Analysis</Method>
						<Description>Using an external debugger, send write transactions to mirrored regions to test if original, write-protected regions are modified. Similarly, send read transactions to mirrored regions to test if the original, read-protected signals can be read.</Description>
						<Effectiveness>High</Effectiveness>
				</Detection_Method>
			</Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>The fabric firewall should apply the same protections as the original region to the mirrored regions.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>The fabric firewall should apply the same protections as the original region to the mirrored regions.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>A memory-controller IP block is connected to the on-chip fabric in a System on Chip (SoC).  The memory controller is configured to divide the memory into four parts: one original and three mirrored regions inside the memory. The upper two bits of the address indicate which region is being addressed. 00 indicates the original region and 01, 10, and 11 are used to address the mirrored regions. All four regions operate in a lock-step manner and are always synchronized. The firewall in the on-chip fabric is programmed to protect the assets in the memory.</Intro_Text>
					<Body_Text>The firewall only protects the original range but not the mirrored regions.</Body_Text>
					<Body_Text>The attacker (as an unprivileged user) sends a write transaction to the mirrored region. The mirrored region has an address with the upper two bits set to “10” and the remaining bits of the address pointing to an asset. The firewall does not block this write transaction. Once the write is successful, contents in the protected-memory region are also updated. Thus, the attacker can bypass existing, memory protections.</Body_Text>
					<Body_Text>Firewall should protect mirrored regions.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1134"/>
			</References>
			<Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati K. Manna</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-06-01</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1313" Name="Hardware Allows Activation of Test or Debug Logic at Runtime" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>During runtime, the hardware allows for test or debug logic (feature) to be activated, which allows for changing the state of the hardware. This feature can alter the intended behavior of the system and allow for alteration and leakage of sensitive data by an adversary.</Description>
			<Extended_Description>
				<xhtml:p>An adversary can take advantage of test or debug logic that is made accessible through the hardware during normal operation to modify the intended behavior of the system. For example, an accessible Test/debug mode may allow read/write access to any system data. Using error injection (a common test/debug feature) during a transmit/receive operation on a bus, data may be modified to produce an unintended message. Similarly, confidentiality could be compromised by such features allowing access to secrets.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
					<Note>Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.</Note>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.</Note>
				</Introduction>
				<Introduction>
					<Phase>Integration</Phase>
					<Note>Such issues could be introduced during integration and identified later during Testing or System configuration phases.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope>
					<Impact>Modify Memory</Impact>
					<Impact>Read Memory</Impact>
					<Impact>DoS: Crash, Exit, or Restart</Impact>
					<Impact>DoS: Instability</Impact>
					<Impact>DoS: Resource Consumption (CPU)</Impact>
					<Impact>DoS: Resource Consumption (Memory)</Impact>
					<Impact>DoS: Resource Consumption (Other)</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Bypass Protection Mechanism</Impact>
					<Impact>Alter Execution Logic</Impact>
					<Impact>Quality Degradation</Impact>
					<Impact>Unexpected State</Impact>
					<Impact>Reduce Performance</Impact>
					<Impact>Reduce Reliability</Impact>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Insert restrictions on when the hardware's test or debug features can be activated. For example, during normal operating modes, the hardware's privileged modes that allow access to such features cannot be activated. Configuring the hardware to only enter a test or debug mode within a window of opportunity such as during boot or configuration stage. The result is disablement of such test/debug features and associated modes during normal runtime operations.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Insert restrictions on when the hardware's test or debug features can be activated. For example, during normal operating modes, the hardware's privileged modes that allow access to such features cannot be activated. Configuring the hardware to only enter a test or debug mode within a window of opportunity such as during boot or configuration stage. The result is disablement of such test/debug features and associated modes during normal runtime operations.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Integration</Phase>
					<Description>Insert restrictions on when the hardware's test or debug features can be activated. For example, during normal operating modes, the hardware's privileged modes that allow access to such features cannot be activated. Configuring the hardware to only enter a test or debug mode within a window of opportunity such as during boot or configuration stage. The result is disablement of such test/debug features and associated modes during normal runtime operations.</Description>
				</Mitigation>
			</Potential_Mitigations>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="121"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <Content_History>
				<Submission>
					<Submission_Name>Brent Sherman</Submission_Name>
					<Submission_Organization>Accellera IP Security Assurance (IPSA) Working Group</Submission_Organization>
					<Submission_Date>2020-08-06</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1314" Name="Missing Write Protection for Parametric Data Values" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>The device does not write-protect the parametric data values for sensors that scale the sensor value, allowing untrusted software to manipulate the apparent result and potentially damage hardware or cause operational failure.</Description>
			<Extended_Description>
				<xhtml:p>Various sensors are used by hardware to detect any devices operating outside of the design limits. The threshold limit values are set by hardware fuses or trusted software such as the BIOS. These limits may be related to thermal, power, voltage, current, and frequency. Hardware mechanisms may be used to protect against alteration of the threshold limit values by untrusted software.</xhtml:p>
				<xhtml:p>The limit values are generally programmed in standard units for the type of value being read. However, the hardware-sensor blocks may report the settings in different units depending upon sensor design and operation. The raw sensor output value is converted to the desired units using a scale conversion based on the parametric data programmed into the sensor. The final converted value is then compared with the previously programmed limits.</xhtml:p>
				<xhtml:p>While the limit values are usually protected, the sensor parametric data values may not be. By changing the parametric data, safe operational limits may be bypassed.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="862" View_ID="1000" Ordinal="Primary"/>
				<Related_Weakness Nature="PeerOf" CWE_ID="1299" View_ID="1194" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Sensor IP" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
					<Note>The lack of a requirement to protect parametric values may contribute to this weakness.</Note>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>The lack of parametric value protection may be a cause of this weakness.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Availability</Scope>
					<Impact>Quality Degradation</Impact>
					<Impact>DoS: Resource Consumption (Other)</Impact>
					<Likelihood>High</Likelihood>
					<Note>Sensor value manipulation, particularly thermal or power, may allow physical damage to occur or disabling of the device by a false fault shutdown causing a Denial-Of-Service.</Note>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Access controls for sensor blocks should ensure that only trusted software is allowed to change threshold limits and sensor parametric data.</Description>
					<Effectiveness>High</Effectiveness>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>
						<xhtml:p>Malicious software executes instructions to increase power consumption to the highest possible level while causing the clock frequency to increase to its maximum value.
							Such a program executing for an extended period of time would likely overheat the device, possibly resulting in permanent damage to the device.
						</xhtml:p>
						<xhtml:p>A ring, oscillator-based temperature sensor will generally report the sensed value as
							oscillator frequency rather than degrees centigrade.  The temperature sensor will have
							calibration values that are used to convert the detected frequency into the corresponding temperature in degrees centigrade.
						</xhtml:p>
						<xhtml:p>Consider a SoC design where the critical maximum temperature limit is set in fuse values to 100C and
							is not modifiable by software.  If the scaled thermal sensor output equals or exceeds this limit, the system is commanded to shut itself down.
						</xhtml:p>
						<xhtml:p>The thermal sensor calibration values are programmable through registers that are exposed to system software.
						These registers allow software to affect the converted temperature output such that the output will never exceed the maximum temperature limit.</xhtml:p>
					</Intro_Text>
					<Example_Code Nature="bad" Language="Other">
					<xhtml:p>The sensor frequency value is scaled by applying the function:</xhtml:p>
					<xhtml:div style="margin-left:10px;">Sensed Temp = a + b * Sensor Freq</xhtml:div>
					<xhtml:p>where a and b are the programmable calibration data coefficients. Software sets a and b to zero ensuring the sensed
							temperature is always zero.</xhtml:p>
					</Example_Code>
					<Body_Text>This weakness may be addressed by preventing access to a and b.</Body_Text>
					<Example_Code Nature="good" Language="Other">
						<xhtml:p>The sensor frequency value is scaled by applying the function:</xhtml:p>
					<xhtml:div style="margin-left:10px;">Sensed Temp = a + b * Sensor Freq</xhtml:div>
						<xhtml:p>where a and b are the programmable calibration data coefficients. Untrusted software is prevented from changing the values of either a or b, 
							preventing this method of manipulating the temperature.</xhtml:p>
					</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
        <Observed_Examples>
            <Observed_Example>
               <Reference>CVE-2017-8252</Reference>
               <Description>Kernel can inject faults in computations during the execution of TrustZone leading to information disclosure in Snapdragon Auto, Snapdragon Compute, Snapdragon Connectivity, Snapdragon Consumer Electronics Connectivity, Snapdragon Consumer IOT, Snapdragon Industrial IOT, Snapdragon IoT, Snapdragon Mobile, Snapdragon Voice and Music, Snapdragon Wearables, Snapdragon Wired Infrastructure and Networking.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-8252</Link>
            </Observed_Example>
         </Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1082"/>
			</References>
			<Content_History>
				<Submission>
					<Submission_Name>Hareesh Khattri, Parbati K. Manna, and Arun Kanuparthi</Submission_Name>
					<Submission_Organization>The Intel Corporation</Submission_Organization>
					<Submission_Date>2020-07-14</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1315" Name="Improper Setting of Bus Controlling Capability in Fabric End-point" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>The bus controller enables bits in the fabric end-point to allow responder devices to control transactions on the fabric.</Description>
			<Extended_Description>
				<xhtml:p>To support reusability, certain fabric interfaces and end points provide a configurable register bit that allows IP blocks connected to the controller to access other peripherals connected to the fabric. This allows the end point to be used with devices that function as a controller or responder. If this bit is set by default in hardware, or if firmware incorrectly sets it later, a device intended to be a responder on a fabric is now capable of controlling transactions to other devices and might compromise system security.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
				<Introduction>
					<Phase>System Configuration</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Access Control</Scope>
					<Impact>Modify Memory</Impact>
					<Impact>Read Memory</Impact>
					<Impact>Bypass Protection Mechanism</Impact>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>For responder devices, the register bit in the fabric end-point that enables the bus controlling capability must be set to 0 by default. This bit should not be set during secure-boot flows. Also, writes to this register must be access-protected to prevent malicious modifications to obtain bus-controlling capability.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>For responder devices, the register bit in the fabric end-point that enables the bus controlling capability must be set to 0 by default. This bit should not be set during secure-boot flows. Also, writes to this register must be access-protected to prevent malicious modifications to obtain bus-controlling capability.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>System Configuration</Phase>
					<Description>For responder devices, the register bit in the fabric end-point that enables the bus controlling capability must be set to 0 by default. This bit should not be set during secure-boot flows. Also, writes to this register must be access-protected to prevent malicious modifications to obtain bus-controlling capability.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>A typical, phone platform consists of the main, compute core or CPU, a DRAM-memory chip, an audio codec, a baseband modem, a power-management-integrated circuit (“PMIC”), a connectivity (WiFi and Bluetooth) modem, and several other analog/RF components. The main CPU is the only component that can control transactions, and all the other components are responder-only devices. All the components implement a PCIe end-point to interface with the rest of the platform. The responder devices should have the bus-control-enable bit in the PCIe-end-point register set to 0 in hardware to prevent the devices from controlling transactions to the CPU or other peripherals.</Intro_Text>
					<Body_Text>The audio-codec chip does not have the bus-controller-enable-register bit hardcoded to 0.  There is no platform-firmware flow to verify that the bus-controller-enable bit is set to 0 in all responders.</Body_Text>
					<Body_Text>Audio codec can now master transactions to the CPU and other platform components. Potentially, it can modify assets in other platform components to subvert system security. </Body_Text>
					<Body_Text>Platform firmware includes a flow to check the configuration of bus-controller-enable bit in all responder devices. If this register bit is set on any of the responders, platform firmware sets it to 0. Ideally, the default value of this register bit should be hardcoded to 0 in RTL. It should also have access control to prevent untrusted entities from setting this bit to become bus controllers.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1135"/>
				<Reference External_Reference_ID="REF-1136"/>
			</References>
			<Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati K. Manna</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-05-19</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1316" Name="Fabric-Address Map Allows Programming of Unwarranted Overlaps of Protected and Unprotected Ranges" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>The address map of the on-chip fabric has protected and unprotected regions overlapping, allowing an attacker to bypass access control to the overlapping portion of the protected region.</Description>
			<Extended_Description>
				<xhtml:p>Various ranges can be defined in the system-address map, either in the memory or in Memory-Mapped-IO (MMIO) space. These ranges are usually defined using special range registers that contain information, such as base address and size. Address decoding is the process of determining for which range the incoming transaction is destined. To ensure isolation, ranges containing secret data are access-control protected.</xhtml:p>
				<xhtml:p>Occasionally, these ranges could overlap. The overlap could either be intentional (e.g. due to a limited number of range registers or limited choice in choosing size of the range) or unintentional (e.g. introduced by errors). Some hardware designs allow dynamic remapping of address ranges assigned to peripheral MMIO ranges. In such designs, intentional address overlaps can be created through misconfiguration by malicious software. When protected and unprotected ranges overlap, an attacker could send a transaction and potentially compromise the protections in place, violating the principle of least privilege. </xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>	
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Bus/Interface IP" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Access Control</Scope>
					<Scope>Authorization</Scope>
					<Impact>Bypass Protection Mechanism</Impact>
					<Impact>Read Memory</Impact>
					<Impact>Modify Memory</Impact>
					<Likelihood>Medium</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
				<Detection_Method>
				<Method>Automated Dynamic Analysis</Method>
				<Description>Review address map in specification to see if there are any overlapping ranges.</Description>
				<Effectiveness>High</Effectiveness>
				</Detection_Method>
				<Detection_Method>
				<Method>Manual Static Analysis</Method>
				<Description>Negative testing of access control on overlapped ranges.</Description>
				<Effectiveness>High</Effectiveness>
				</Detection_Method>
			</Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>When architecting the address map of the chip, ensure that protected and unprotected ranges are isolated and do not overlap. When designing, ensure that ranges hardcoded in Register-Transfer Level (RTL) do not overlap.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Ranges configured by firmware should not overlap. If overlaps are mandatory because of constraints such as a limited number of registers, then ensure that no assets are present in the overlapped portion.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Testing</Phase>
					<Description>Validate mitigation actions with robust testing.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>An on-chip fabric supports a 64KB address space that is memory-mapped. The fabric has two range registers that support creation of two protected ranges with specific size constraints--4KB, 8KB, 16KB or 32KB. Assets that belong to user A require 4KB, and those of user B require 20KB.  Registers and other assets that are not security-sensitive require 40KB.  One range register is configured to program 4KB to protect user A’s assets. Since a 20KB range cannot be created with the given size constraints, the range register for user B’s assets is configured as 32KB. The rest of the address space is left as open. As a result, some part of untrusted and open-address space overlaps with user B range.  </Intro_Text>
					<Body_Text>The fabric does not support least privilege, and an attacker can send a transaction to the overlapping region to tamper with user B data.</Body_Text>
					<Body_Text>Since range B only requires 20KB but is allotted 32KB, there is 12KB of reserved space.  Overlapping this region of user B data, where there are no assets, with the untrusted space will prevent an attacker from tampering with user B data. </Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
			<Observed_Examples>
				<Observed_Example>
					<Reference>CVE-2009-4419</Reference>
					<Description>Attacker can modify MCHBAR register to overlap with an attacker-controlled region, which modification prevents the SENTER instruction from properly applying VT-d protection while a Measured Launch Environment is being launched.</Description>
					<Link>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2009-4419</Link>
				</Observed_Example>
			</Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1137"/>
			</References>
			<Notes>
			  <Note Type="Maintenance">As of CWE 4.6, CWE-1260 and CWE-1316 are siblings under view 1000, but CWE-1260 might be a parent of CWE-1316. More analysis is warranted.</Note>
			</Notes>
			<Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-06-01</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1317" Name="Missing Security Checks in Fabric Bridge" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>A bridge that is connected to a fabric without security features forwards transactions to the slave without checking the privilege level of the master.  Similarly, it does not check the hardware identity of the transaction received from the slave interface of the bridge.</Description>
			<Extended_Description>
				<xhtml:p>In hardware designs, different IP blocks are connected through interconnect-bus fabrics (e.g. AHB and OCP). Within a System on Chip (SoC), the IP block subsystems could be using different bus protocols. In such a case, the IP blocks are then linked to the central bus (and to other IP blocks) through a fabric bridge. Bridges are used as bus-interconnect-routing modules that link different protocols or separate, different segments of the overall SoC interconnect.</xhtml:p>
				<xhtml:p>For overall system security, it is important that the access-control privileges associated with any fabric transaction are consistently maintained and applied, even when they are routed or translated by a fabric bridge. A bridge that is connected to a fabric without security features forwards transactions to the slave without checking the privilege level of the master and results in a weakness in SoC access-control security. The same weakness occurs if a bridge does not check the hardware identity of the transaction received from the slave interface of the bridge.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>	
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Processor IP" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Access Control</Scope>
					<Scope>Availability</Scope>
					<Impact>DoS: Crash, Exit, or Restart</Impact>
					<Impact>Bypass Protection Mechanism</Impact>
					<Impact>Read Memory</Impact>
					<Impact>Modify Memory</Impact>
					<Likelihood>Medium</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
				<Detection_Method>
				<Method>Automated Dynamic Analysis</Method>
				<Description>RTL simulation to ensure that bridge-access controls are implemented properly.</Description>
				<Effectiveness>High</Effectiveness>
				</Detection_Method>
				<Detection_Method>
				<Method>Manual Static Analysis</Method>
				<Description>Formal verification of bridge RTL to ensure that access control cannot be bypassed. </Description>
				<Effectiveness>High</Effectiveness>
				</Detection_Method>
			</Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Design includes provisions for access-control checks in the bridge for both upstream and downstream transactions.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Implement access-control checks in the bridge for both upstream and downstream transactions.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>The iLPC2AHB bridge connects a CPU (with multiple, privilege levels, such as user, super user, debug, etc.) over AHB interface to an LPC bus. Several peripherals are connected to the LPC bus. The bridge is expected to check the privilege level of the transactions initiated in the core before forwarding them to the peripherals on the LPC bus. </Intro_Text>
					<Body_Text>The bridge does not implement the checks and allows reads and writes from all privilege levels. </Body_Text>
					<Body_Text>To address this, designers should implement hardware-based checks that are either hardcoded to block untrusted agents from accessing secure peripherals or implement firmware flows that configure the bridge to block untrusted agents from making arbitrary reads or writes.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
			<Observed_Examples>
			  <Observed_Example>
			    <Reference>CVE-2019-6260</Reference>
			    <Description>Baseboard Management Controller (BMC) device implements Advanced High-performance Bus (AHB) bridges that do not require authentication for arbitrary read and write access to the BMC's physical address space from the host, and possibly the network [REF-1138].</Description>
			    <Link>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-6260</Link>
			  </Observed_Example>
			</Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="122"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1138"/>
			</References>
			<Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-05-19</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1318" Name="Missing Support for Security Features in On-chip Fabrics or Buses" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description> On-chip fabrics or buses either do not support or are not configured to support privilege separation or other security features, such as access control. </Description>
			<Extended_Description>
				<xhtml:p> Certain on-chip fabrics and buses, especially simple and low-power buses, do not support security features.  Apart from data transfer and addressing ports, some fabrics and buses do not have any interfaces to transfer privilege, immutable identity, or any other security attribute coming from the bus master.  Similarly, they do not have dedicated signals to transport security-sensitive data from slave to master, such as completions for certain types of transactions.  Few other on-chip fabrics and buses support security features and define specific interfaces/signals for transporting security attributes from master to slave or vice-versa.  However, including these signals is not mandatory and could be left unconfigured when generating the register-transfer-level (RTL) description for the fabric.  Such fabrics or buses should not be used to transport any security attribute coming from the bus master.  In general, peripherals with security assets should not be connected to such buses before the transaction from the bus master reaches the bus, unless some form of access control is performed at a fabric bridge or another intermediate module.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="693" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>	
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Processor IP" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Access Control</Scope>
					<Scope>Availability</Scope>
					<Impact>DoS: Crash, Exit, or Restart</Impact>
					<Impact>Read Memory</Impact>
					<Impact>Modify Memory</Impact>
					<Likelihood>Medium</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
				<Detection_Method>
				<Method>Architecture or Design Review</Method>
				<Description>Review the fabric specification and ensure that it contains signals to transfer security-sensitive signals. </Description>
				<Effectiveness>High</Effectiveness>
				</Detection_Method>
				<Detection_Method>
				<Method>Manual Static Analysis - Source Code</Method>
				<Description>Lack of security features can also be confirmed through manual RTL review of the fabric RTL. </Description>
				<Effectiveness>High</Effectiveness>
				</Detection_Method>
			</Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>If fabric does not support security features, implement security checks in a bridge or any component that is between the master and the fabric.  Alternatively, connect all fabric slaves that do not have any security assets under one such fabric and connect peripherals with security assets to a different fabric that supports security features. </Description>
				</Mitigation>
			</Potential_Mitigations>
			
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>Several systems on chips (SoCs) use the Advanced-Microcontroller Bus Architecture (AMBA) Advanced-Peripheral Bus (APB) protocol.  APB is a simple, low-power bus and uses the PPROT[2:0] bits to indicate the security state of the bus masters ;PPROT[0] indicates privilege, PPROT[1] indicates secure/non-secure transaction, and PPROT[2] indicates instruction/data.  Assume that there is no fabric bridge in the SoC. One of the slaves, the power-management unit, contains registers that store the thermal-shutdown limits.</Intro_Text>
					<Body_Text>The APB bus is used to connect several bus masters, each with a unique and immutable hardware identity, to several slaves. For a CPU supporting 8 potential identities (each with varying privilege levels), 16 types of outgoing transactions can be made--8 read transactions with each supported privilege level and 8 write transactions with each supported privilege level.  </Body_Text>
					<Body_Text>Since APB PPROT can only support up to 8 transaction types, access-control checks cannot be performed on transactions going to the slaves at the right granularity for all possible transaction types.  Thus, potentially, user code running on the CPU could maliciously corrupt the thermal-shutdown-configuration registers to burn the device, resulting in permanent denial of service.  </Body_Text>
					<Body_Text>In this scenario, only peripherals that need access protection from 8 of the 16 possible transaction types can be connected to the APB bus. Peripherals that require protection from the remaining 8 transaction types can be connected to a different APB bus. Alternatively, a bridge could be implemented to handle such complex scenarios before forwarding traffic to the APB bus. </Body_Text>
				</Demonstrative_Example>
				<Demonstrative_Example>
					<Intro_Text>The Open-Core-Protocol (OCP) fabric supports two configurable, width-optional signals for transporting security attributes: MReqInfo and SRespInfo.  MReqInfo is used to transport security attributes from bus master to slave, and SRespInfo is used to transport security attributes from slave to bus master. An SoC uses OCP to connect several bus masters, each with a unique and immutable hardware identity, to several slaves.  One of the bus masters, the CPU, reports the privilege level (user or super user) in addition to the unique identity.  One of the slaves, the power-management unit, contains registers that store the thermal-shutdown limits.</Intro_Text>
					<Body_Text>Since MReqInfo and SRespInfo are not mandatory, these signals are not configured when autogenerating RTL for the OCP fabric.  Thus, the fabric cannot be used to transport security attributes from bus masters to slave. </Body_Text>
					<Body_Text>Code running at user-privilege level on the CPU could maliciously corrupt the thermal-shutdown-configuration registers to burn the device and cause permanent denial of service. </Body_Text>
					<Body_Text>To address this, configure the fabric to include MReqInfo and SRespInfo signals and use these to transport security identity and privilege level to perform access-control checks at the slave interface.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1139"/>
				<Reference External_Reference_ID="REF-1140"/>
			</References>
			<Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-05-20</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1319" Name="Improper Protection against Electromagnetic Fault Injection (EM-FI)" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>The device is susceptible to electromagnetic fault injection attacks, causing device internal information to be compromised or security mechanisms to be bypassed.</Description>
			<Extended_Description>
				<xhtml:p>Electromagnetic fault injection may allow an attacker to locally and dynamically modify the signals (both internal and external) of an integrated circuit. EM-FI attacks consist of producing a local, transient magnetic field near the device, inducing current in the device wires. A typical EMFI setup is made up of a pulse injection circuit that generates a high current transient in an EMI coil, producing an abrupt magnetic pulse which couples to the target producing faults in the device, which can lead to:</xhtml:p>
				<xhtml:ul>
				<xhtml:li>Bypassing security mechanisms such as secure JTAG or Secure Boot</xhtml:li>
				<xhtml:li>Leaking device information</xhtml:li>
				<xhtml:li>Modifying program flow</xhtml:li>
				<xhtml:li>Perturbing secure hardware modules (e.g. random number generators)</xhtml:li>
				</xhtml:ul>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="693" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="System on Chip" Prevalence="Undetermined"/>
				<Technology Name="Microcontroller IP" Prevalence="Undetermined"/>
				<Technology Name="Memory IP" Prevalence="Undetermined"/>
				<Technology Name="Power Management IP" Prevalence="Undetermined"/>
				<Technology Name="Processor IP" Prevalence="Undetermined"/>
				<Technology Name="Test/Debug IP" Prevalence="Undetermined"/>
				<Technology Name="Sensor IP" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Access Control</Scope>
					<Scope>Availability</Scope>
					<Impact>Modify Memory</Impact>
					<Impact>Read Memory</Impact>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Bypass Protection Mechanism</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Phase>Implementation</Phase>
					<Description>
					  <xhtml:ul>
						<xhtml:li>1. Redundancy – By replicating critical operations and comparing the two outputs can help indicate whether a fault has been injected.</xhtml:li>
						<xhtml:li>2. Error detection and correction codes - Gay, Mael, et al. proposed a new scheme that not only detects faults injected by a malicious adversary but also automatically corrects single nibble/byte errors introduced by low-multiplicity faults.</xhtml:li>
						<xhtml:li>3. Fail by default coding - When checking conditions (switch or if) check all possible cases and fail by default because the default case in a switch (or the else part of a cascaded if-else-if construct) is used for dealing with the last possible (and valid) value without checking. This is prone to fault injection because this alternative is easily selected as a result of potential data manipulation [REF-1141].</xhtml:li>
						<xhtml:li>4. Random Behavior - adding random delays before critical operations, so that timing is not predictable.</xhtml:li>
						<xhtml:li>5. Program Flow Integrity Protection – The program flow can be secured by integrating run-time checking aiming at detecting control flow inconsistencies. One such example is tagging the source code to indicate the points not to be bypassed [REF-1147].</xhtml:li>
						<xhtml:li>6. Sensors – Usage of sensors can detect variations in voltage and current.</xhtml:li>
						<xhtml:li>7. Shields – physical barriers to protect the chips from malicious manipulation.</xhtml:li>
					  </xhtml:ul>
					</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>In many devices, security related information is stored in fuses. These fuses are loaded into shadow registers at boot time. Disturbing this transfer phase with EM-FI can lead to the shadow registers storing erroneous values potentially resulting in reduced security.</Intro_Text>
					<Body_Text>Colin O'Flynn has demonstrated an attack scenario which uses electro-magnetic glitching during booting to bypass security and gain read access to flash, read and erase access to shadow memory area (where the private password is stored). Most devices in the MPC55xx and MPC56xx series that include the Boot Assist Module (BAM) (a serial or CAN bootloader mode) are susceptible to this attack. In this paper, a GM ECU was used as a real life target. While the success rate appears low (less than 2 percent), in practice a success can be found within 1-5 minutes once the EMFI tool is setup. In a practical scenario, the author showed that success can be achieved within 30-60 minutes from a cold start.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="624"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1141"/>
				<Reference External_Reference_ID="REF-1142"/>
				<Reference External_Reference_ID="REF-1143"/>
				<Reference External_Reference_ID="REF-1144"/>
				<Reference External_Reference_ID="REF-1145"/>
				<Reference External_Reference_ID="REF-1146"/>
				<Reference External_Reference_ID="REF-1147"/>
			</References>
			<Notes>
			<Note Type="Maintenance">This entry is attack-oriented and may require significant modification in future versions, or even deprecation. It is not clear whether there is really a design "mistake" that enables such attacks, so this is not necessarily a weakness and may be more appropriate for CAPEC.</Note>
			</Notes>
			<Content_History>
				<Submission>
					<Submission_Name>Sebastien Leger, Rohini Narasipur</Submission_Name>
					<Submission_Organization>Bosch</Submission_Organization>
					<Submission_Date>2020-08-27</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1320" Name="Improper Protection for Out of Bounds Signal Level Alerts" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>Untrusted agents can disable alerts about signal conditions exceeding limits or the response mechanism that handles such alerts.
			</Description>
			<Extended_Description>
				<xhtml:p>Hardware sensors are used to detect whether a device is operating within design limits. The threshold values for these limits are set by hardware fuses or trusted software such as a BIOS.  
				Modification of these limits may be protected by hardware mechanisms.</xhtml:p>
				<xhtml:p>When device sensors detect out of bound conditions, alert signals may be generated for remedial action, which may take the form of device shutdown or throttling.</xhtml:p>
				<xhtml:p>Warning signals that are not properly secured may be disabled or used to generate spurious alerts, causing degraded performance or denial-of-service (DoS).
				These alerts may be masked by untrusted software. Examples of these alerts involve thermal and power sensor alerts.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="System on Chip" Prevalence="Undetermined"/>
				<Technology Name="Microcontroller IP" Prevalence="Undetermined"/>
				<Technology Name="Memory IP" Prevalence="Undetermined"/>
				<Technology Name="Power Management IP" Prevalence="Undetermined"/>
				<Technology Name="Processor IP" Prevalence="Undetermined"/>
				<Technology Name="Test/Debug IP" Prevalence="Undetermined"/>
				<Technology Name="Sensor IP" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Availability</Scope>
					<Impact>DoS: Instability</Impact>
					<Impact>DoS: Crash, Exit, or Restart</Impact>
					<Impact>Reduce Reliability</Impact>
					<Impact>Unexpected State</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Alert signals generated by critical events should be protected from access by untrusted agents. Only hardware or trusted firmware modules should be able to alter the alert configuration.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>
						<xhtml:p>Consider a platform design where a Digital-Thermal Sensor (DTS) is used to monitor temperature and compare that output against a threshold value.
							If the temperature output equals or exceeds the threshold value, the DTS unit sends an alert signal to the processor.</xhtml:p>
						<xhtml:p>The processor, upon getting the alert, input triggers system shutdown. The alert signal is handled as a General-Purpose-I/O (GPIO) pin in input mode.</xhtml:p>
					</Intro_Text>
					<Example_Code Nature="bad">The processor-GPIO controller exposes software-programmable controls that allow untrusted software to reprogram the state of the GPIO pin.</Example_Code>
					<Body_Text>Reprogramming the state of the GPIO pin allows malicious software to trigger spurious alerts or to set the alert pin to a zero value so that thermal sensor alerts are not received by the processor.</Body_Text>
					<Example_Code Nature="good">The GPIO alert-signal pin is blocked from untrusted software access and is controlled only by trusted software, such as the System BIOS.</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
         </Related_Attack_Patterns>
         <Content_History>
				<Submission>
					<Submission_Name>Hareesh Khattri, Arun Kanuparthi, Parbati K. Manna</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-05-29</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1323" Name="Improper Management of Sensitive Trace Data" Abstraction="Base" Structure="Simple" Status="Draft">
            <Description>Trace data collected from several sources on the
                System-on-Chip (SoC) is stored in unprotected locations or
                transported to untrusted agents.</Description>
			<Extended_Description>
                <xhtml:p>To facilitate verification of complex System-on-Chip
                    (SoC) designs, SoC integrators add specific IP blocks that
                    trace the SoC's internal signals in real-time. This
                    infrastructure enables observability of the SoC's internal
                    behavior, validation of its functional design,
                    and detection of hardware and software bugs. Such tracing
                    IP blocks collect traces from several sources on the SoC
                    including the CPU, crypto coprocessors, and on-chip fabrics. Traces collected from these sources are then
                    aggregated inside trace IP block and forwarded to trace
                    sinks, such as debug-trace ports that facilitate debugging by
                    external hardware and software debuggers.</xhtml:p>
					<xhtml:p>Since
                    these traces are collected from several security-sensitive
                    sources, they must be protected against untrusted
                    debuggers. If they are stored in unprotected memory, an
                    untrusted software debugger can access these traces and
                    extract secret information. Additionally, if
                    security-sensitive traces are not tagged as secure, an
                    untrusted hardware debugger might access them to extract
                    confidential information.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
                <Technology Class="System on Chip" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Impact>Read Memory</Impact>
					<Note>An adversary can read secret values if they are captured in debug traces and stored unsafely.</Note>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Tag traces to indicate owner and debugging privilege level (designer, OEM, or end user) needed to access that trace.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
                    <Intro_Text>In a SoC, traces generated from sources
                        include security-sensitive IP blocks such as CPU (with
                        tracing information such as instructions executed and
                        memory operands), on-chip fabric (e.g., memory-transfer
                        signals, transaction type and destination, and
                        on-chip-firewall-error signals), power-management
                        IP blocks (e.g., clock- and power-gating signals), and
                        cryptographic coprocessors (e.g., cryptographic keys and
                        intermediate values of crypto operations), among
                        other non-security-sensitive IP blocks including timers
                        and other functional blocks. The collected traces are
                        then forwarded to the debug and trace interface used by
                        the external hardware debugger.</Intro_Text>
                    <Example_Code Nature="bad" Language="Other">The traces do
                        not have any privilege level attached to them. All
                        collected traces can be viewed by any debugger (i.e., SoC
                        designer, OEM debugger, or end user).</Example_Code>
                    <Example_Code Nature="good" Language="Other">Some of the
                        traces are SoC-design-house secrets, while some are OEM
                        secrets. Few are end-user secrets and the rest are
                        not security-sensitive. Tag all traces with the
                        appropriate, privilege level at the source. The bits
                        indicating the privilege level must be immutable in
                        their transit from trace source to the final, trace
                        sink. Debugger privilege level must be checked before
                        providing access to traces. </Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="150"/>
            <Related_Attack_Pattern CAPEC_ID="167"/>
            <Related_Attack_Pattern CAPEC_ID="545"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1150"/>
				<Reference External_Reference_ID="REF-1151"/>
			</References>
			<Content_History>
				<Submission>
					<Submission_Name>Hareesh Khattri, Parbati K. Manna, and Arun Kanuparthi</Submission_Name>
					<Submission_Organization>The Intel Corporation</Submission_Organization>
					<Submission_Date>2020-07-20</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1324" Name="Sensitive Information Accessible by Physical Probing of JTAG Interface" Abstraction="Base" Structure="Simple" Status="Draft">
            <Description>Sensitive information in clear text on the JTAG
                interface may be examined by an eavesdropper, e.g.
                by placing a probe device on the interface such as a logic
                analyzer, or a corresponding software technique.
            </Description>
			<Extended_Description>
                <xhtml:p>On a debug configuration with a remote host,
                    unbeknownst to the host/user, an attacker with physical
                    access to a target system places a probing device on the
                    debug interface or software related to the JTAG port e.g.
                    device driver. While the authorized host/user performs
                    sensitive operations to the target system, the attacker
                    uses the probe to collect the JTAG traffic. 
                </xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="300" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
                <Technology Name="Test/Debug IP" Prevalence="Undetermined"/>
                <Technology Class="System on Chip" Prevalence="Undetermined"/>
            </Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
                    <Note>May be introduced when design does not plan for an attacker having physical access while legitimate user is remotely operating device</Note>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Impact>Read Memory</Impact>
					<Impact>Read Files or Directories</Impact>
					<Impact>Read Application Data</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Manufacturing</Phase>
					<Description>Disable permanently the JTAG interface before releasing the system to untrusted users.</Description>
                    <Effectiveness>High</Effectiveness>
				</Mitigation>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Encrypt all information (traffic) on the JTAG interface using an approved algorithm (such as recommended by NIST). Encrypt the path from inside the chip to the trusted user application.</Description>
                    <Effectiveness>High</Effectiveness>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Block access to secret data from JTAG.</Description>
                    <Effectiveness>High</Effectiveness>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
                    <Intro_Text>
                        A TAP accessible register is read/written by a JTAG
                        based tool, for internal tool use for an authorized
                        user.  The JTAG based tool does not provide access to
                        this data to an unauthorized user of the tool.
                        However, the user can connect a probing device and
                        collect the values directly from the JTAG interface, if
                        no additional protections are employed.
                    </Intro_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="150"/>
            <Related_Attack_Pattern CAPEC_ID="167"/>
            <Related_Attack_Pattern CAPEC_ID="545"/>
         </Related_Attack_Patterns>
         <Content_History>
				<Submission>
					<Submission_Name>Accellera IP Security Assurance (IPSA) Working Group</Submission_Name>
					<Submission_Organization>Accellera Systems Initiative</Submission_Organization>
					<Submission_Date>2020-10-01</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1326" Name="Missing Immutable Root of Trust in Hardware" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>A missing immutable root of trust in the hardware results in the ability to bypass secure boot or execute untrusted or adversarial boot code.</Description>
			<Extended_Description>
				<xhtml:p>A System-on-Chip (SoC) implements secure boot by verifying or authenticating signed boot code. The signing of the code is achieved by an entity that the SoC trusts.  Before executing the boot code, the SoC verifies that the code or the public key with which the code has been signed has not been tampered with. The other data upon which the SoC depends are system-hardware settings in fuses such as whether “Secure Boot is enabled”. These data play a crucial role in establishing a Root of Trust (RoT) to execute secure-boot flows.</xhtml:p>
				<xhtml:p>One of the many ways RoT is achieved is by storing the code and data in memory or fuses. This memory should be immutable, i.e., once the RoT is programmed/provisioned in memory, that memory should be locked and prevented from further programming or writes. If the memory contents (i.e., RoT) are mutable, then an adversary can modify the RoT to execute their choice of code, resulting in a compromised secure boot.</xhtml:p>
				<xhtml:p>Note that, for components like ROM, secure patching/update features should be supported to allow authenticated and authorized updates in the field. </xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="693" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>	
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Security IP" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>Such issues could be introduced during policy definition, hardware architecture, design, manufacturing, and/or provisioning and can be identified later during testing or system configuration phases.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Authentication</Scope>
					<Scope>Authorization</Scope>
					<Impact>Gain Privileges or Assume Identity</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
					<Impact>Modify Memory</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
				<Detection_Method>
				<Method>Automated Dynamic Analysis</Method>
				<Description>Automated testing can verify that RoT components are immutable.</Description>
				<Effectiveness>High</Effectiveness>
				</Detection_Method>
				<Detection_Method>
				<Method>Architecture or Design Review</Method>
				<Description>Root of trust elements and memory should be part of architecture and design reviews.</Description>
				<Effectiveness>High</Effectiveness>
				</Detection_Method>
			</Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>When architecting the system, the RoT should be designated for storage in a memory that does not allow further programming/writes.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>During implementation and test, the RoT memory location should be demonstrated to not allow further programming/writes. </Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>The RoT is stored in memory. This memory can be modified by an adversary. For example, if an SoC implements “Secure Boot” by storing the boot code in an off-chip/on-chip flash, the contents of the flash can be modified by using a flash programmer. Similarly, if the boot code is stored in ROM (Read-Only Memory) but the public key or the hash of the public key (used to enable “Secure Boot”) is stored in Flash or a memory that is susceptible to modifications or writes, the implementation is vulnerable.</Intro_Text>
					<Body_Text>In general, if the boot code, key materials and data that enable “Secure Boot” are all mutable, the implementation is vulnerable.</Body_Text>
					<Body_Text>Good architecture defines RoT as immutable in hardware. One of the best ways to achieve immutability is to store boot code, public key or hash of the public key and other relevant data in Read-Only Memory (ROM) or One-Time Programmable (OTP) memory that prevents further programming or writes.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="180"/>
            <Related_Attack_Pattern CAPEC_ID="68"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1152"/>
				<Reference External_Reference_ID="REF-1153"/>
			</References>
			<Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-04-25</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1328" Name="Security Version Number Mutable to Older Versions" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>Security-version number in hardware is mutable, resulting in the ability to downgrade (roll-back) the boot firmware to vulnerable code versions.</Description>
			<Extended_Description>
				<xhtml:p>A System-on-Chip (SoC) implements secure boot or verified boot. It might support a security version number, which prevents downgrading the current firmware to a vulnerable version. Once downgraded to a previous version, an adversary can launch exploits on the SoC and thus compromise the security of the SoC. These downgrade attacks are also referred to as roll-back attacks.</xhtml:p>
				<xhtml:p>The security version number must be stored securely and persistently across power-on resets. A common weakness is that the security version number is modifiable by an adversary, allowing roll-back or downgrade attacks or, under certain circumstances, preventing upgrades (i.e. Denial-of-Service on upgrades). In both cases, the SoC is in a vulnerable state.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="285" View_ID="1000" Ordinal="Primary"/>
				<Related_Weakness Nature="PeerOf" CWE_ID="757" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>	
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Security IP" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>Such issues could be introduced during hardware architecture and design, and can be identified later during testing or system configuration phases.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Authentication</Scope>
					<Scope>Authorization</Scope>
					<Impact>Other</Impact>
					<Likelihood>High</Likelihood>
					<Note>Impact includes roll-back or downgrade to a vulnerable version of the firmware or DoS (prevent upgrades).</Note>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
				<Detection_Method>
				<Method>Automated Dynamic Analysis</Method>
				<Description>Mutability of stored security version numbers and programming with older firmware images should be part of automated testing.</Description>
				<Effectiveness>High</Effectiveness>
				</Detection_Method>
				<Detection_Method>
				<Method>Architecture or Design Review</Method>
				<Description>Anti-roll-back features should be reviewed as part of Architecture or Design review.</Description>
				<Effectiveness>High</Effectiveness>
				</Detection_Method>
			</Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>When architecting the system, security version data should be designated for storage in registers that are either read-only or have access controls that prevent modification by an untrusted agent.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>During implementation and test, security version data should be demonstrated to be read-only and access controls should be validated.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>A new version of firmware is signed with a security version number higher than the previous version. During the firmware update process the SoC checks for the security version number and upgrades the SoC firmware with the latest version. This security version number is stored in persistent memory upon successful upgrade for use across power-on resets. </Intro_Text>
					<Body_Text>In general, if the security version number is mutable, the implementation is vulnerable. A mutable security version number allows an adversary to change the security version to a lower value to allow roll-back or to a higher value to prevent future upgrades. </Body_Text>
					<Body_Text>The security version number should be stored in immutable hardware such as fuses, and the writes to these fuses should be highly access-controlled with appropriate authentication and authorization protections.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="176"/>
         </Related_Attack_Patterns>
         <Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-04-25</Submission_Date>
				</Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
				</Modification>
			</Content_History>
		</Weakness>
      <Weakness ID="1330" Name="Remanent Data Readable after Memory Erase" Abstraction="Variant" Structure="Simple" Status="Draft">
			<Description>Confidential information stored in memory circuits is readable or recoverable after being cleared or erased.</Description>
			<Extended_Description>
				<xhtml:p>Data remanence occurs when stored, memory content is not fully lost after a memory-clear or -erase operation. Confidential memory contents can still be readable through data remanence in the hardware.</xhtml:p>
				<xhtml:p>Data remanence can occur because of performance optimization or memory organization during 'clear' or 'erase' operations, like a design that allows the memory-organization metadata (e.g., file pointers) to be erased without erasing the actual memory content. To protect against this weakness, memory devices will often support different commands for optimized memory erase and explicit secure erase.</xhtml:p>
				<xhtml:p>Data remanence can also happen because of the physical properties of memory circuits in use. For example, static, random-access-memory (SRAM) and dynamic, random-access-memory (DRAM) data retention is based on the charge retained in the memory cell, which depends on factors such as power supply, refresh rates, and temperature.</xhtml:p>
				<xhtml:p>Other than explicit erase commands, self-encrypting, secure-memory devices can also support secure erase through cryptographic erase commands. In such designs, only the decryption keys for encrypted data stored on the device are erased. That is, the stored data are always remnant in the media after a cryptographic erase. However, only the encrypted data can be extracted. Thus, protection against data recovery in such designs relies on the strength of the encryption algorithm.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="1301" View_ID="1000" Ordinal="Primary"/>
				<Related_Weakness Nature="ChildOf" CWE_ID="1301" View_ID="1194" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Security IP" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
               		<Phase>Architecture and Design</Phase>
            	</Introduction>
           		<Introduction>
               		<Phase>Implementation</Phase>
            	</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Impact>Modify Memory</Impact>
					<Impact>Read Memory</Impact>
					<Note>Confidential data are readable to untrusted agent.</Note>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
				<Detection_Method>
					<Method>Architecture or Design Review</Method>
					<Description>
					<xhtml:ol>
					<xhtml:li>Testing of memory-device contents after clearing or erase commands.</xhtml:li>
					<xhtml:li>Dynamic analysis of memory contents during device operation to detect specific, confidential assets.</xhtml:li>
					<xhtml:li>Architecture and design analysis of memory clear and erase operations.</xhtml:li>
					</xhtml:ol>
					</Description>
				</Detection_Method>
				<Detection_Method>
					<Method>Dynamic Analysis with Manual Results Interpretation</Method>
					<Description>
					<xhtml:ol>
					<xhtml:li>Testing of memory-device contents after clearing or erase commands.</xhtml:li>
					<xhtml:li>Dynamic analysis of memory contents during device operation to detect specific, confidential assets.</xhtml:li>
					<xhtml:li>Architecture and design analysis of memory clear and erase operations.</xhtml:li>
					</xhtml:ol>
					</Description>
				</Detection_Method>
			</Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>
					<xhtml:ol>
					<xhtml:li>Support for secure-erase commands that apply multiple cycles of overwriting memory with known patterns and of erasing actual content.</xhtml:li>
					<xhtml:li>Support for cryptographic erase in self-encrypting, memory devices.</xhtml:li>
					<xhtml:li>External, physical tools to erase memory such as ultraviolet-rays-based erase of Electrically erasable, programmable, read-only memory (EEPROM).</xhtml:li>
					<xhtml:li>Physical destruction of media device. This is done for repurposed or scrapped devices that are no longer in use.</xhtml:li>
					</xhtml:ol>
					</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>Consider a device that uses flash memory for non-volatile-data storage. To optimize flash-access performance or reliable-flash lifetime, the device might limit the number of flash writes/erases by maintaining some state in internal SRAM and only committing changes to flash memory periodically.</Intro_Text>
					<Body_Text>The device also supports user reset to factory defaults with the expectation that all personal information is erased from the device after this operation. On factory reset, user files are erased using explicit, erase commands supported by the flash device.</Body_Text>
					<Body_Text>In the given, system design, the flash-file system can support performance-optimized erase such that only the file metadata are erased and not the content. If this optimized erase is used for files containing user data during factory-reset flow, then device, flash memory can contain remanent data from these files.</Body_Text>
					<Body_Text>On device-factory reset, the implementation might not erase these copies, since the file organization has changed and the flash file system does not have the metadata to track all previous copies.</Body_Text>
					<Body_Text>A flash-memory region that is used by a flash-file system should be fully erased as part of the factory-reset flow. This should include secure-erase flow for the flash media such as overwriting patterns multiple times followed by erase.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
			<Observed_Examples>
				<Observed_Example>
					<Reference>CVE-2019-8575</Reference>
					<Description>Firmware Data Deletion Vulnerability in which a base station factory reset might not delete all user information. The impact of this enables a new owner of a used device that has been "factory-default reset" with a vulnerable firmware version can still retrieve, at least, the previous owner's wireless network name, and the previous owner's wireless security (such as WPA2) key. This issue was addressed with improved, data deletion.</Description>
					<Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-8575</Link>
				</Observed_Example>
			</Observed_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="150"/>
            <Related_Attack_Pattern CAPEC_ID="37"/>
            <Related_Attack_Pattern CAPEC_ID="545"/>
         </Related_Attack_Patterns>
         <References>
				<Reference External_Reference_ID="REF-1154"/>
			</References>
			<Content_History>
				<Submission>
					<Submission_Name>Hareesh Khattri, Arun Kanuparthi, Parbati K. Manna</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-06-10</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1331" Name="Improper Isolation of Shared Resources in Network On Chip (NoC)" Abstraction="Base" Structure="Simple" Status="Stable">
			<Description>The Network On Chip (NoC) does not isolate or incorrectly isolates its on-chip-fabric and internal resources such that they are shared between trusted and untrusted agents, creating timing channels.</Description>
			<Extended_Description>
			  <xhtml:p>Typically, network on chips (NoC) have many internal resources that are shared between packets from different trust domains. These resources include internal buffers, crossbars and switches, individual ports, and channels. The sharing of resources causes contention and introduces interference between differently trusted domains, which poses a security threat via a timing channel, allowing attackers to infer data that belongs to a trusted agent. This may also result in introducing network interference, resulting in degraded throughput and latency.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="653" View_ID="1000" Ordinal="Primary"/>
			  <Related_Weakness Nature="ChildOf" CWE_ID="668" View_ID="1000"/>
			  <Related_Weakness Nature="PeerOf" CWE_ID="1189" View_ID="1194"/>
			</Related_Weaknesses>
		 <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Primary</Ordinality>
            </Weakness_Ordinality>
		 </Weakness_Ordinalities>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Security IP" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Background_Details>
			  <Background_Detail>
			    <xhtml:p>"Network-on-chip" (NoC) is a commonly-used term used for hardware interconnect fabrics used by multicore Systems-on-Chip (SoC).  Communication between modules on the chip uses packet-based methods, with improved efficiency and scalability compared to bus architectures [REF-1241].</xhtml:p>
			  </Background_Detail>
			</Background_Details>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Availability</Scope>
					<Impact>DoS: Resource Consumption (Other)</Impact>
					<Impact>Varies by Context</Impact>
					<Impact>Other</Impact>
					<Likelihood>Medium</Likelihood>
					<Note>Attackers may infer data that belongs to a trusted agent; the methods used to perform this attack may result in noticeably increased resource consumption.</Note>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
			  <Detection_Method>
			    <Method>Manual Analysis</Method>
			    <Description>Providing marker flags to send through the interfaces coupled with examination of which users are able to read or manipulate the flags will help verify that the proper isolation has been achieved and is effective.</Description>
			    <Effectiveness>Moderate</Effectiveness>
			  </Detection_Method>
			</Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Phase>Implementation</Phase>
					<Description>Implement priority-based arbitration inside the NoC and have dedicated buffers or virtual channels for routing secret data from trusted agents.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>Consider a NoC that implements a one-dimensional mesh network with four nodes. This supports two flows: Flow A from node 0 to node 3 (via node 1 and node 2) and Flow B from node 1 to node 2. Flows A and B share a common link between Node 1 and Node 2.  Only one flow can use the link in each cycle.</Intro_Text>
					<Body_Text>One of the masters to this NoC implements a cryptographic algorithm (RSA), and another master to the NoC is a core that can be exercised by an attacker. The RSA algorithm performs a modulo multiplication of two large numbers and depends on each bit of the secret key. The algorithm examines each bit in the secret key and only performs multiplication if the bit is 1. This algorithm is known to be prone to timing attacks. Whenever RSA performs multiplication, there is additional network traffic to the memory controller. One of the reasons for this is cache conflicts.</Body_Text>
					<Body_Text>Since this is a one-dimensional mesh, only one flow can use the link in each cycle.  Also, packets from the attack program and the RSA program share the output port of the network-on-chip.  This contention results in network interference, and the throughput and latency of one flow can be affected by the other flow's demand.</Body_Text>
					<Example_Code Nature="attack">
					  The attacker runs a loop program on the core they control, and this causes a cache miss in every iteration for the RSA algorithm. Thus, by observing network-traffic bandwidth and timing, the attack program can determine when the RSA algorithm is doing a multiply operation (i.e., when the secret key bit is 1) and eventually extract the entire, secret key.</Example_Code>
					<Body_Text>There may be different ways to fix this particular weakness.</Body_Text>
					<Example_Code Nature="good" Language="Other">
					Implement priority-based arbitration inside the NoC and have dedicated buffers or virtual channels for routing secret data from trusted agents.
					</Example_Code>
				</Demonstrative_Example>
			</Demonstrative_Examples>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="124"/>
         </Related_Attack_Patterns>
         <References>
	   <Reference External_Reference_ID="REF-1155"/>
	   <Reference External_Reference_ID="REF-1241"/>
	   <Reference External_Reference_ID="REF-1242"/>
	 </References>
	 <Content_History>
	   <Submission>
	     <Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati K. Manna</Submission_Name>
	     <Submission_Organization>Intel Corporation</Submission_Organization>
	     <Submission_Date>2020-05-23</Submission_Date>
	   </Submission>
	   <Contribution Type="Content">
	     <Contribution_Name>Hareesh Khattri</Contribution_Name>
	     <Contribution_Organization>Intel Corporation</Contribution_Organization>
	     <Contribution_Date>2021-10-22</Contribution_Date>
	     <Contribution_Comment>provided references and background information</Contribution_Comment>
	   </Contribution>
	 </Content_History>
       </Weakness>
      <Weakness ID="1332" Name="Improper Handling of Faults that Lead to Instruction Skips" Abstraction="Base" Structure="Simple" Status="Stable">
            <Description>The device is missing or incorrectly implements circuitry or sensors that detect and mitigate the skipping of security-critical CPU instructions when they occur.</Description>
			<Extended_Description>
              <xhtml:p>The operating conditions of hardware may change
              in ways that cause unexpected behavior to occur,
              including the skipping of security-critical CPU
              instructions. Generally, this can occur due to
              electrical disturbances or when the device operates
              outside of its expected conditions.</xhtml:p>
			  <xhtml:p>In practice, application code may contain
			  conditional branches that are security-sensitive (e.g.,
			  accepting or rejecting a user-provided password). These
			  conditional branches are typically implemented by a
			  single conditional branch instruction in the program
			  binary which, if skipped, may lead to effectively
			  flipping the branch condition - i.e., causing the wrong
			  security-sensitive branch to be taken. This affects
			  processes such as firmware authentication, password
			  verification, and other security-sensitive decision
			  points.</xhtml:p>
			  <xhtml:p>Attackers can use fault injection techniques to
			  alter the operating conditions of hardware so that
			  security-critical instructions are skipped more
			  frequently or more reliably than they would in a
			  "natural" setting.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="PeerOf" CWE_ID="1247" View_ID="1194" Ordinal="Primary"/>
				<Related_Weakness Nature="ChildOf" CWE_ID="703" View_ID="1000"/>
			</Related_Weaknesses>
		 <Weakness_Ordinalities>
            <Weakness_Ordinality>
               <Ordinality>Primary</Ordinality>
            </Weakness_Ordinality>
		 </Weakness_Ordinalities>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
                <Technology Class="System on Chip" Prevalence="Undetermined"/>
            </Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
                    <Note>Failure to design appropriate countermeasures to common fault injection techniques can manifest this weakness.</Note>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>This weakness can arise if the hardware design incorrectly implements countermeasures to prevent fault injection.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Scope>Authentication</Scope>
                    <Impact>Bypass Protection Mechanism</Impact>
                    <Impact>Alter Execution Logic</Impact>
			        <Impact>Unexpected State</Impact>
					<Likelihood>High</Likelihood>
                    <Note>Depending on the context, instruction skipping can
                        have a broad range of consequences related to the
                        generic bypassing of security critical code.</Note>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
			  <Detection_Method>
			    <Method>Automated Static Analysis</Method>
			    <Description>This weakness can be found using automated static analysis once a developer has indicated which code paths are critical to protect.</Description>
			    <Effectiveness>Moderate</Effectiveness>
			  </Detection_Method>
			  <Detection_Method>
			    <Method>Simulation / Emulation</Method>
			    <Description>This weakness can be found using automated dynamic analysis. Both emulation of a CPU with instruction skips, as well as RTL simulation of a CPU IP, can indicate parts of the code that are sensitive to faults due to instruction skips.</Description>
			    <Effectiveness>Moderate</Effectiveness>
			  </Detection_Method>
			  <Detection_Method>
			    <Method>Manual Analysis</Method>
			    <Description>This weakness can be found using manual (static) analysis. The analyst has security objectives that are matched against the high-level code. This method is less precise than emulation, especially if the analysis is done at the higher level language rather than at assembly level.</Description>
			    <Effectiveness>Moderate</Effectiveness>
			  </Detection_Method>
			</Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Design strategies for ensuring safe failure if inputs such as Vcc are modified out of acceptable ranges.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Design strategies for ensuring safe behavior if instructions attempt to be skipped.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
                    <Description>Ensure that architected fault mitigations are
                        strong enough in practice. For example, a low power
                        detection mechanism that takes 50 clock cycles to
                        trigger at lower voltages may be an insufficient security mechanism if the instruction counter
                        has already progressed with no other CPU activity occurring.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
			  <Demonstrative_Example>
			    <Intro_Text>A smart card contains authentication credentials that are used as authorization to enter a building. The credentials are only accessible when a correct PIN is presented to the card.</Intro_Text>
			    <Example_Code Nature="bad">
			      The card emits the credentials when a voltage anomaly is injected into the power line to the device at a particular time after providing an incorrect PIN to the card, causing the internal program to accept the incorrect PIN.</Example_Code>
			    <Body_Text>There are several ways this weakness could be fixed.</Body_Text>
			    <Example_Code Nature="good"><xhtml:ul>
			      <xhtml:li>add an internal filter or internal power supply in series with the power supply pin on the device</xhtml:li>
			      <xhtml:li>add sensing circuitry to reset the device if out of tolerance conditions are detected</xhtml:li>
			      <xhtml:li>add additional execution sensing circuits to monitor the execution order for anomalies and abort the action or reset the device under fault conditions</xhtml:li>
			      </xhtml:ul>
			    </Example_Code>
			  </Demonstrative_Example>
			</Demonstrative_Examples>
			<Observed_Examples>
			  <Observed_Example>
				<Reference>CVE-2019-15894</Reference>
				<Description>fault injection attack bypasses the verification mode, potentially allowing arbitrary code execution.</Description>
				<Link>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-15894</Link>
			  </Observed_Example>
			</Observed_Examples>
			<Functional_Areas>
            	<Functional_Area>Power</Functional_Area>
         	</Functional_Areas>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="624"/>
         </Related_Attack_Patterns>
         <References>
                <Reference External_Reference_ID="REF-1160"/>
                <Reference External_Reference_ID="REF-1161"/>
		<Reference External_Reference_ID="REF-1222"/>
		<Reference External_Reference_ID="REF-1223"/>
		<Reference External_Reference_ID="REF-1224"/>
            </References>
			<Content_History>
				<Submission>
					<Submission_Name>Jasper van Woudenberg</Submission_Name>
					<Submission_Organization>Riscure</Submission_Organization>
					<Submission_Date>2020-10-14</Submission_Date>
				</Submission>
                <Modification>
					<Modification_Name>Jasper van Woudenberg</Modification_Name>
					<Modification_Organization>Riscure</Modification_Organization>
					<Modification_Date>2021-01-11</Modification_Date>
                </Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-03-15</Modification_Date>
					<Modification_Comment>updated Description, Functional_Areas, Potential_Mitigations, References</Modification_Comment>
				</Modification>
				<Contribution Type="Content">
				  <Contribution_Name>Jasper van Woudenberg</Contribution_Name>
				  <Contribution_Organization>Riscure</Contribution_Organization>
				  <Contribution_Date>2021-10-11</Contribution_Date>
				  <Contribution_Comment>Provided detection methods and feedback on demonstrative example</Contribution_Comment>
				</Contribution>
			</Content_History>
		</Weakness>
      <Weakness ID="1334" Name="Unauthorized Error Injection Can Degrade Hardware Redundancy" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>An unauthorized agent can inject errors into a redundant block to deprive the system of redundancy or put the system in a degraded operating mode.</Description>
			<Extended_Description>
				<xhtml:p>To ensure the performance and functional reliability of certain components, hardware designers can implement hardware blocks for redundancy in the case that others fail. This redundant block can be prevented from performing as intended if the design allows unauthorized agents to inject errors into it. In this way, a path with injected errors may become unavailable to serve as a redundant channel. This may put the system into a degraded mode of operation which could be exploited by a subsequent attack.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="284" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
					<Note>Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.</Note>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.</Note>
                </Introduction>
                <Introduction>
                    <Phase>Integration</Phase>
                    <Note>Such issues could be introduced during integration and identified later during Testing or System Configuration phases.</Note>
                </Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Integrity</Scope>
					<Scope>Availability</Scope> 
                    <Impact>DoS: Crash, Exit, or Restart</Impact>
                    <Impact>DoS: Instability</Impact>
                    <Impact>Quality Degradation</Impact>
					<Impact>DoS: Resource Consumption (CPU)</Impact>
					<Impact>DoS: Resource Consumption (Memory)</Impact>
                    <Impact>DoS: Resource Consumption (Other)</Impact>
                    <Impact>Reduce Performance</Impact>
					<Impact>Reduce Reliability</Impact>
					<Impact>Unexpected State</Impact>					
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Ensure the design does not allow error injection in modes intended for normal run-time operation. Provide access controls on interfaces for injecting errors.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>Disallow error injection in modes which are expected to be used for normal run-time operation. Provide access controls on interfaces for injecting errors.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Integration</Phase>
					<Description>Add an access control layer atop any unprotected interfaces for injecting errors.</Description>
				</Mitigation>
			</Potential_Mitigations>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="624"/>
         </Related_Attack_Patterns>
         <Content_History>
				<Submission>
					<Submission_Name>James Pangburn</Submission_Name>
					<Submission_Organization>Accellera IP Security Assurance (IPSA) Working Group</Submission_Organization>
					<Submission_Date>2020-07-29</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1338" Name="Improper Protections Against Hardware Overheating" Abstraction="Base" Structure="Simple" Status="Draft">
			<Description>A hardware device is missing or has inadequate protection features to prevent overheating.</Description>
			<Extended_Description>
				<xhtml:p>Hardware, electrical circuits, and semiconductor silicon have thermal side effects, such that some of the energy consumed by the device gets dissipated as heat and increases the temperature of the device. For example, in semiconductors, higher-operating frequency of silicon results in higher power dissipation and heat. The leakage current in CMOS circuits increases with temperature, and this creates positive feedback that can result in thermal runaway and damage the device permanently.</xhtml:p>
				<xhtml:p>Any device lacking protections such as thermal sensors, adequate platform cooling or thermal insulation is susceptible to attacks by malicious software that might deliberately operate the device in modes that result in overheating. This can be used as an effective denial of service (DoS) or permanent denial of service (PDoS) attack.</xhtml:p>
				<xhtml:p>Depending on the type of hardware device and its expected usage, such thermal overheating can also cause safety hazards and reliability issues. Note that battery failures can also cause device overheating but the mitigations and examples included in this submission cannot reliably protect against a battery failure. </xhtml:p>
				<xhtml:p>There can be similar weaknesses with lack of protection from attacks based on overvoltage or overcurrent conditions. However, thermal heat is generated by hardware operation and the device should implement protection from overheating.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
				<Related_Weakness Nature="ChildOf" CWE_ID="693" View_ID="1000"/>
			</Related_Weaknesses>
			<Applicable_Platforms>	
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
				<Technology Name="Power Management IP" Prevalence="Undetermined"/>
				<Technology Name="Processor IP" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
			</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
					<Note>Such issues could be introduced during hardware architecture, design or implementation.</Note>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Availability</Scope>
					<Impact>DoS: Resource Consumption (Other)</Impact>
					<Likelihood>High</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Detection_Methods>
				<Detection_Method>
				<Method>Dynamic Analysis with Manual Results Interpretation</Method>
				<Description>Dynamic tests should be performed to stress-test temperature controls.</Description>
				<Effectiveness>High</Effectiveness>
				</Detection_Method>
				<Detection_Method>
				<Method>Architecture or Design Review</Method>
				<Description>Power management controls should be part of Architecture and Design reviews.</Description>
				<Effectiveness>High</Effectiveness>
				</Detection_Method>
			</Detection_Methods>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>Temperature maximum and minimum limits should be enforced using thermal sensors both in silicon and at the platform level.</Description>
				</Mitigation>
				<Mitigation>
					<Phase>Implementation</Phase>
					<Description>The platform should support cooling solutions such as fans that can be modulated based on device-operation needs to maintain a stable temperature.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>Malicious software running on a core can execute instructions that consume maximum power or increase core frequency. Such a power-virus program could execute on the platform for an extended time to overheat the device, resulting in permanent damage.</Intro_Text>
					<Body_Text>Execution core and platform do not support thermal sensors, performance throttling, or platform-cooling countermeasures to ensure that any software executing on the system cannot cause overheating past the maximum allowable temperature.</Body_Text>
					<Body_Text>The platform and SoC should have failsafe thermal limits that are enforced by thermal sensors that trigger critical temperature alerts when high temperature is detected. Upon detection of high temperatures, the platform should trigger cooling or shutdown automatically.</Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
			<References>
				<Reference External_Reference_ID="REF-1156"/>
			</References>
			<Content_History>
				<Submission>
					<Submission_Name>Arun Kanuparthi, Hareesh Khattri, Parbati Kumar Manna</Submission_Name>
					<Submission_Organization>Intel Corporation</Submission_Organization>
					<Submission_Date>2020-05-29</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1342" Name="Information Exposure through Microarchitectural State after Transient Execution" Abstraction="Base" Structure="Simple" Status="Incomplete">
			<Description>The processor does not properly clear microarchitectural state after incorrect microcode assists or speculative execution, resulting in transient execution.</Description>
			<Extended_Description>
				<xhtml:p>In many processor architectures an exception, mis-speculation, or microcode assist results in a flush operation to clear results that are no longer required. This action prevents these results from influencing architectural state that is intended to be visible from software. However, traces of this transient execution may remain in microarchitectural buffers, resulting in a change in microarchitectural state that can expose sensitive information to an attacker using side-channel analysis. For example, Load Value Injection (LVI) [REF-1202] can exploit direct injection of erroneous values into intermediate load and store buffers.</xhtml:p>
				<xhtml:p>Several conditions may need to be fulfilled for a successful attack:</xhtml:p>
			    <xhtml:ul>
				<xhtml:li>1) incorrect transient execution that results in remanence of sensitive information;</xhtml:li>
				<xhtml:li>2) attacker has the ability to provoke microarchitectural exceptions;</xhtml:li>
				<xhtml:li>3) operations and structures in victim code that can be exploited must be identified.</xhtml:li>
			    </xhtml:ul>
			</Extended_Description>
			<Related_Weaknesses>
			  <Related_Weakness Nature="ChildOf" CWE_ID="226" View_ID="1000" Ordinal="Primary"/>
			  <Related_Weakness Nature="ChildOf" CWE_ID="226" View_ID="1194" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Workstation" Prevalence="Undetermined"/>
				<Architecture Name="x86" Prevalence="Undetermined"/>
				<Architecture Name="ARM" Prevalence="Undetermined"/>
				<Architecture Name="Other" Prevalence="Undetermined"/>
				<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
				<Technology Class="System on Chip" Prevalence="Undetermined"/>
				</Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Requirements</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Confidentiality</Scope>
					<Scope>Integrity</Scope>
					<Impact>Modify Memory</Impact>
					<Impact>Read Memory</Impact>
					<Impact>Execute Unauthorized Code or Commands</Impact>
					<Likelihood>Medium</Likelihood>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Phase>Requirements</Phase>
					<Description>Hardware ensures that no illegal data flows from faulting micro-ops exists at the microarchitectural level.</Description>
					<Effectiveness>High</Effectiveness>
					<Effectiveness_Notes>Being implemented in silicon it is expected to fully address the known weaknesses with limited performance impact.</Effectiveness_Notes>
				</Mitigation>
				<Mitigation>
					<Phase>Build and Compilation</Phase>
					<Description>Include instructions that explicitly remove traces of unneeded computations from software interactions with microarchitectural elements e.g. lfence, sfence, mfence, clflush.</Description>
					<Effectiveness>High</Effectiveness>
					<Effectiveness_Notes>This effectively forces the processor to complete each memory access before moving on to the next operation. This may have a large performance impact.</Effectiveness_Notes>
				</Mitigation>
			</Potential_Mitigations>
			<Demonstrative_Examples>
				<Demonstrative_Example>
					<Intro_Text>Faulting loads in a victim domain may trigger incorrect transient forwarding, which leaves secret-dependent traces in the microarchitectural state. Consider this example from [REF-1203].</Intro_Text>
					<Body_Text>Consider the code gadget:</Body_Text>
					<Example_Code Nature="bad" Language="Other">
					  <xhtml:div>
					    void call_victim(size_t untrusted_arg) {<xhtml:br/>
					    <xhtml:div style="margin-left:10px;">
					      *arg_copy = untrusted_arg;<xhtml:br/>
					      array[**trusted_ptr * 4096];<xhtml:br/>
					    </xhtml:div>
					    }
					</xhtml:div>
					</Example_Code>
					<Body_Text><xhtml:p>A processor with this weakness will store the value of untrusted_arg (which may be provided by an attacker) to the stack, which is trusted memory. Additionally, this store operation will save this value in some microarchitectural buffer, e.g. the store queue.</xhtml:p>
					<xhtml:p>In this code gadget, 
					trusted_ptr is dereferenced while the attacker forces a page fault. The faulting load causes the processor to mis-speculate by forwarding untrusted_arg as the (speculative) load result. The processor then uses untrusted_arg for the pointer dereference. After the fault has been handled and the load has been re-issued with the correct argument, secret-dependent information stored at the address of trusted_ptr remains in microarchitectural state and can be extracted by an attacker using a code gadget.</xhtml:p></Body_Text>
				</Demonstrative_Example>
			</Demonstrative_Examples>
			<Observed_Examples>
				<Observed_Example>
					<Reference>CVE-2020-0551</Reference>
					<Description>Load value injection in some processors utilizing speculative execution may allow an authenticated user to enable information disclosure via a side-channel with local access.</Description>
					<Link>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-0551</Link>
				</Observed_Example>
			</Observed_Examples>
			<References>
				<Reference External_Reference_ID="REF-1202"/>
				<Reference External_Reference_ID="REF-1203"/>
				<Reference External_Reference_ID="REF-1204"/>
				<Reference External_Reference_ID="REF-1205"/>
			</References>
			<Notes>
			  <Note Type="Relationship">
			    CWE-1342 differs from CWE-1303, which is related to misprediction and biasing microarchitectural components, while CWE-1342 addresses illegal data flows and retention. For example, Spectre is an instance of CWE-1303 biasing branch prediction to steer the transient execution indirectly.
			  </Note>
			</Notes>
			  
			<Content_History>
				<Submission>
					<Submission_Name>Anders Nordstrom, Alric Althoff</Submission_Name>
					<Submission_Organization>Tortuga Logic</Submission_Organization>
					<Submission_Date>2021-09-22</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="1351" Name="Improper Handling of Hardware Behavior in Exceptionally Cold Environments" Abstraction="Base" Structure="Simple" Status="Incomplete">
            <Description>A hardware device, or the firmware running on it, is
                missing or has incorrect protection features to maintain
                goals of security primitives when the device is cooled below
                standard operating temperatures.</Description>
			<Extended_Description>
                <xhtml:p>The hardware designer may improperly anticipate
                    hardware behavior when exposed to exceptionally cold
                    conditions. As a result they may introduce a weakness by not
                    accounting for the modified behavior of critical components
                    when in extreme environments.</xhtml:p>
                <xhtml:p>An example of a change in behavior is that power loss
                    won't clear/reset any volatile state when cooled below
                    standard operating temperatures. This may result in
                    a weakness when the starting state of the volatile memory is
                    being relied upon for a security decision. For example, a
                    Physical Unclonable Function (PUF) may be supplied as a
                    security primitive to improve confidentiality,
                    authenticity, and integrity guarantees. However, when the
                    PUF is paired with DRAM, SRAM, or another temperature
                    sensitive entropy source, the system designer may introduce
                    weakness by failing to account for the chosen entropy
                    source's behavior at exceptionally low temperatures. In the
                    case of DRAM and SRAM, when power is cycled at low
                    temperatures, the device will not contain the bitwise
                    biasing caused by inconsistencies in manufacturing and will
                    instead contain the data from previous boot. Should the PUF
                    primitive be used in a cryptographic construction which
                    does not account for full adversary control of PUF seed
                    data, weakness would arise.</xhtml:p>
                <xhtml:p>This weakness does not cover "Cold Boot Attacks"
                    wherein RAM or other external storage is super cooled and
                    read externally by an attacker.</xhtml:p>
			</Extended_Description>
			<Related_Weaknesses>
              <Related_Weakness Nature="ChildOf" CWE_ID="703" View_ID="1000" Ordinal="Primary"/>
			</Related_Weaknesses>
			<Applicable_Platforms>
				<Language Class="Language-Independent" Prevalence="Undetermined"/>
				<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
				<Architecture Class="Embedded" Prevalence="Undetermined"/>
				<Architecture Class="Microcomputer" Prevalence="Undetermined"/>
				<Technology Class="System on Chip" Prevalence="Undetermined"/>
            </Applicable_Platforms>
			<Modes_Of_Introduction>
				<Introduction>
					<Phase>Architecture and Design</Phase>
				</Introduction>
				<Introduction>
					<Phase>Implementation</Phase>
				</Introduction>
			</Modes_Of_Introduction>
			<Common_Consequences>
				<Consequence>
					<Scope>Integrity</Scope>
					<Scope>Authentication</Scope>
					<Impact>Varies by Context</Impact>
					<Impact>Unexpected State</Impact>
					<Likelihood>Low</Likelihood>
					<Note>Consequences of this weakness are highly contextual.</Note>
				</Consequence>
			</Common_Consequences>
			<Potential_Mitigations>
				<Mitigation>
					<Phase>Architecture and Design</Phase>
					<Description>The system should account for security primitive behavior when cooled outside standard temperatures.</Description>
				</Mitigation>
			</Potential_Mitigations>
			<References>
				<Reference External_Reference_ID="REF-1181"/>
				<Reference External_Reference_ID="REF-1182"/>
				<Reference External_Reference_ID="REF-1183"/>
			</References>
			<Content_History>
				<Submission>
					<Submission_Name>Paul A. Wortman</Submission_Name>
					<Submission_Organization>Wells Fargo</Submission_Organization>
					<Submission_Date>2020-10-23</Submission_Date>
				</Submission>
			</Content_History>
		</Weakness>
      <Weakness ID="203" Name="Observable Discrepancy" Abstraction="Base" Structure="Simple" Status="Incomplete">
         <Description>The product behaves differently or sends different responses under different circumstances in a way that is observable to an unauthorized actor, which exposes security-relevant information about the state of the product, such as whether a particular operation was successful or not.</Description>
         <Extended_Description>Discrepancies can take many forms, and variations may be detectable in timing, control flow, communications such as replies or requests, or general behavior. These discrepancies can reveal information about the product's operation or internal state to an unauthorized actor. In some cases, discrepancies can be used by attackers to form a side channel.</Extended_Description>
         <Related_Weaknesses>
            <Related_Weakness Nature="ChildOf" CWE_ID="200" View_ID="1000" Ordinal="Primary"/>
            <Related_Weakness Nature="ChildOf" CWE_ID="200" View_ID="1003" Ordinal="Primary"/>
         </Related_Weaknesses>
         <Applicable_Platforms>
            <Language Class="Language-Independent" Prevalence="Undetermined"/>
            <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
         </Applicable_Platforms>
         <Alternate_Terms>
            <Alternate_Term>
               <Term>Side Channel Attack</Term>
               <Description>Observable Discrepancies are at the root of side channel attacks.</Description>
            </Alternate_Term>
         </Alternate_Terms>
         <Modes_Of_Introduction>
            <Introduction>
               <Phase>Architecture and Design</Phase>
            </Introduction>
            <Introduction>
               <Phase>Implementation</Phase>
            </Introduction>
         </Modes_Of_Introduction>
         <Common_Consequences>
            <Consequence>
               <Scope>Confidentiality</Scope>
               <Scope>Access Control</Scope>
               <Impact>Read Application Data</Impact>
               <Impact>Bypass Protection Mechanism</Impact>
               <Note>An attacker can gain access to sensitive information about the system, including authentication information that may allow an attacker to gain access to the system.</Note>
            </Consequence>
            <Consequence>
               <Scope>Confidentiality</Scope>
               <Impact>Read Application Data</Impact>
               <Note>When cryptographic primitives are vulnerable to side-channel-attacks, this could be used to reveal unencrypted plaintext in the worst case.</Note>
            </Consequence>
         </Common_Consequences>
         <Potential_Mitigations>
            <Mitigation Mitigation_ID="MIT-46">
               <Phase>Architecture and Design</Phase>
               <Strategy>Separation of Privilege</Strategy>
               <Description>
                  <xhtml:p>Compartmentalize the system to have "safe" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.</xhtml:p>
                  <xhtml:p>Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.</xhtml:p>
               </Description>
            </Mitigation>
            <Mitigation Mitigation_ID="MIT-39">
               <Phase>Implementation</Phase>
               <Description>
                  <xhtml:p>Ensure that error messages only contain minimal details that are useful to the intended audience and no one else. The messages need to strike the balance between being too cryptic (which can confuse users) or being too detailed (which may reveal more than intended). The messages should not reveal the methods that were used to determine the error. Attackers can use detailed information to refine or optimize their original attack, thereby increasing their chances of success.</xhtml:p>
                  <xhtml:p>If errors must be captured in some detail, record them in log messages, but consider what could occur if the log messages can be viewed by attackers. Highly sensitive information such as passwords should never be saved to log files.</xhtml:p>
		  <xhtml:p>Avoid inconsistent messaging that might accidentally tip off an attacker about internal state, such as whether a user account exists or not.</xhtml:p>
               </Description>
            </Mitigation>
         </Potential_Mitigations>
         <Demonstrative_Examples>
            <Demonstrative_Example Demonstrative_Example_ID="DX-38">
               <Intro_Text>The following code checks validity of the supplied username and password and notifies the user of a successful or failed login.</Intro_Text>
               <Example_Code Nature="bad" Language="Perl">
                  <xhtml:div>my $username=param('username');
                  <xhtml:br/>my $password=param('password');
                  <xhtml:br/>
                  <xhtml:br/>if (IsValidUsername($username) == 1)
                  <xhtml:br/>{
                  <xhtml:div style="margin-left:10px;">if (IsValidPassword($username, $password) == 1)
                  <xhtml:br/>{
                  <xhtml:div style="margin-left:10px;">print "Login Successful";
                  </xhtml:div>}
                  <xhtml:br/>else
                  <xhtml:br/>{
                  <xhtml:div style="margin-left:10px;">print "Login Failed - incorrect password";
                  </xhtml:div>}
                  </xhtml:div>}
                  <xhtml:br/>else
                  <xhtml:br/>{
                  <xhtml:div style="margin-left:10px;">print "Login Failed - unknown username";
                  </xhtml:div>}
                  </xhtml:div>
               </Example_Code>
               <Body_Text>In the above code, there are different messages for when an incorrect username is supplied, versus when the username is correct but the password is wrong. This difference enables a potential attacker to understand the state of the login function, and could allow an attacker to discover a valid username by trying different values until the incorrect password message is returned. In essence, this makes it easier for an attacker to obtain half of the necessary authentication credentials.</Body_Text>
               <Body_Text>While this type of information may be helpful to a user, it is also useful to a potential attacker. In the above example, the message for both failed cases should be the same, such as:</Body_Text>
               <Example_Code Nature="result">
                  <xhtml:div>"Login Failed - incorrect username or password"</xhtml:div>
               </Example_Code>
            </Demonstrative_Example>
            <Demonstrative_Example>
               <Intro_Text>Non-uniform processing time causes timing channel.</Intro_Text>
               <Example_Code Nature="bad">Suppose an algorithm for implementing an encryption routine works fine per se, but the time taken to output the result of the encryption routine depends on a relationship between the input plaintext and the key (e.g., suppose, if the plaintext is similar to the key, it would run very fast).</Example_Code>
               <Body_Text>In the example above, an attacker may vary the inputs, then observe differences between processing times (since different plaintexts take different time). This could be used to infer information about the key.</Body_Text>
               <Example_Code Nature="good">Artificial delays may be added to ensured all calculations take equal time to execute.</Example_Code>
            </Demonstrative_Example>
            <Demonstrative_Example>
               <Intro_Text>Suppose memory access patterns for an encryption routine are dependent on the secret key.</Intro_Text>
               <Body_Text>An attacker can recover the key by knowing if specific memory locations have been accessed or not.  The value stored at those memory locations is irrelevant.  The encryption routine's memory accesses will affect the state of the processor cache.  If cache resources are shared across contexts, after the encryption routine completes, an attacker in different execution context can discover which memory locations the routine accessed by measuring the time it takes for their own memory accesses to complete.</Body_Text>
            </Demonstrative_Example>
         </Demonstrative_Examples>
         <Observed_Examples>
               <Observed_Example>
                     <Reference>CVE-2020-8695</Reference>
                     <Description>Observable discrepancy in the RAPL interface for some Intel processors allows information disclosure.</Description>
                     <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8695</Link>
                     </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2002-2094</Reference>
               <Description>This, and others, use ".." attacks and monitor error responses, so there is overlap with directory traversal.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2002-2094</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2001-1483</Reference>
               <Description>Enumeration of valid usernames based on inconsistent responses</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2001-1483</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2001-1528</Reference>
               <Description>Account number enumeration via inconsistent responses.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2001-1528</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2004-2150</Reference>
               <Description>User enumeration via discrepancies in error messages.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2004-2150</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2005-1650</Reference>
               <Description>User enumeration via discrepancies in error messages.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2005-1650</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2004-0294</Reference>
               <Description>Bulletin Board displays different error messages when a user exists or not, which makes it easier for remote attackers to identify valid users and conduct a brute force password guessing attack.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2004-0294</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2004-0243</Reference>
               <Description>Operating System, when direct remote login is disabled, displays a different message if the password is correct, which allows remote attackers to guess the password via brute force methods.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2004-0243</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2002-0514</Reference>
               <Description>Product allows remote attackers to determine if a port is being filtered because the response packet TTL is different than the default TTL.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2002-0514</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2002-0515</Reference>
               <Description>Product sets a different TTL when a port is being filtered than when it is not being filtered, which allows remote attackers to identify filtered ports by comparing TTLs.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2002-0515</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2002-0208</Reference>
               <Description>Product modifies TCP/IP stack and ICMP error messages in unusual ways that show the product is in use.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2002-0208</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2004-2252</Reference>
               <Description>Behavioral infoleak by responding to SYN-FIN packets.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2004-2252</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2001-1387</Reference>
               <Description>Product may generate different responses than specified by the administrator, possibly leading to an information leak.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2001-1387</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2004-0778</Reference>
               <Description>Version control system allows remote attackers to determine the existence of arbitrary files and directories via the -X command for an alternate history file, which causes different error messages to be returned.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2004-0778</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2004-1428</Reference>
               <Description>FTP server generates an error message if the user name does not exist instead of prompting for a password, which allows remote attackers to determine valid usernames.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2004-1428</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2003-0078</Reference>
               <Description>SSL implementation does not perform a MAC computation if an incorrect block cipher padding is used, which causes an information leak (timing discrepancy) that may make it easier to launch cryptographic attacks that rely on distinguishing between padding and MAC verification errors, possibly leading to extraction of the original plaintext, aka the "Vaudenay timing attack."</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2003-0078</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2000-1117</Reference>
               <Description>Virtual machine allows malicious web site operators to determine the existence of files on the client by measuring delays in the execution of the getSystemResource method.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2000-1117</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2003-0637</Reference>
               <Description>Product uses a shorter timeout for a non-existent user than a valid user, which makes it easier for remote attackers to guess usernames and conduct brute force password guessing.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2003-0637</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2003-0190</Reference>
               <Description>Product immediately sends an error message when a user does not exist, which allows remote attackers to determine valid usernames via a timing attack.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2003-0190</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2004-1602</Reference>
               <Description>FTP server responds in a different amount of time when a given username exists, which allows remote attackers to identify valid usernames by timing the server response.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2004-1602</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2005-0918</Reference>
               <Description>Browser allows remote attackers to determine the existence of arbitrary files by setting the src property to the target filename and using Javascript to determine if the web page immediately stops loading, which indicates whether the file exists or not.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2005-0918</Link>
            </Observed_Example>
         </Observed_Examples>
         <Taxonomy_Mappings>
            <Taxonomy_Mapping Taxonomy_Name="PLOVER">
               <Entry_Name>Discrepancy Information Leaks</Entry_Name>
            </Taxonomy_Mapping>
            <Taxonomy_Mapping Taxonomy_Name="OWASP Top Ten 2007">
               <Entry_ID>A6</Entry_ID>
               <Entry_Name>Information Leakage and Improper Error Handling</Entry_Name>
               <Mapping_Fit>CWE More Specific</Mapping_Fit>
            </Taxonomy_Mapping>
            <Taxonomy_Mapping Taxonomy_Name="OWASP Top Ten 2004">
               <Entry_ID>A7</Entry_ID>
               <Entry_Name>Improper Error Handling</Entry_Name>
               <Mapping_Fit>CWE More Specific</Mapping_Fit>
            </Taxonomy_Mapping>
         </Taxonomy_Mappings>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="189"/>
         </Related_Attack_Patterns>
         <Content_History>
            <Submission>
               <Submission_Name>PLOVER</Submission_Name>
               <Submission_Date>2006-07-19</Submission_Date>
            </Submission>
            <Modification>
               <Modification_Name>Eric Dalci</Modification_Name>
               <Modification_Organization>Cigital</Modification_Organization>
               <Modification_Date>2008-07-01</Modification_Date>
               <Modification_Comment>updated Potential_Mitigations, Time_of_Introduction</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2008-09-08</Modification_Date>
               <Modification_Comment>updated Relationships, Taxonomy_Mappings</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2009-12-28</Modification_Date>
               <Modification_Comment>updated Description, Name</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2011-06-01</Modification_Date>
               <Modification_Comment>updated Common_Consequences</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2012-05-11</Modification_Date>
               <Modification_Comment>updated Common_Consequences, Demonstrative_Examples, Observed_Examples, Relationships</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2012-10-30</Modification_Date>
               <Modification_Comment>updated Potential_Mitigations</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2014-07-30</Modification_Date>
               <Modification_Comment>updated Relationships</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2017-11-08</Modification_Date>
               <Modification_Comment>updated Applicable_Platforms</Modification_Comment>
            </Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2019-06-20</Modification_Date>
					<Modification_Comment>updated Relationships, Type</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-02-24</Modification_Date>
					<Modification_Comment>updated Alternate_Terms, Applicable_Platforms, Common_Consequences, Demonstrative_Examples, Description, Name, Observed_Examples, Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Alternate_Terms, Common_Consequences, Demonstrative_Examples, Description, Name, Potential_Mitigations, Related_Attack_Patterns, Relationships, Research_Gaps</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-12-10</Modification_Date>
					<Modification_Comment>updated Common_Consequences, Demonstrative_Examples, Description, Name, Potential_Mitigations, Research_Gaps</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Demonstrative_Examples</Modification_Comment>
				</Modification>
            <Contribution Type="Content">
			  <Contribution_Name>Nicole Fern</Contribution_Name>
               <Contribution_Organization>Tortuga Logic</Contribution_Organization>
               <Contribution_Date>2020-06-03</Contribution_Date>
               <Contribution_Comment>Provided Demonstrative Example for cache timing attack</Contribution_Comment>
            </Contribution>
            <Previous_Entry_Name Date="2009-12-28">Discrepancy Information Leaks</Previous_Entry_Name>
			<Previous_Entry_Name Date="2020-02-24">Information Exposure Through Discrepancy</Previous_Entry_Name>
			<Previous_Entry_Name Date="2020-08-20">Observable Discrepancy</Previous_Entry_Name>
			<Previous_Entry_Name Date="2020-12-10">Observable Differences in Behavior to Error Inputs</Previous_Entry_Name>
         </Content_History>
      </Weakness>
      <Weakness ID="226" Name="Sensitive Information in Resource Not Removed Before Reuse" Abstraction="Base" Structure="Simple" Status="Draft">
     <Description>The product releases a resource such as memory or a file so that it can be made available for reuse, but it does not clear or "zeroize" the information contained in the resource before the product performs a critical state transition or makes the resource available for reuse by other entities.</Description>
     <Extended_Description>
			 <xhtml:p>When resources are released, they can be made available for reuse. For example, after memory is de-allocated, an operating system may make the memory available to another process, or disk space may be reallocated when a file is deleted. As removing information requires time and additional resources, operating systems do not usually clear the previously written information.</xhtml:p>
			 <xhtml:p>Even when the resource is reused by the same process, this weakness can arise when new data is not as large as the old data, which leaves portions of the old data still available. Equivalent errors can occur in other situations where the length of data is variable but the associated data structure is not. If memory is not cleared after use, the information may be read by less trustworthy parties when the memory is reallocated.</xhtml:p>
			 <xhtml:p>This weakness can apply in hardware, such as when a device or system switches between power, sleep, or debug states during normal operation, or when execution changes to different users or privilege levels.</xhtml:p>
     </Extended_Description>
     <Related_Weaknesses>
      <Related_Weakness Nature="ChildOf" CWE_ID="459" View_ID="1000" Ordinal="Primary"/>
      <Related_Weakness Nature="ChildOf" CWE_ID="212" View_ID="1000"/>
      <Related_Weakness Nature="CanPrecede" CWE_ID="201" View_ID="1000"/>
     </Related_Weaknesses>
     <Weakness_Ordinalities>
      <Weakness_Ordinality>
        <Ordinality>Primary</Ordinality>
      </Weakness_Ordinality>
     </Weakness_Ordinalities>
     <Applicable_Platforms>
      <Language Class="Language-Independent" Prevalence="Undetermined"/>
      <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
     </Applicable_Platforms>
     <Modes_Of_Introduction>
      <Introduction>
        <Phase>Architecture and Design</Phase>
      </Introduction>
      <Introduction>
        <Phase>Implementation</Phase>
      </Introduction>
     </Modes_Of_Introduction>
     <Common_Consequences>
      <Consequence>
        <Scope>Confidentiality</Scope>
        <Impact>Read Application Data</Impact>
      </Consequence>
     </Common_Consequences>
     <Detection_Methods>
       <Detection_Method>
	 <Method>Manual Analysis</Method>
	 <Description>Write a known pattern into each sensitive location. Trigger the release of the resource or cause the desired state transition to occur. Read data back from the sensitive locations. If the reads are successful, and the data is the same as the pattern that was originally written, the test fails and the product needs to be fixed. Note that this test can likely be automated.</Description>
	 <Effectiveness>High</Effectiveness>
       </Detection_Method>
     </Detection_Methods>
     <Potential_Mitigations>
       <Mitigation>
	 <Phase>Architecture and Design</Phase>
	 <Phase>Implementation</Phase>
	 <Description>During critical state transitions, information not needed in the next state should be removed or overwritten with fixed patterns (such as all 0's) or random data, before the transition to the next state.</Description>
	 <Effectiveness>High</Effectiveness>
       </Mitigation>
       <Mitigation>
	 <Phase>Architecture and Design</Phase>
	 <Phase>Implementation</Phase>
	 <Description>When releasing, de-allocating, or deleting a resource, overwrite its data and relevant metadata with fixed patterns or random data. Be cautious about complex resource types whose underlying representation might be non-contiguous or change at a low level, such as how a file might be split into different chunks on a file system, even though "logical" file positions are contiguous at the application layer. Such resource types might require invocation of special modes or APIs to tell the underlying operating system to perform the necessary clearing, such as SDelete (Secure Delete) on Windows, although the appropriate functionality might not be available at the application layer.</Description>
	 <Effectiveness>High</Effectiveness>
       </Mitigation>
     </Potential_Mitigations>
     <Demonstrative_Examples>
       <Demonstrative_Example Demonstrative_Example_ID="DX-147">
	 <Intro_Text>This example shows how an attacker can take advantage of an incorrect state transition.</Intro_Text>
	 <Body_Text>
	   <xhtml:p>Suppose a device is transitioning from state A to state B. During state A, it can read certain private keys from the hidden fuses that are only accessible in state A but not in state B. The device reads the keys, performs operations using those keys, then transitions to state B, where those private keys should no longer be accessible.</xhtml:p>
	 </Body_Text>
	 <Example_Code Nature="bad">
	 <xhtml:p>During the transition from A to B, the device does not scrub the memory.</xhtml:p>
	 </Example_Code>
	 <Body_Text><xhtml:p>After the transition to state B, even though the private keys are no longer accessible directly from the fuses in state B, they can be accessed indirectly by reading the memory that contains the private keys.</xhtml:p></Body_Text>
	 <Example_Code Nature="good">For transition from state A to state B, remove information which should not be available once the transition is complete.</Example_Code>
       </Demonstrative_Example>
       <Demonstrative_Example Demonstrative_Example_ID="DX-148">
         <Intro_Text>The following code calls realloc() on a buffer containing sensitive data:</Intro_Text>
         <Example_Code Nature="bad" Language="C">
           <xhtml:div>cleartext_buffer = get_secret();...<xhtml:br/>cleartext_buffer = realloc(cleartext_buffer, 1024);<xhtml:br/>...<xhtml:br/>scrub_memory(cleartext_buffer, 1024);</xhtml:div>
         </Example_Code>
         <Body_Text>There is an attempt to scrub the sensitive data from memory, but realloc() is used, so it could return a pointer to a different part of memory. The memory that was originally allocated for cleartext_buffer could still contain an uncleared copy of the data.</Body_Text>
       </Demonstrative_Example>
     </Demonstrative_Examples>
     <Observed_Examples>
      <Observed_Example>
        <Reference>CVE-2003-0001</Reference>
        <Description>Ethernet NIC drivers do not pad frames with null bytes, leading to infoleak from malformed packets.</Description>
        <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2003-0001</Link>
      </Observed_Example>
      <Observed_Example>
        <Reference>CVE-2003-0291</Reference>
        <Description>router does not clear information from DHCP packets that have been previously used</Description>
        <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2003-0291</Link>
      </Observed_Example>
      <Observed_Example>
        <Reference>CVE-2005-1406</Reference>
        <Description>Products do not fully clear memory buffers when less data is stored into the buffer than previous.</Description>
        <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2005-1406</Link>
      </Observed_Example>
      <Observed_Example>
        <Reference>CVE-2005-1858</Reference>
        <Description>Products do not fully clear memory buffers when less data is stored into the buffer than previous.</Description>
        <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2005-1858</Link>
      </Observed_Example>
      <Observed_Example>
        <Reference>CVE-2005-3180</Reference>
        <Description>Products do not fully clear memory buffers when less data is stored into the buffer than previous.</Description>
        <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2005-3180</Link>
      </Observed_Example>
      <Observed_Example>
        <Reference>CVE-2005-3276</Reference>
        <Description>Product does not clear a data structure before writing to part of it, yielding information leak of previously used memory.</Description>
        <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2005-3276</Link>
      </Observed_Example>
      <Observed_Example>
        <Reference>CVE-2002-2077</Reference>
        <Description>Memory not properly cleared before reuse.</Description>
        <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2002-2077</Link>
      </Observed_Example>
     </Observed_Examples>
     <Functional_Areas>
      <Functional_Area>Memory Management</Functional_Area>
      <Functional_Area>Networking</Functional_Area>
     </Functional_Areas>
     <Affected_Resources>
      <Affected_Resource>Memory</Affected_Resource>
     </Affected_Resources>
     <Taxonomy_Mappings>
      <Taxonomy_Mapping Taxonomy_Name="PLOVER">
        <Entry_Name>Sensitive Information Uncleared Before Use</Entry_Name>
      </Taxonomy_Mapping>
      <Taxonomy_Mapping Taxonomy_Name="CERT C Secure Coding">
        <Entry_ID>MEM03-C</Entry_ID>
        <Entry_Name>Clear sensitive information stored in reusable resources returned for reuse</Entry_Name>
      </Taxonomy_Mapping>
      <Taxonomy_Mapping Taxonomy_Name="Software Fault Patterns">
        <Entry_ID>SFP23</Entry_ID>
        <Entry_Name>Exposed Data</Entry_Name>
      </Taxonomy_Mapping>
     </Taxonomy_Mappings>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="37"/>
         </Related_Attack_Patterns>
         <Notes>
      <Note Type="Relationship">There is a close association between CWE-226 and CWE-212. The difference is partially that of perspective. CWE-226 is geared towards the final stage of the resource lifecycle, in which the resource is deleted, eliminated, expired, or otherwise released for reuse. Technically, this involves a transfer to a different control sphere, in which the original contents of the resource are no longer relevant. CWE-212, however, is intended for sensitive data in resources that are intentionally shared with others, so they are still active. This distinction is useful from the perspective of the CWE research view (CWE-1000).</Note>
      <Note Type="Maintenance">This entry needs modification to clarify the differences with CWE-212. The description also combines two problems that are distinct from the CWE research perspective: the inadvertent transfer of information to another sphere, and improper initialization/shutdown. Some of the associated taxonomy mappings reflect these different uses.</Note>
      <Note Type="Research Gap">This is frequently found for network packets, but it can also exist in local memory allocation, files, etc.</Note>
     </Notes>
     <Content_History>
      <Submission>
        <Submission_Name>PLOVER</Submission_Name>
        <Submission_Date>2006-07-19</Submission_Date>
      </Submission>
      <Modification>
        <Modification_Name>Eric Dalci</Modification_Name>
        <Modification_Organization>Cigital</Modification_Organization>
        <Modification_Date>2008-07-01</Modification_Date>
        <Modification_Comment>updated Time_of_Introduction</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2008-09-08</Modification_Date>
        <Modification_Comment>updated Relationships, Other_Notes, Relationship_Notes, Taxonomy_Mappings, Weakness_Ordinalities</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2008-10-14</Modification_Date>
        <Modification_Comment>updated Relationships</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2008-11-24</Modification_Date>
        <Modification_Comment>updated Relationships, Taxonomy_Mappings</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2009-03-10</Modification_Date>
        <Modification_Comment>updated Relationships</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2009-05-27</Modification_Date>
        <Modification_Comment>updated Relationships</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2009-10-29</Modification_Date>
        <Modification_Comment>updated Description, Other_Notes</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2010-02-16</Modification_Date>
        <Modification_Comment>updated Applicable_Platforms, Maintenance_Notes, Relationship_Notes</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2010-09-27</Modification_Date>
        <Modification_Comment>updated Relationships</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2010-12-13</Modification_Date>
        <Modification_Comment>updated Description</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2011-06-01</Modification_Date>
        <Modification_Comment>updated Common_Consequences, Relationships, Taxonomy_Mappings</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2011-09-13</Modification_Date>
        <Modification_Comment>updated Relationships, Taxonomy_Mappings</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2012-05-11</Modification_Date>
        <Modification_Comment>updated Relationships, Taxonomy_Mappings</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2014-07-30</Modification_Date>
        <Modification_Comment>updated Relationships, Taxonomy_Mappings</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2017-11-08</Modification_Date>
        <Modification_Comment>updated Causal_Nature, Functional_Areas, Relationships, Taxonomy_Mappings</Modification_Comment>
      </Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-02-24</Modification_Date>
					<Modification_Comment>updated Applicable_Platforms, Description, Name, Relationships, Time_of_Introduction, Weakness_Ordinalities</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Description, Name, Related_Attack_Patterns, Relationships</Modification_Comment>
				</Modification>
      <Previous_Entry_Name Date="2008-04-11">Sensitive Information Uncleared Before Use</Previous_Entry_Name>
			<Previous_Entry_Name Date="2020-02-24">Sensitive Information Uncleared Before Release</Previous_Entry_Name>
			<Previous_Entry_Name Date="2020-08-20">Sensitive Information Uncleared in Resource Before Release for Reuse</Previous_Entry_Name>
     </Content_History>
   </Weakness>
      <Weakness ID="276" Name="Incorrect Default Permissions" Abstraction="Base" Structure="Simple" Status="Draft">
     <Description>During installation, installed file permissions are set to allow anyone to modify those files.</Description>
     <Related_Weaknesses>
      <Related_Weakness Nature="ChildOf" CWE_ID="732" View_ID="1000" Ordinal="Primary"/>
      <Related_Weakness Nature="ChildOf" CWE_ID="732" View_ID="1003" Ordinal="Primary"/>
     </Related_Weaknesses>
     <Weakness_Ordinalities>
      <Weakness_Ordinality>
        <Ordinality>Primary</Ordinality>
      </Weakness_Ordinality>
     </Weakness_Ordinalities>
     <Applicable_Platforms>
      <Language Class="Language-Independent" Prevalence="Undetermined"/>
      <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
     </Applicable_Platforms>
     <Modes_Of_Introduction>
      <Introduction>
        <Phase>Architecture and Design</Phase>
      </Introduction>
      <Introduction>
        <Phase>Implementation</Phase>
      </Introduction>
      <Introduction>
        <Phase>Installation</Phase>
      </Introduction>
      <Introduction>
        <Phase>Operation</Phase>
      </Introduction>
     </Modes_Of_Introduction>
     <Likelihood_Of_Exploit>Medium</Likelihood_Of_Exploit>
     <Common_Consequences>
      <Consequence>
        <Scope>Confidentiality</Scope>
        <Scope>Integrity</Scope>
        <Impact>Read Application Data</Impact>
        <Impact>Modify Application Data</Impact>
      </Consequence>
     </Common_Consequences>
     <Detection_Methods>
      <Detection_Method>
        <Method>Automated Static Analysis - Binary or Bytecode</Method>
        <Description>
         <xhtml:p>According to SOAR, the following detection techniques may be useful:</xhtml:p>
         <xhtml:div style="margin-left:10px;">
           <xhtml:div>Cost effective for partial coverage:</xhtml:div>
           <xhtml:div style="margin-left:10px;">
            <xhtml:ul>
              <xhtml:li>Inter-application Flow Analysis</xhtml:li>
            </xhtml:ul>
           </xhtml:div>
         </xhtml:div>
        </Description>
        <Effectiveness>SOAR Partial</Effectiveness>
      </Detection_Method>
      <Detection_Method>
        <Method>Manual Static Analysis - Binary or Bytecode</Method>
        <Description>
         <xhtml:p>According to SOAR, the following detection techniques may be useful:</xhtml:p>
         <xhtml:div style="margin-left:10px;">
           <xhtml:div>Cost effective for partial coverage:</xhtml:div>
           <xhtml:div style="margin-left:10px;">
            <xhtml:ul>
              <xhtml:li>Binary / Bytecode disassembler - then use manual analysis for vulnerabilities &amp; anomalies</xhtml:li>
            </xhtml:ul>
           </xhtml:div>
         </xhtml:div>
        </Description>
        <Effectiveness>SOAR Partial</Effectiveness>
      </Detection_Method>
      <Detection_Method>
        <Method>Dynamic Analysis with Automated Results Interpretation</Method>
        <Description>
         <xhtml:p>According to SOAR, the following detection techniques may be useful:</xhtml:p>
         <xhtml:div style="margin-left:10px;">
           <xhtml:div>Cost effective for partial coverage:</xhtml:div>
           <xhtml:div style="margin-left:10px;">
            <xhtml:ul>
              <xhtml:li>Host-based Vulnerability Scanners - Examine configuration for flaws, verifying that audit mechanisms work, ensure host configuration meets certain predefined criteria</xhtml:li>
              <xhtml:li>Web Application Scanner</xhtml:li>
              <xhtml:li>Web Services Scanner</xhtml:li>
              <xhtml:li>Database Scanners</xhtml:li>
            </xhtml:ul>
           </xhtml:div>
         </xhtml:div>
        </Description>
        <Effectiveness>SOAR Partial</Effectiveness>
      </Detection_Method>
      <Detection_Method>
        <Method>Dynamic Analysis with Manual Results Interpretation</Method>
        <Description>
         <xhtml:p>According to SOAR, the following detection techniques may be useful:</xhtml:p>
         <xhtml:div style="margin-left:10px;">
           <xhtml:div>Highly cost effective:</xhtml:div>
           <xhtml:div style="margin-left:10px;">
            <xhtml:ul>
              <xhtml:li>Host Application Interface Scanner</xhtml:li>
            </xhtml:ul>
           </xhtml:div>
           <xhtml:div>Cost effective for partial coverage:</xhtml:div>
           <xhtml:div style="margin-left:10px;">
            <xhtml:ul>
              <xhtml:li>Fuzz Tester</xhtml:li>
              <xhtml:li>Framework-based Fuzzer</xhtml:li>
              <xhtml:li>Automated Monitored Execution</xhtml:li>
              <xhtml:li>Forced Path Execution</xhtml:li>
            </xhtml:ul>
           </xhtml:div>
         </xhtml:div>
        </Description>
        <Effectiveness>High</Effectiveness>
      </Detection_Method>
      <Detection_Method>
        <Method>Manual Static Analysis - Source Code</Method>
        <Description>
         <xhtml:p>According to SOAR, the following detection techniques may be useful:</xhtml:p>
         <xhtml:div style="margin-left:10px;">
           <xhtml:div>Highly cost effective:</xhtml:div>
           <xhtml:div style="margin-left:10px;">
            <xhtml:ul>
              <xhtml:li>Manual Source Code Review (not inspections)</xhtml:li>
            </xhtml:ul>
           </xhtml:div>
           <xhtml:div>Cost effective for partial coverage:</xhtml:div>
           <xhtml:div style="margin-left:10px;">
            <xhtml:ul>
              <xhtml:li>Focused Manual Spotcheck - Focused manual analysis of source</xhtml:li>
            </xhtml:ul>
           </xhtml:div>
         </xhtml:div>
        </Description>
        <Effectiveness>High</Effectiveness>
      </Detection_Method>
      <Detection_Method>
        <Method>Automated Static Analysis - Source Code</Method>
        <Description>
         <xhtml:p>According to SOAR, the following detection techniques may be useful:</xhtml:p>
         <xhtml:div style="margin-left:10px;">
           <xhtml:div>Cost effective for partial coverage:</xhtml:div>
           <xhtml:div style="margin-left:10px;">
            <xhtml:ul>
              <xhtml:li>Context-configured Source Code Weakness Analyzer</xhtml:li>
            </xhtml:ul>
           </xhtml:div>
         </xhtml:div>
        </Description>
        <Effectiveness>SOAR Partial</Effectiveness>
      </Detection_Method>
      <Detection_Method>
        <Method>Automated Static Analysis</Method>
        <Description>
         <xhtml:p>According to SOAR, the following detection techniques may be useful:</xhtml:p>
         <xhtml:div style="margin-left:10px;">
           <xhtml:div>Cost effective for partial coverage:</xhtml:div>
           <xhtml:div style="margin-left:10px;">
            <xhtml:ul>
              <xhtml:li>Configuration Checker</xhtml:li>
            </xhtml:ul>
           </xhtml:div>
         </xhtml:div>
        </Description>
        <Effectiveness>SOAR Partial</Effectiveness>
      </Detection_Method>
      <Detection_Method>
        <Method>Architecture or Design Review</Method>
        <Description>
         <xhtml:p>According to SOAR, the following detection techniques may be useful:</xhtml:p>
         <xhtml:div style="margin-left:10px;">
           <xhtml:div>Highly cost effective:</xhtml:div>
           <xhtml:div style="margin-left:10px;">
            <xhtml:ul>
              <xhtml:li>Formal Methods / Correct-By-Construction</xhtml:li>
            </xhtml:ul>
           </xhtml:div>
           <xhtml:div>Cost effective for partial coverage:</xhtml:div>
           <xhtml:div style="margin-left:10px;">
            <xhtml:ul>
              <xhtml:li>Inspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)</xhtml:li>
            </xhtml:ul>
           </xhtml:div>
         </xhtml:div>
        </Description>
        <Effectiveness>High</Effectiveness>
      </Detection_Method>
     </Detection_Methods>
     <Potential_Mitigations>
      <Mitigation Mitigation_ID="MIT-1">
        <Phase>Architecture and Design</Phase>
        <Phase>Operation</Phase>
        <Description>The architecture needs to access and modification attributes for files to only those users who actually require those actions.</Description>
      </Mitigation>
      <Mitigation Mitigation_ID="MIT-46">
        <Phase>Architecture and Design</Phase>
        <Strategy>Separation of Privilege</Strategy>
        <Description>
          <xhtml:p>Compartmentalize the system to have "safe" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.</xhtml:p>
          <xhtml:p>Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.</xhtml:p>
        </Description>
      </Mitigation>
     </Potential_Mitigations>
     <Observed_Examples>
      <Observed_Example>
        <Reference>CVE-2005-1941</Reference>
        <Description>Executables installed world-writable.</Description>
        <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2005-1941</Link>
      </Observed_Example>
      <Observed_Example>
        <Reference>CVE-2002-1713</Reference>
        <Description>Home directories installed world-readable.</Description>
        <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2002-1713</Link>
      </Observed_Example>
      <Observed_Example>
        <Reference>CVE-2001-1550</Reference>
        <Description>World-writable log files allow information loss; world-readable file has cleartext passwords.</Description>
        <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2001-1550</Link>
      </Observed_Example>
      <Observed_Example>
        <Reference>CVE-2002-1711</Reference>
        <Description>World-readable directory.</Description>
        <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2002-1711</Link>
      </Observed_Example>
      <Observed_Example>
        <Reference>CVE-2002-1844</Reference>
        <Description>Windows product uses insecure permissions when installing on Solaris (genesis: port error).</Description>
        <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2002-1844</Link>
      </Observed_Example>
      <Observed_Example>
        <Reference>CVE-2001-0497</Reference>
        <Description>Insecure permissions for a shared secret key file. Overlaps cryptographic problem.</Description>
        <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2001-0497</Link>
      </Observed_Example>
      <Observed_Example>
        <Reference>CVE-1999-0426</Reference>
        <Description>Default permissions of a device allow IP spoofing.</Description>
        <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-1999-0426</Link>
      </Observed_Example>
     </Observed_Examples>
     <Taxonomy_Mappings>
      <Taxonomy_Mapping Taxonomy_Name="PLOVER">
        <Entry_Name>Insecure Default Permissions</Entry_Name>
      </Taxonomy_Mapping>
      <Taxonomy_Mapping Taxonomy_Name="CERT C Secure Coding">
        <Entry_ID>FIO06-C</Entry_ID>
        <Entry_Name>Create files with appropriate access permissions</Entry_Name>
      </Taxonomy_Mapping>
      <Taxonomy_Mapping Taxonomy_Name="The CERT Oracle Secure Coding Standard for Java (2011)">
        <Entry_ID>FIO01-J</Entry_ID>
        <Entry_Name>Create files with appropriate access permission</Entry_Name>
      </Taxonomy_Mapping>
     </Taxonomy_Mappings>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="1"/>
            <Related_Attack_Pattern CAPEC_ID="127"/>
            <Related_Attack_Pattern CAPEC_ID="81"/>
         </Related_Attack_Patterns>
         <References>
      <Reference External_Reference_ID="REF-62" Section="Chapter 3, &#34;Insecure Defaults&#34;, Page 69"/>
     </References>
     <Content_History>
      <Submission>
        <Submission_Name>PLOVER</Submission_Name>
        <Submission_Date>2006-07-19</Submission_Date>
      </Submission>
      <Modification>
        <Modification_Name>Eric Dalci</Modification_Name>
        <Modification_Organization>Cigital</Modification_Organization>
        <Modification_Date>2008-07-01</Modification_Date>
        <Modification_Comment>updated Time_of_Introduction</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2008-09-08</Modification_Date>
        <Modification_Comment>updated Relationships, Taxonomy_Mappings, Weakness_Ordinalities</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2008-11-24</Modification_Date>
        <Modification_Comment>updated Relationships, Taxonomy_Mappings</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2009-05-27</Modification_Date>
        <Modification_Comment>updated Description, Name</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2011-06-01</Modification_Date>
        <Modification_Comment>updated Common_Consequences, Relationships, Taxonomy_Mappings</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2011-09-13</Modification_Date>
        <Modification_Comment>updated Relationships, Taxonomy_Mappings</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2012-05-11</Modification_Date>
        <Modification_Comment>updated References, Related_Attack_Patterns, Relationships, Taxonomy_Mappings</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2012-10-30</Modification_Date>
        <Modification_Comment>updated Potential_Mitigations</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2014-07-30</Modification_Date>
        <Modification_Comment>updated Detection_Factors, Relationships</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2017-05-03</Modification_Date>
        <Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
      </Modification>
      <Modification>
        <Modification_Name>CWE Content Team</Modification_Name>
        <Modification_Organization>MITRE</Modification_Organization>
        <Modification_Date>2017-11-08</Modification_Date>
        <Modification_Comment>updated Applicable_Platforms, Causal_Nature, Modes_of_Introduction, Relationships, Taxonomy_Mappings</Modification_Comment>
      </Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2019-01-03</Modification_Date>
					<Modification_Comment>updated Relationships, Taxonomy_Mappings</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2019-06-20</Modification_Date>
					<Modification_Comment>updated Relationships, Type</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-02-24</Modification_Date>
					<Modification_Comment>updated Applicable_Platforms, Description, Detection_Factors, Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Description, Modes_of_Introduction, Potential_Mitigations</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-12-10</Modification_Date>
					<Modification_Comment>updated Potential_Mitigations</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
      <Previous_Entry_Name Date="2009-05-27">Insecure Default Permissions</Previous_Entry_Name>
     </Content_History>
   </Weakness>
      <Weakness ID="325" Name="Missing Cryptographic Step" Abstraction="Base" Structure="Simple" Status="Draft">
         <Description>The product does not implement a required step in a cryptographic algorithm, resulting in weaker encryption than advertised by the algorithm.</Description>
         <Related_Weaknesses>
            <Related_Weakness Nature="ChildOf" CWE_ID="573" View_ID="1000" Ordinal="Primary"/>
            <Related_Weakness Nature="PeerOf" CWE_ID="358" View_ID="1000"/>
         </Related_Weaknesses>
         <Applicable_Platforms>
            <Language Class="Language-Independent" Prevalence="Undetermined"/>
            <Technology Class="Technology-Independent" Prevalence="Undetermined"/>
         </Applicable_Platforms>
         <Modes_Of_Introduction>
            <Introduction>
               <Phase>Implementation</Phase>
               <Note>Developers sometimes omit "expensive" (resource-intensive) steps in order to improve performance, especially in devices with limited memory or slower CPUs. This step may be taken under a mistaken impression that the step is unnecessary for the cryptographic algorithm.
               </Note>
            </Introduction>
            <Introduction>
               <Phase>Architecture and Design</Phase>
            </Introduction>
            <Introduction>
               <Phase>Requirements</Phase>
               <Note>This issue may happen when the requirements for the cryptographic algorithm are not clearly stated.
               </Note>
            </Introduction>
         </Modes_Of_Introduction>
         <Common_Consequences>
            <Consequence>
               <Scope>Access Control</Scope>
               <Impact>Bypass Protection Mechanism</Impact>
            </Consequence>
            <Consequence>
               <Scope>Confidentiality</Scope>
               <Scope>Integrity</Scope>
               <Impact>Read Application Data</Impact>
               <Impact>Modify Application Data</Impact>
            </Consequence>
            <Consequence>
               <Scope>Accountability</Scope>
               <Scope>Non-Repudiation</Scope>
               <Impact>Hide Activities</Impact>
            </Consequence>
         </Common_Consequences>
         <Observed_Examples>
            <Observed_Example>
               <Reference>CVE-2001-1585</Reference>
               <Description>Missing challenge-response step allows authentication bypass using public key.</Description>
               <Link>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2001-1585</Link>
            </Observed_Example>
         </Observed_Examples>
         <Functional_Areas>
            <Functional_Area>Cryptography</Functional_Area>
         </Functional_Areas>
         <Taxonomy_Mappings>
            <Taxonomy_Mapping Taxonomy_Name="PLOVER">
               <Entry_Name>Missing Required Cryptographic Step</Entry_Name>
            </Taxonomy_Mapping>
            <Taxonomy_Mapping Taxonomy_Name="OWASP Top Ten 2007">
               <Entry_ID>A8</Entry_ID>
               <Entry_Name>Insecure Cryptographic Storage</Entry_Name>
               <Mapping_Fit>CWE More Specific</Mapping_Fit>
            </Taxonomy_Mapping>
            <Taxonomy_Mapping Taxonomy_Name="OWASP Top Ten 2007">
               <Entry_ID>A9</Entry_ID>
               <Entry_Name>Insecure Communications</Entry_Name>
               <Mapping_Fit>CWE More Specific</Mapping_Fit>
            </Taxonomy_Mapping>
         </Taxonomy_Mappings>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="68"/>
         </Related_Attack_Patterns>
         <Notes>
            <Note Type="Relationship">Overlaps incomplete/missing security check.</Note>
            <Note Type="Relationship">Can be resultant.</Note>
         </Notes>
         <Content_History>
            <Submission>
               <Submission_Name>PLOVER</Submission_Name>
               <Submission_Date>2006-07-19</Submission_Date>
            </Submission>
            <Modification>
               <Modification_Name>Eric Dalci</Modification_Name>
               <Modification_Organization>Cigital</Modification_Organization>
               <Modification_Date>2008-07-01</Modification_Date>
               <Modification_Comment>updated Time_of_Introduction</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2008-09-08</Modification_Date>
               <Modification_Comment>updated Description, Functional_Areas, Modes_of_Introduction, Relationships, Observed_Example, Relationship_Notes, Taxonomy_Mappings</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2011-06-01</Modification_Date>
               <Modification_Comment>updated Common_Consequences</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2012-05-11</Modification_Date>
               <Modification_Comment>updated Common_Consequences, Relationships</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2014-06-23</Modification_Date>
               <Modification_Comment>updated Relationships</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2014-07-30</Modification_Date>
               <Modification_Comment>updated Relationships</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2017-11-08</Modification_Date>
               <Modification_Comment>updated Applicable_Platforms, Modes_of_Introduction, Relationships</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2018-03-27</Modification_Date>
               <Modification_Comment>updated Relationships</Modification_Comment>
            </Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-02-24</Modification_Date>
					<Modification_Comment>updated Applicable_Platforms, Description, Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Common_Consequences, Description, Modes_of_Introduction, Name</Modification_Comment>
				</Modification>
			<Previous_Entry_Name Date="2020-08-20">Missing Required Cryptographic Step</Previous_Entry_Name>
         </Content_History>
      </Weakness>
      <Weakness ID="440" Name="Expected Behavior Violation" Abstraction="Base" Structure="Simple" Status="Draft">
         <Description>A feature, API, or function does not perform according to its specification.</Description>
         <Related_Weaknesses>
            <Related_Weakness Nature="ChildOf" CWE_ID="684" View_ID="1000" Ordinal="Primary"/>
         </Related_Weaknesses>
         <Applicable_Platforms>
            <Language Class="Language-Independent" Prevalence="Undetermined"/>
         </Applicable_Platforms>
         <Modes_Of_Introduction>
            <Introduction>
               <Phase>Architecture and Design</Phase>
            </Introduction>
            <Introduction>
               <Phase>Implementation</Phase>
            </Introduction>
            <Introduction>
               <Phase>Operation</Phase>
            </Introduction>
         </Modes_Of_Introduction>
         <Common_Consequences>
            <Consequence>
               <Scope>Other</Scope>
               <Impact>Quality Degradation</Impact>
               <Impact>Varies by Context</Impact>
            </Consequence>
         </Common_Consequences>
         <Observed_Examples>
            <Observed_Example>
               <Reference>CVE-2003-0187</Reference>
               <Description>Program uses large timeouts on "undeserving" to compensate for inconsistency of support for linked lists.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2003-0187</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2003-0465</Reference>
               <Description>"strncpy" in Linux kernel acts different than libc on x86, leading to expected behavior difference - sort of a multiple interpretation error?</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2003-0465</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2005-3265</Reference>
               <Description>Buffer overflow in product stems the use of a third party library function that is expected to have internal protection against overflows, but doesn't.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2005-3265</Link>
            </Observed_Example>
         </Observed_Examples>
         <Taxonomy_Mappings>
            <Taxonomy_Mapping Taxonomy_Name="PLOVER">
               <Entry_Name>Expected behavior violation</Entry_Name>
            </Taxonomy_Mapping>
         </Taxonomy_Mappings>
         <Notes>
            <Note Type="Theoretical">The behavior of an application that is not consistent with the expectations of the developer may lead to incorrect use of the software.</Note>
         </Notes>
         <Content_History>
            <Submission>
               <Submission_Name>PLOVER</Submission_Name>
               <Submission_Date>2006-07-19</Submission_Date>
            </Submission>
            <Modification>
               <Modification_Name>Eric Dalci</Modification_Name>
               <Modification_Organization>Cigital</Modification_Organization>
               <Modification_Date>2008-07-01</Modification_Date>
               <Modification_Comment>updated Time_of_Introduction</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2008-09-08</Modification_Date>
               <Modification_Comment>updated Relationships, Other_Notes, Taxonomy_Mappings</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2009-10-29</Modification_Date>
               <Modification_Comment>updated Other_Notes, Relevant_Properties, Theoretical_Notes</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2011-06-01</Modification_Date>
               <Modification_Comment>updated Common_Consequences</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2011-06-27</Modification_Date>
               <Modification_Comment>updated Common_Consequences</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2012-05-11</Modification_Date>
               <Modification_Comment>updated Relationships</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2014-07-30</Modification_Date>
               <Modification_Comment>updated Relationships</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2017-11-08</Modification_Date>
               <Modification_Comment>updated Applicable_Platforms, Relevant_Properties</Modification_Comment>
            </Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-02-24</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Description, Observed_Examples, Theoretical_Notes</Modification_Comment>
				</Modification>
         </Content_History>
      </Weakness>
      <Weakness ID="441" Name="Unintended Proxy or Intermediary ('Confused Deputy')" Abstraction="Class" Structure="Simple" Status="Draft">
         <Description>The product receives a request, message, or directive from an upstream component, but the product does not sufficiently preserve the original source of the request before forwarding the request to an external actor that is outside of the product's control sphere. This causes the product to appear to be the source of the request, leading it to act as a proxy or other intermediary between the upstream component and the external actor.</Description>
         <Extended_Description>
            <xhtml:p>If an attacker cannot directly contact a target, but the product has access to the target, then the attacker can send a request to the product and have it be forwarded to the target. The request would appear to be coming from the product's system, not the attacker's system. As a result, the attacker can bypass access controls (such as firewalls) or hide the source of malicious requests, since the requests would not be coming directly from the attacker.</xhtml:p>
            <xhtml:p>Since proxy functionality and message-forwarding often serve a legitimate purpose, this issue only becomes a vulnerability when:</xhtml:p>
            <xhtml:div style="margin-left:10px;">
               <xhtml:ul>
                  <xhtml:li>The product runs with different privileges or on a different system, or otherwise has different levels of access than the upstream component;</xhtml:li>
                  <xhtml:li>The attacker is prevented from making the request directly to the target; and</xhtml:li>
                  <xhtml:li>The attacker can create a request that the proxy does not explicitly intend to be forwarded on the behalf of the requester. Such a request might point to an unexpected hostname, port number, hardware IP, or service. Or, the request might be sent to an allowed service, but the request could contain disallowed directives, commands, or resources.</xhtml:li>
               </xhtml:ul>
            </xhtml:div>
         </Extended_Description>
         <Related_Weaknesses>
            <Related_Weakness Nature="ChildOf" CWE_ID="610" View_ID="1000" Ordinal="Primary"/>
            <Related_Weakness Nature="CanPrecede" CWE_ID="668" View_ID="1000"/>
         </Related_Weaknesses>
         <Applicable_Platforms>
            <Language Class="Language-Independent" Prevalence="Undetermined"/>
			<Operating_System Class="OS-Independent" Prevalence="Undetermined"/>
			<Architecture Class="Architecture-Independent" Prevalence="Undetermined"/>
			<Technology Class="Technology-Independent" Prevalence="Undetermined"/>
         </Applicable_Platforms>
         <Alternate_Terms>
            <Alternate_Term>
               <Term>Confused Deputy</Term>
               <Description>This weakness is sometimes referred to as the "Confused deputy" problem, in which an attacker misused the authority of one victim (the "confused deputy") when targeting another victim.</Description>
            </Alternate_Term>
         </Alternate_Terms>
         <Modes_Of_Introduction>
            <Introduction>
               <Phase>Architecture and Design</Phase>
               <Note>REALIZATION: This weakness is caused during implementation of an architectural security tactic.</Note>
            </Introduction>
         </Modes_Of_Introduction>
         <Common_Consequences>
            <Consequence>
               <Scope>Non-Repudiation</Scope>
               <Scope>Access Control</Scope>
               <Impact>Gain Privileges or Assume Identity</Impact>
               <Impact>Hide Activities</Impact>
               <Impact>Execute Unauthorized Code or Commands</Impact>
            </Consequence>
         </Common_Consequences>
         <Potential_Mitigations>
            <Mitigation>
               <Phase>Architecture and Design</Phase>
               <Description>Enforce the use of strong mutual authentication mechanism between the two parties.</Description>
            </Mitigation>
            <Mitigation>
               <Phase>Architecture and Design</Phase>
               <Description>Whenever a product is an intermediary or proxy for
                   transactions between two other components, the proxy core
                   should not drop the identity of the initiator of the
                   transaction. The immutability of the identity of the
                   initiator must be maintained and should be forwarded all the
                   way to the target. </Description>
            </Mitigation>
         </Potential_Mitigations>
         <Demonstrative_Examples>
             <Demonstrative_Example>
                 <Intro_Text>
                     A SoC contains a microcontroller (running ring-3
                     (least trusted ring) code), a Memory Mapped Input Output
                     (MMIO) mapped IP core (containing design-house secrets),
                     and a Direct Memory Access (DMA) controller, among several
                     other compute elements and peripherals. The SoC implements
                     access control to protect the registers in the IP core
                     (which registers store the design-house secrets) from
                     malicious, ring-3 (least trusted ring) code executing on
                     the microcontroller.  The DMA controller, however, is not
                     blocked off from accessing the IP core for functional
                     reasons.
                 </Intro_Text>
                 <Example_Code Nature="bad" Language="Other">
                     The code in ring-3 (least trusted ring) of the
                     microcontroller attempts to directly read the protected
                     registers in IP core through MMIO transactions. However,
                     this attempt is blocked due to the implemented access
                     control. Now, the microcontroller configures the DMA core
                     to transfer data from the protected registers to a memory
                     region that it has access to. The DMA core, which is
                     acting as an intermediary in this transaction, does not
                     preserve the identity of the microcontroller and, instead,
                     initiates a new transaction with its own identity. Since
                     the DMA core has access, the transaction (and hence, the
                     attack) is successful.
                 </Example_Code>
                 <Body_Text>The weakness here is that the intermediary or the
                     proxy agent did not ensure the immutability of the
                     identity of the microcontroller initiating the
                     transaction. 
                 </Body_Text>
                 <Example_Code Nature="good" Language="Other">The DMA
                     core forwards this transaction with the identity of the
                     code executing on the microcontroller, which is the
                     original initiator of the end-to-end transaction. Now the
                     transaction is blocked, as a result of forwarding the
                     identity of the true initiator which lacks the permission
                     to access the confidential MMIO mapped IP core.
                 </Example_Code>
             </Demonstrative_Example>
         </Demonstrative_Examples>
         <Observed_Examples>
            <Observed_Example>
               <Reference>CVE-1999-0017</Reference>
               <Description>FTP bounce attack. The design of the protocol allows an attacker to modify the PORT command to cause the FTP server to connect to other machines besides the attacker's.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-1999-0017</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-1999-0168</Reference>
               <Description>RPC portmapper could redirect service requests from an attacker to another entity, which thinks the requests came from the portmapper.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-1999-0168</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2005-0315</Reference>
               <Description>FTP server does not ensure that the IP address in a PORT command is the same as the FTP user's session, allowing port scanning by proxy.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2005-0315</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2002-1484</Reference>
               <Description>Web server allows attackers to request a URL from another server, including other ports, which allows proxied scanning.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2002-1484</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2004-2061</Reference>
               <Description>CGI script accepts and retrieves incoming URLs.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2004-2061</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2001-1484</Reference>
               <Description>Bounce attack allows access to TFTP from trusted side.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2001-1484</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2010-1637</Reference>
               <Description>Web-based mail program allows internal network scanning using a modified POP3 port number.</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2010-1637</Link>
            </Observed_Example>
            <Observed_Example>
               <Reference>CVE-2009-0037</Reference>
               <Description>URL-downloading library automatically follows redirects to file:// and scp:// URLs</Description>
               <Link>https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2009-0037</Link>
            </Observed_Example>
         </Observed_Examples>
         <Taxonomy_Mappings>
            <Taxonomy_Mapping Taxonomy_Name="PLOVER">
               <Entry_Name>Unintended proxy/intermediary</Entry_Name>
            </Taxonomy_Mapping>
            <Taxonomy_Mapping Taxonomy_Name="PLOVER">
               <Entry_Name>Proxied Trusted Channel</Entry_Name>
            </Taxonomy_Mapping>
            <Taxonomy_Mapping Taxonomy_Name="WASC">
               <Entry_ID>32</Entry_ID>
               <Entry_Name>Routing Detour</Entry_Name>
            </Taxonomy_Mapping>
         </Taxonomy_Mappings>
         <Related_Attack_Patterns>
            <Related_Attack_Pattern CAPEC_ID="141"/>
            <Related_Attack_Pattern CAPEC_ID="142"/>
            <Related_Attack_Pattern CAPEC_ID="219"/>
            <Related_Attack_Pattern CAPEC_ID="465"/>
         </Related_Attack_Patterns>
         <References>
            <Reference External_Reference_ID="REF-432"/>
            <Reference External_Reference_ID="REF-1125"/>
         </References>
         <Notes>
            <Note Type="Relationship">This weakness has a chaining relationship with CWE-668 (Exposure of Resource to Wrong Sphere) because the proxy effectively provides the attacker with access to the target's resources that the attacker cannot directly obtain.</Note>
            <Note Type="Maintenance">This could possibly be considered as an emergent resource.</Note>
            <Note Type="Theoretical">It could be argued that the "confused deputy" is a fundamental aspect of most vulnerabilities that require an active attacker. Even for common implementation issues such as buffer overflows, SQL injection, OS command injection, and path traversal, the vulnerable program already has the authorization to run code or access files. The vulnerability arises when the attacker causes the program to run unexpected code or access unexpected files.</Note>
         </Notes>
         <Content_History>
            <Submission>
               <Submission_Name>PLOVER</Submission_Name>
               <Submission_Date>2006-07-19</Submission_Date>
            </Submission>
            <Modification>
               <Modification_Name>Eric Dalci</Modification_Name>
               <Modification_Organization>Cigital</Modification_Organization>
               <Modification_Date>2008-07-01</Modification_Date>
               <Modification_Comment>updated Potential_Mitigations, Time_of_Introduction</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2008-09-08</Modification_Date>
               <Modification_Comment>updated Relationships, Observed_Example, Other_Notes, Taxonomy_Mappings</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2008-11-24</Modification_Date>
               <Modification_Comment>updated Maintenance_Notes, Relationships, Taxonomy_Mappings, Time_of_Introduction</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2010-02-16</Modification_Date>
               <Modification_Comment>updated Taxonomy_Mappings</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2010-04-05</Modification_Date>
               <Modification_Comment>updated Related_Attack_Patterns</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2010-06-21</Modification_Date>
               <Modification_Comment>updated Other_Notes</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2011-06-01</Modification_Date>
               <Modification_Comment>updated Common_Consequences</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2011-06-27</Modification_Date>
               <Modification_Comment>updated Common_Consequences</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2012-05-11</Modification_Date>
               <Modification_Comment>updated Related_Attack_Patterns, Relationships</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2012-10-30</Modification_Date>
               <Modification_Comment>updated Potential_Mitigations</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2013-02-21</Modification_Date>
               <Modification_Comment>updated Alternate_Terms, Applicable_Platforms, Description, Maintenance_Notes, Name, Observed_Examples, References, Relationship_Notes, Relationships, Theoretical_Notes, Type</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2014-07-30</Modification_Date>
               <Modification_Comment>updated Relationships</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2015-12-07</Modification_Date>
               <Modification_Comment>updated Relationships</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2017-01-19</Modification_Date>
               <Modification_Comment>updated Relationships</Modification_Comment>
            </Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2017-11-08</Modification_Date>
               <Modification_Comment>updated Modes_of_Introduction, Relationships</Modification_Comment>
            </Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2019-06-20</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-02-24</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
            <Modification>
               <Modification_Name>CWE Content Team</Modification_Name>
               <Modification_Organization>MITRE</Modification_Organization>
               <Modification_Date>2020-08-14</Modification_Date>
               <Modification_Comment>Per Intel Corporation suggestion, added language to be inclusive to hardware: updated Demonstrative_Examples, Description, Extended_Description, Applicable_Platforms, Potential_Mitigation, Common_Consequences, References</Modification_Comment>
            </Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Applicable_Platforms, Common_Consequences, Demonstrative_Examples, Description, Potential_Mitigations, References, Relationships</Modification_Comment>
				</Modification>
            <Previous_Entry_Name Date="2013-02-21">Unintended Proxy/Intermediary</Previous_Entry_Name>
         </Content_History>
      </Weakness>
   </Weaknesses>
   <Categories>
      <Category ID="1195" Name="Manufacturing and Life Cycle Management Concerns" Status="Draft">
         <Summary>Weaknesses in this category are root-caused to defects that arise in the semiconductor-manufacturing process or during the life cycle and supply chain.</Summary>
         <Relationships>
             <Has_Member CWE_ID="1248" View_ID="1194"/>
             <Has_Member CWE_ID="1266" View_ID="1194"/>
             <Has_Member CWE_ID="1269" View_ID="1194"/>
             <Has_Member CWE_ID="1273" View_ID="1194"/>
             <Has_Member CWE_ID="1278" View_ID="1194"/>
			 <Has_Member CWE_ID="1297" View_ID="1194"/>
         </Relationships>
         <Content_History>
             <Submission>
			     <Submission_Name>CWE Content Team</Submission_Name>
			     <Submission_Organization>MITRE</Submission_Organization>
                 <Submission_Date>2019-12-27</Submission_Date>
             </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-06-25</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
         </Content_History>
      </Category>
      <Category ID="1196" Name="Security Flow Issues" Status="Draft">
         <Summary>Weaknesses in this category are related to improper design of full-system security flows, including but not limited to secure boot, secure update, and hardware-device attestation.</Summary>
         <Relationships>
             <Has_Member CWE_ID="1190" View_ID="1194"/>
             <Has_Member CWE_ID="1193" View_ID="1194"/>
             <Has_Member CWE_ID="1264" View_ID="1194"/>
             <Has_Member CWE_ID="1274" View_ID="1194"/>
             <Has_Member CWE_ID="1283" View_ID="1194"/>
             <Has_Member CWE_ID="1310" View_ID="1194"/>
             <Has_Member CWE_ID="1326" View_ID="1194"/>
             <Has_Member CWE_ID="1328" View_ID="1194"/>
         </Relationships>
         <Content_History>
             <Submission>
			     <Submission_Name>CWE Content Team</Submission_Name>
			     <Submission_Organization>MITRE</Submission_Organization>
                 <Submission_Date>2019-12-27</Submission_Date>
             </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-06-25</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-12-10</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
         </Content_History>
      </Category>
      <Category ID="1197" Name="Integration Issues" Status="Draft">
         <Summary>Weaknesses in this category are those that arise due to integration of multiple hardware Intellectual Property (IP) cores, from System-on-a-Chip (SoC) subsystem interactions, or from hardware platform subsystem interactions.</Summary>
		 <Relationships>
            <Has_Member CWE_ID="1276" View_ID="1194"/>
         </Relationships>
         <Content_History>
             <Submission>
			     <Submission_Name>CWE Content Team</Submission_Name>
			     <Submission_Organization>MITRE</Submission_Organization>
                 <Submission_Date>2019-12-27</Submission_Date>
             </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-06-25</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Description</Modification_Comment>
				</Modification>
         </Content_History>
      </Category>
      <Category ID="1198" Name="Privilege Separation and Access Control Issues" Status="Draft">
         <Summary>Weaknesses in this category are related to features and mechanisms providing hardware-based isolation and access control (e.g., identity, policy, locking control) of sensitive shared hardware resources such as registers and fuses.</Summary>
         <Relationships>
            <Has_Member CWE_ID="276" View_ID="1194"/>
            <Has_Member CWE_ID="441" View_ID="1194"/>
            <Has_Member CWE_ID="1189" View_ID="1194"/>
            <Has_Member CWE_ID="1192" View_ID="1194"/>
            <Has_Member CWE_ID="1220" View_ID="1194"/>
            <Has_Member CWE_ID="1242" View_ID="1194"/>
            <Has_Member CWE_ID="1260" View_ID="1194"/>
            <Has_Member CWE_ID="1262" View_ID="1194"/>
            <Has_Member CWE_ID="1267" View_ID="1194"/>
            <Has_Member CWE_ID="1268" View_ID="1194"/>
            <Has_Member CWE_ID="1280" View_ID="1194"/>
            <Has_Member CWE_ID="1294" View_ID="1194"/>
            <Has_Member CWE_ID="1299" View_ID="1194"/>
            <Has_Member CWE_ID="1302" View_ID="1194"/>
            <Has_Member CWE_ID="1303" View_ID="1194"/>
            <Has_Member CWE_ID="1314" View_ID="1194"/>
            <Has_Member CWE_ID="1318" View_ID="1194"/>
            <Has_Member CWE_ID="1334" View_ID="1194"/>
         </Relationships>
         <Content_History>
             <Submission>
			     <Submission_Name>CWE Content Team</Submission_Name>
			     <Submission_Organization>MITRE</Submission_Organization>
                 <Submission_Date>2019-12-27</Submission_Date>
             </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-06-25</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-12-10</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
         </Content_History>
      </Category>
      <Category ID="1199" Name="General Circuit and Logic Design Concerns" Status="Draft">
         <Summary>Weaknesses in this category are related to hardware-circuit design and logic (e.g., CMOS transistors, finite state machines, and registers) as well as issues related to hardware description languages such as System Verilog and VHDL.</Summary>
         <Relationships>
            <Has_Member CWE_ID="1209" View_ID="1194"/>
            <Has_Member CWE_ID="1221" View_ID="1194"/>
            <Has_Member CWE_ID="1223" View_ID="1194"/>
            <Has_Member CWE_ID="1224" View_ID="1194"/>
            <Has_Member CWE_ID="1231" View_ID="1194"/>
            <Has_Member CWE_ID="1232" View_ID="1194"/>
            <Has_Member CWE_ID="1233" View_ID="1194"/>
            <Has_Member CWE_ID="1234" View_ID="1194"/>
            <Has_Member CWE_ID="1245" View_ID="1194"/>
            <Has_Member CWE_ID="1253" View_ID="1194"/>
            <Has_Member CWE_ID="1254" View_ID="1194"/>
            <Has_Member CWE_ID="1261" View_ID="1194"/>
            <Has_Member CWE_ID="1298" View_ID="1194"/>
         </Relationships>
         <Content_History>
             <Submission>
			     <Submission_Name>CWE Content Team</Submission_Name>
			     <Submission_Organization>MITRE</Submission_Organization>
                 <Submission_Date>2019-12-27</Submission_Date>
             </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-06-25</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
         </Content_History>
      </Category>
      <Category ID="1201" Name="Core and Compute Issues" Status="Draft">
         <Summary>Weaknesses in this category are typically associated with CPUs, Graphics, Vision, AI, FPGA, and microcontrollers.</Summary>
         <Relationships>
             <Has_Member CWE_ID="1252" View_ID="1194"/>
             <Has_Member CWE_ID="1281" View_ID="1194"/>
             <Has_Member CWE_ID="1342" View_ID="1194"/>
         </Relationships>
         <Content_History>
             <Submission>
			     <Submission_Name>CWE Content Team</Submission_Name>
			     <Submission_Organization>MITRE</Submission_Organization>
                 <Submission_Date>2019-12-27</Submission_Date>
             </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-06-25</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
         </Content_History>
      </Category>
      <Category ID="1202" Name="Memory and Storage Issues" Status="Draft">
         <Summary>Weaknesses in this category are typically associated with memory (e.g., DRAM, SRAM) and storage technologies (e.g., NAND Flash, OTP, EEPROM, and eMMC).</Summary>
         <Relationships>
            <Has_Member CWE_ID="226" View_ID="1194"/>
            <Has_Member CWE_ID="1246" View_ID="1194"/>
            <Has_Member CWE_ID="1251" View_ID="1194"/>
            <Has_Member CWE_ID="1257" View_ID="1194"/>
            <Has_Member CWE_ID="1282" View_ID="1194"/>
         </Relationships>
         <Content_History>
             <Submission>
			     <Submission_Name>CWE Content Team</Submission_Name>
			     <Submission_Organization>MITRE</Submission_Organization>
                 <Submission_Date>2019-12-27</Submission_Date>
             </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-06-25</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
         </Content_History>
      </Category>
      <Category ID="1203" Name="Peripherals, On-chip Fabric, and Interface/IO Problems" Status="Draft">
         <Summary>
		   Weaknesses in this category are related to hardware
		   security problems that apply to peripheral devices, IO
		   interfaces, on-chip interconnects, network-on-chip (NoC),
		   and buses.  For example, this category includes issues
		   related to design of hardware interconnect and/or protocols
		   such as PCIe, USB, SMBUS, general-purpose IO pins, and
		   user-input peripherals such as mouse and keyboard.
		 </Summary>
       <Relationships>
             <Has_Member CWE_ID="1311" View_ID="1194"/>
             <Has_Member CWE_ID="1312" View_ID="1194"/>
             <Has_Member CWE_ID="1315" View_ID="1194"/>
             <Has_Member CWE_ID="1316" View_ID="1194"/>
             <Has_Member CWE_ID="1317" View_ID="1194"/>
             <Has_Member CWE_ID="1319" View_ID="1194"/>
             <Has_Member CWE_ID="1331" View_ID="1194"/>
       </Relationships>
         <Content_History>
             <Submission>
			     <Submission_Name>CWE Content Team</Submission_Name>
			     <Submission_Organization>MITRE</Submission_Organization>
                 <Submission_Date>2019-12-27</Submission_Date>
             </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-12-10</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
         </Content_History>
      </Category>
      <Category ID="1205" Name="Security Primitives and Cryptography Issues" Status="Draft">
         <Summary>Weaknesses in this category are related to hardware implementations of cryptographic protocols and other hardware-security primitives such as physical unclonable functions (PUFs) and random number generators (RNGs).</Summary>
         <Relationships>
            <Has_Member CWE_ID="203" View_ID="1194"/>
            <Has_Member CWE_ID="325" View_ID="1194"/>
            <Has_Member CWE_ID="1240" View_ID="1194"/>
            <Has_Member CWE_ID="1241" View_ID="1194"/>
            <Has_Member CWE_ID="1279" View_ID="1194"/>
            <Has_Member CWE_ID="1351" View_ID="1194"/>
         </Relationships>
         <Content_History>
             <Submission>
			     <Submission_Name>CWE Content Team</Submission_Name>
			     <Submission_Organization>MITRE</Submission_Organization>
                 <Submission_Date>2019-12-27</Submission_Date>
             </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-06-25</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2021-07-20</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
         </Content_History>
      </Category>
      <Category ID="1206" Name="Power, Clock, and Reset Concerns" Status="Draft">
         <Summary>Weaknesses in this category are related to system power, voltage, current, temperature, clocks, system state saving/restoring, and resets at the platform and SoC level.</Summary>
         <Relationships>
             <Has_Member CWE_ID="1232" View_ID="1194"/>
             <Has_Member CWE_ID="1247" View_ID="1194"/>
             <Has_Member CWE_ID="1255" View_ID="1194"/>
             <Has_Member CWE_ID="1256" View_ID="1194"/>
             <Has_Member CWE_ID="1271" View_ID="1194"/>
             <Has_Member CWE_ID="1304" View_ID="1194"/>
             <Has_Member CWE_ID="1314" View_ID="1194"/>
             <Has_Member CWE_ID="1320" View_ID="1194"/>
             <Has_Member CWE_ID="1332" View_ID="1194"/>
             <Has_Member CWE_ID="1338" View_ID="1194"/>
         </Relationships>
         <Content_History>
             <Submission>
			     <Submission_Name>CWE Content Team</Submission_Name>
			     <Submission_Organization>MITRE</Submission_Organization>
                 <Submission_Date>2019-12-27</Submission_Date>
             </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-06-25</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-12-10</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
         </Content_History>
      </Category>
      <Category ID="1207" Name="Debug and Test Problems" Status="Draft">
         <Summary>Weaknesses in this category are related to hardware debug and test interfaces such as JTAG and scan chain.</Summary>
         <Relationships>
             <Has_Member CWE_ID="1191" View_ID="1194"/>
             <Has_Member CWE_ID="1234" View_ID="1194"/>
             <Has_Member CWE_ID="1243" View_ID="1194"/>
             <Has_Member CWE_ID="1244" View_ID="1194"/>
             <Has_Member CWE_ID="1258" View_ID="1194"/>
             <Has_Member CWE_ID="1272" View_ID="1194"/>
             <Has_Member CWE_ID="1291" View_ID="1194"/>
             <Has_Member CWE_ID="1295" View_ID="1194"/>
			    <Has_Member CWE_ID="1296" View_ID="1194"/>
             <Has_Member CWE_ID="1313" View_ID="1194"/>
			    <Has_Member CWE_ID="1323" View_ID="1194"/>
			    <Has_Member CWE_ID="1324" View_ID="1194"/>
         </Relationships>
         <Content_History>
             <Submission>
			     <Submission_Name>CWE Content Team</Submission_Name>
			     <Submission_Organization>MITRE</Submission_Organization>
                 <Submission_Date>2019-12-27</Submission_Date>
             </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-06-25</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-12-10</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
         </Content_History>
      </Category>
      <Category ID="1208" Name="Cross-Cutting Problems" Status="Draft">
         <Summary>Weaknesses in this category can arise in multiple areas of hardware design or can apply to a wide cross-section of components.</Summary>
         <Relationships>
            <Has_Member CWE_ID="440" View_ID="1194"/>
            <Has_Member CWE_ID="1053" View_ID="1194"/>
            <Has_Member CWE_ID="1263" View_ID="1194"/>
			<Has_Member CWE_ID="1277" View_ID="1194"/>
            <Has_Member CWE_ID="1278" View_ID="1194"/>
            <Has_Member CWE_ID="1300" View_ID="1194"/>
            <Has_Member CWE_ID="1301" View_ID="1194"/>
         </Relationships>
         <Content_History>
             <Submission>
			     <Submission_Name>CWE Content Team</Submission_Name>
			     <Submission_Organization>MITRE</Submission_Organization>
                 <Submission_Date>2019-12-27</Submission_Date>
             </Submission>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-06-25</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
				<Modification>
					<Modification_Name>CWE Content Team</Modification_Name>
					<Modification_Organization>MITRE</Modification_Organization>
					<Modification_Date>2020-08-20</Modification_Date>
					<Modification_Comment>updated Relationships</Modification_Comment>
				</Modification>
         </Content_History>
      </Category>
   </Categories>
   <Views>
      <View ID="1194" Name="Hardware Design" Type="Graph" Status="Draft">
         <Objective>This view organizes weaknesses around concepts that are frequently used or encountered in hardware design. Accordingly, this view can align closely with the perspectives of designers, manufacturers, educators, and assessment vendors. It provides a variety of categories that are intended to simplify navigation, browsing, and mapping.</Objective>
         <Audience>
            <Stakeholder>
               <Type>Hardware Designers</Type>
               <Description>Hardware Designers use this view to better understand potential mistakes that can be made in specific areas of their IP design. The use of concepts with which hardware designers are familiar makes it easier to navigate.</Description>
            </Stakeholder>
            <Stakeholder>
               <Type>Educators</Type>
               <Description>Educators use this view to teach future professionals about the types of mistakes that are commonly made in hardware design.</Description>
            </Stakeholder>
         </Audience>
         <Members>
            <Has_Member CWE_ID="1195" View_ID="1194"/>
            <Has_Member CWE_ID="1196" View_ID="1194"/>
            <Has_Member CWE_ID="1197" View_ID="1194"/>
            <Has_Member CWE_ID="1198" View_ID="1194"/>
            <Has_Member CWE_ID="1199" View_ID="1194"/>
            <Has_Member CWE_ID="1201" View_ID="1194"/>
            <Has_Member CWE_ID="1202" View_ID="1194"/>
            <Has_Member CWE_ID="1203" View_ID="1194"/>
            <Has_Member CWE_ID="1205" View_ID="1194"/>
            <Has_Member CWE_ID="1206" View_ID="1194"/>
            <Has_Member CWE_ID="1207" View_ID="1194"/>
            <Has_Member CWE_ID="1208" View_ID="1194"/>
         </Members>
         <Notes>
            <Note Type="Other">The top level categories in this view represent commonly understood areas/terms within hardware design, and are meant to aid the user in identifying potential related weaknesses. It is possible for the same weakness to exist within multiple different categories.</Note>
            <Note Type="Other">This view attempts to present weaknesses in a simple and intuitive way. As such it targets a single level of abstraction. It is important to realize that not every CWE will be represented in this view. High-level class weaknesses and low-level variant weaknesses are mostly ignored. However, by exploring the weaknesses that are included, and following the defined relationships, one can find these higher and lower level weaknesses.</Note>
         </Notes>
         <Content_History>
            <Submission>
               <Submission_Name>CWE Content Team</Submission_Name>
               <Submission_Organization>MITRE</Submission_Organization>
               <Submission_Date>2019-12-27</Submission_Date>
            </Submission>
         </Content_History>
      </View>
   </Views>
   <External_References>
      <External_Reference Reference_ID="REF-62">
			<Author>Mark Dowd</Author>
			<Author>John McDonald</Author>
			<Author>Justin Schuh</Author>
			<Title>The Art of Software Security Assessment</Title>
			<Edition>1st Edition</Edition>
			<Publication_Year>2006</Publication_Year>
			<Publisher>Addison Wesley</Publisher>
		</External_Reference>
      <External_Reference Reference_ID="REF-267">
			<Author>Information Technology Laboratory, National Institute of Standards and Technology</Author>
			<Title>SECURITY REQUIREMENTS FOR CRYPTOGRAPHIC MODULES</Title>
			<Publication_Year>2001</Publication_Year>
			<Publication_Month>--05</Publication_Month>
			<Publication_Day>---25</Publication_Day>
			<URL>http://csrc.nist.gov/publications/fips/fips140-2/fips1402.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-432">
			<Author>Norm Hardy</Author>
			<Title>The Confused Deputy (or why capabilities might have been invented)</Title>
			<Publication_Year>1988</Publication_Year>
			<URL>http://www.cap-lore.com/CapTheory/ConfusedDeputy.html</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-963">
			<Author>Robert A. Martin</Author>
			<Author>Lawrence H. Shafer</Author>
			<Title>Providing a Framework for Effective Software Quality Assessment</Title>
			<Publication_Year>1996</Publication_Year>
			<Publication_Month>--07</Publication_Month>
			<URL>https://www.researchgate.net/publication/285403022_PROVIDING_A_FRAMEWORK_FOR_EFFECTIVE_SOFTWARE_QUALITY_MEASUREMENT_MAKING_A_SCIENCE_OF_RISK_ASSESSMENT</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1036">
			<Author>Ali Abbasi and Majid Hashemi</Author>
			<Title>Ghost in the PLC Designing an Undetectable Programmable Logic Controller Rootkit via Pin Control Attack</Title>
			<Publication_Year>2016</Publication_Year>
			<URL>https://www.blackhat.com/docs/eu-16/materials/eu-16-Abbasi-Ghost-In-The-PLC-Designing-An-Undetectable-Programmable-Logic-Controller-Rootkit-wp.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1037">
			<Author>Kurt Rosenfeld</Author>
			<Author>Ramesh Karri</Author>
			<Title>Attacks and Defenses for JTAG</Title>
			<Publication_Year>2010</Publication_Year>
			<Publication_Month>--02</Publication_Month>
			<URL>https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5406671</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1038">
			<Title>DMA attack</Title>
			<Publication_Year>2019</Publication_Year>
			<Publication_Month>--10</Publication_Month>
			<Publication_Day>---19</Publication_Day>
			<URL>https://en.wikipedia.org/wiki/DMA_attack</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1039">
			<Author>A. Theodore Markettos</Author>
			<Author>Colin Rothwell</Author>
			<Author>Brett F. Gutstein</Author>
			<Author>Allison Pearce</Author>
			<Author>Peter G. Neumann</Author>
			<Author>Simon W. Moore</Author>
			<Author>Robert N. M. Watson</Author>
			<Title>Thunderclap: Exploring Vulnerabilities in Operating System IOMMU Protection via DMA from Untrustworthy Peripherals</Title>
			<Publication_Year>2019</Publication_Year>
			<Publication_Month>--02</Publication_Month>
			<Publication_Day>---25</Publication_Day>
			<URL>https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_05A-1_Markettos_paper.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1040">
			<Author>Maximillian Dornseif</Author>
			<Author>Michael Becher</Author>
			<Author>Christian N. Klein</Author>
			<Title>FireWire all your memory are belong to us</Title>
			<Publication_Year>2005</Publication_Year>
			<URL>https://cansecwest.com/core05/2005-firewire-cansecwest.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1041">
			<Author>Rory Breuk</Author>
			<Author>Albert Spruyt</Author>
			<Author>Adam Boileau</Author>
			<Title>Integrating DMA attacks in exploitation frameworks</Title>
			<Publication_Year>2012</Publication_Year>
			<Publication_Month>--02</Publication_Month>
			<Publication_Day>---20</Publication_Day>
			<URL>https://www.os3.nl/_media/2011-2012/courses/rp1/p14_report.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1042">
			<Author>Maximillian Dornseif</Author>
			<Title>Owned by an iPod</Title>
			<Publication_Year>2004</Publication_Year>
			<URL>https://pacsec.jp/psj04/psj04-dornseif-e.ppt</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1043">
			<Author>Gopal Vishwakarma</Author>
			<Author>Wonjun Lee</Author>
			<Title>Exploiting JTAG and Its Mitigation in IOT: A Survey</Title>
			<Publication_Year>2018</Publication_Year>
			<Publication_Month>--12</Publication_Month>
			<Publication_Day>---03</Publication_Day>
			<URL>https://www.mdpi.com/1999-5903/10/12/121/pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1044">
			<Author>Dmytro Oleksiuk</Author>
			<Title>My aimful life</Title>
			<Publication_Year>2015</Publication_Year>
			<Publication_Month>--09</Publication_Month>
			<Publication_Day>---12</Publication_Day>
			<URL>http://blog.cr4.sh/2015/09/breaking-uefi-security-with-software.html</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1046">
			<Author>A. Theodore Markettos</Author>
			<Author>Adam Boileau</Author>
			<Title>Hit by a Bus:Physical Access Attacks with Firewire</Title>
			<Publication_Year>2006</Publication_Year>
			<URL>https://security-assessment.com/files/presentations/ab_firewire_rux2k6-final.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1055">
			<Author>Peter Gutmann</Author>
			<Title>Data Remanence in Semiconductor Devices</Title>
			<Publication>10th USENIX Security Symposium</Publication>
			<Publication_Year>2001</Publication_Year>
			<Publication_Month>--08</Publication_Month>
			<URL>https://www.usenix.org/legacy/events/sec01/full_papers/gutmann/gutmann.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1056">
			<Author>F-Secure Labs</Author>
			<Title>Multiple Vulnerabilities in Barco Clickshare: JTAG access is not permanently disabled</Title>
			<URL>https://labs.f-secure.com/advisories/multiple-vulnerabilities-in-barco-clickshare/</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1057">
			<Author>Kurt Rosenfeld</Author>
			<Author>Ramesh Karri</Author>
			<Title>Attacks and Defenses for JTAG</Title>
			<URL>https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5406671</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1058">
			<Author>Moinuddin Qureshi</Author>
			<Author>Michele Franchescini</Author>
			<Author>Vijayalakshmi Srinivasan</Author>
			<Author>Luis Lastras</Author>
			<Author>Bulent Abali</Author>
			<Author>John Karidis</Author>
			<Title>Enhancing Lifetime and Security of PCM-Based Main Memory with Start-Gap Wear Leveling</Title>
			<URL>https://researcher.watson.ibm.com/researcher/files/us-moinqureshi/papers-sgap.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1059">
			<Author>Micron</Author>
			<Title>Bad Block Management in NAND Flash Memory</Title>
			<URL>https://www.micron.com/-/media/client/global/documents/products/technical-note/nand-flash/tn2959_bbm_in_nand_flash.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1060">
			<Author>Farimah Farahmandi</Author>
			<Author>Prabhat Mishra</Author>
			<Title>FSM Anomaly Detection using Formal Analysis</Title>
			<URL>https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8119228&amp;tag=1</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1061">
			<Author>Keith Bowman</Author>
			<Author>James Tschanz</Author>
			<Author>Chris Wilkerson</Author>
			<Author>Shih-Lien Lu</Author>
			<Author>Tanay Karnik</Author>
			<Author>Vivek De</Author>
			<Author>Shekhar Borkar</Author>
			<Title>Circuit Techniques for Dynamic Variation Tolerance</Title>
			<URL>https://dl.acm.org/doi/10.1145/1629911.1629915</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1062">
			<Author>Dan Ernst</Author>
			<Author>Nam Sung Kim</Author>
			<Author>Shidhartha Das</Author>
			<Author>Sanjay Pant</Author>
			<Author>Rajeev Rao</Author>
			<Author>Toan Pham</Author>
			<Author>Conrad Ziesler</Author>
			<Author>David Blaauw</Author>
			<Author>Todd Austin</Author>
			<Author>Krisztian Flautner</Author>
			<Author>Trevor Mudge</Author>
			<Title>Razor: A Low-Power Pipeline Based on Circuit-Level Timing Speculation</Title>
			<URL>https://web.eecs.umich.edu/~taustin/papers/MICRO36-Razor.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1063">
			<Author>James Tschanz</Author>
			<Author>Keith Bowman</Author>
			<Author>Steve Walstra</Author>
			<Author>Marty Agostinelli</Author>
			<Author>Tanay Karnik</Author>
			<Author>Vivek De</Author>
			<Title>Tunable Replica Circuits and Adaptive Voltage-Frequency Techniques for Dynamic Voltage, Temperature, and Aging Variation Tolerance</Title>
			<URL>https://ieeexplore.ieee.org/document/5205410</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1064">
			<Author>Bilgiday Yuce</Author>
			<Author>Nahid F. Ghalaty</Author>
			<Author>Chinmay Deshpande</Author>
			<Author>Conor Patrick</Author>
			<Author>Leyla Nazhandali</Author>
			<Author>Patrick Schaumont</Author>
			<Title>FAME: Fault-attack Aware Microprocessor Extensions for Hardware Fault Detection and Software Fault Response</Title>
			<URL>https://dl.acm.org/doi/10.1145/2948618.2948626</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1065">
			<Author>Keith A. Bowman</Author>
			<Author>James W. Tschanz</Author>
			<Author>Shih-Lien L. Lu</Author>
			<Author>Paolo A. Aseron</Author>
			<Author>Muhammad M. Khellah</Author>
			<Author>Arijit Raychowdhury</Author>
			<Author>Bibiche M. Geuskens</Author>
			<Author>Carlos Tokunaga</Author>
			<Author>Chris B. Wilkerson</Author>
			<Author>Tanay Karnik</Author>
			<Author>Vivek De</Author>
			<Title>A 45 nm Resilient Microprocessor Core for Dynamic Variation Tolerance</Title>
			<URL>https://ieeexplore.ieee.org/document/5654663</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1066">
			<Author>Niek Timmers</Author>
			<Author>Albert Spruyt</Author>
			<Title>Bypassing Secure Boot Using Fault Injection</Title>
			<URL>https://www.blackhat.com/docs/eu-16/materials/eu-16-Timmers-Bypassing-Secure-Boot-Using-Fault-Injection.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1067">
			<Author>Brian Bailey</Author>
			<Title>Why Chips Die</Title>
			<URL>https://semiengineering.com/why-chips-die/</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1068">
			<Author>V. Lakshminarayan</Author>
			<Title>What causes semiconductor devices to fail</Title>
			<URL>https://www.edn.com/what-causes-semiconductor-devices-to-fail/</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1071">
			<Author>Ali Abbasi</Author>
			<Author>Tobias Scharnowski</Author>
			<Author>Thorsten Holz</Author>
			<Title>Doors of Durin: The Veiled Gate to Siemens S7 Silicon</Title>
			<URL>https://i.blackhat.com/eu-19/Wednesday/eu-19-Abbasi-Doors-Of-Durin-The-Veiled-Gate-To-Siemens-S7-Silicon.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1072">
			<Author>Sergei Skorobogatov</Author>
			<Author>Christopher Woods</Author>
			<Title>Breakthrough Silicon Scanning Discovers Backdoor in Military Chip</Title>
			<URL>https://www.cl.cam.ac.uk/~sps32/Silicon_scan_draft.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1073">
			<Author>Chris Domas</Author>
			<Title>God Mode Unlocked: Hardware Backdoors in x86 CPUs</Title>
			<URL>https://i.blackhat.com/us-18/Thu-August-9/us-18-Domas-God-Mode-Unlocked-Hardware-Backdoors-In-x86-CPUs.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1074">
			<Author>Jonathan Brossard</Author>
			<Title>Hardware Backdooring is Practical</Title>
			<URL>https://media.blackhat.com/bh-us-12/Briefings/Brossard/BH_US_12_Brossard_Backdoor_Hacking_Slides.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1075">
			<Author>Sergei Skorabogatov</Author>
			<Title>Security, Reliability, and Backdoors</Title>
			<URL>https://www.cl.cam.ac.uk/~sps32/SG_talk_SRB.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1076">
			<Author>ARM</Author>
			<Title>Cortex-R4 Manual</Title>
			<URL>https://developer.arm.com/ip-products/processors/cortex-m/cortex-m4</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1077">
			<Author>Intel</Author>
			<Title>MCS 51 Microcontroller Family User's Manual</Title>
			<URL>http://web.mit.edu/6.115/www/document/8051.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1078">
			<Author>ARM</Author>
			<Title>Memory Protection Unit (MPU)</Title>
			<URL>https://static.docs.arm.com/100699/0100/armv8m_architecture_memory_protection_unit_100699_0100_00_en.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1079">
			<Author>Joe Fitzpatrick</Author>
			<Title>SCA4n00bz - Timing-based Sidechannel Attacks for Hardware N00bz workshop</Title>
			<URL>https://github.com/securelyfitz/SCA4n00bz</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1080">
			<Author>Christopher Tarnovsky</Author>
			<Title>Security Failures in Secure Devices</Title>
			<URL>https://www.blackhat.com/presentations/bh-europe-08/Tarnovsky/Presentation/bh-eu-08-tarnovsky.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1081">
			<Author>Kit Murdock</Author>
			<Author>David Oswald</Author>
			<Author>Flavio D Garcia</Author>
			<Author>Jo Van Bulck</Author>
			<Author>Frank Piessens</Author>
			<Author>Daniel Gruss</Author>
			<Title>Plundervolt</Title>
			<URL>https://plundervolt.com/</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1082">
			<Author>Adrian Tang</Author>
			<Author>Simha Sethumadhavan</Author>
			<Author>Salvatore Stolfo</Author>
			<Title>CLKSCREW: Exposing the Perils of Security-Oblivious Energy Management</Title>
			<URL>https://www.usenix.org/system/files/conference/usenixsecurity17/sec17-tang.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1083">
			<Author>Yoongu Kim</Author>
			<Author>Ross Daly</Author>
			<Author>Jeremie Kim</Author>
			<Author>Ji Hye Lee</Author>
			<Author>Donghyuk Lee</Author>
			<Author>Chris Wilkerson</Author>
			<Author>Konrad Lai</Author>
			<Author>Onur Mutlu</Author>
			<Title>Flipping Bits in Memory Without Accessing Them: An Experimental Study of DRAM Disturbance Errors</Title>
			<URL>https://users.ece.cmu.edu/~yoonguk/papers/kim-isca14.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1084">
			<Author>Gopal Vishwakarma</Author>
			<Author>Wonjun Lee</Author>
			<Title>JTAG Explained (finally!): Why “IoT”, Software Security Engineers, and Manufacturers Should Care</Title>
			<URL>https://www.mdpi.com/1999-5903/10/12/121/pdf </URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1085">
			<Author>Bob Molyneaux</Author>
			<Author>Mark McDermott</Author>
			<Author>Anil Sabbavarapu</Author>
			<Title>Design for Testability &amp; Design for Debug</Title>
			<URL>http://users.ece.utexas.edu/~mcdermot/vlsi-2/Lecture_17.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1086">
			<Author>Fan Wang</Author>
			<Author>Vishwani D. Agrawal</Author>
			<Title>Single Event Upset: An Embedded Tutorial</Title>
			<URL>https://www.eng.auburn.edu/~agrawvd/TALKS/tutorial_6pg.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1087">
			<Author>P. D. Bradley</Author>
			<Author>E. Normand</Author>
			<Title>Single Event Upsets in Implantable Cardioverter Defibrillators</Title>
			<URL>https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=736549</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1088">
			<Author>Melanie Berg</Author>
			<Author>Kenneth LaBel</Author>
			<Author>Jonathan Pellish</Author>
			<Title>Single Event Effects in FPGA Devices 2015-2016</Title>
			<URL>https://ntrs.nasa.gov/search.jsp?R=20160007754</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1089">
			<Author>Cisco</Author>
			<Title>Cisco 12000 Single Event Upset Failures Overview and Work Around Summary</Title>
			<URL>https://www.cisco.com/c/en/us/support/docs/field-notices/200/fn25994.html</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1090">
			<Author>Cypress</Author>
			<Title>Different Ways to Mitigate Soft Errors in Asynchronous SRAMs - KBA90939</Title>
			<URL>https://community.cypress.com/docs/DOC-10826</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1091">
			<Author>Ian Johnston</Author>
			<Title>Cosmic particles can change elections and cause plans to fall through the sky, scientists warn</Title>
			<URL>https://www.independent.co.uk/news/science/subatomic-particles-cosmic-rays-computers-change-elections-planes-autopilot-a7584616.html</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1092">
			<Author>Shahed E. Quadir</Author>
			<Author>Junlin Chen</Author>
			<Author>Domenic Forte</Author>
			<Author>Navid Asadizanjani</Author>
			<Author>Sina Shahbazmohamadi</Author>
			<Author>Lei Wang</Author>
			<Author>John Chandy</Author>
			<Author>Mark Tehranipoor</Author>
			<Title>A Survey on Chip to System Reverse Engineering</Title>
			<URL>https://dl.acm.org/doi/pdf/10.1145/2755563</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1093">
			<Author>Brandon Hill</Author>
			<Title>Huge Intel CPU Bug Allegedly Causes Kernel Memory Vulnerability With Up To 30% Performance Hit In Windows And Linux</Title>
			<Publication_Year>2018</Publication_Year>
			<Publication_Month>--01</Publication_Month>
			<Publication_Day>---02</Publication_Day>
			<URL>https://hothardware.com/news/intel-cpu-bug-kernel-memory-isolation-linux-windows-macos</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1094">
			<Author>Christopher Domas</Author>
			<Title>Breaking the x86 ISA</Title>
			<URL>https://github.com/xoreaxeaxeax/sandsifter/blob/master/references/domas_breaking_the_x86_isa_wp.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1095">
			<Author>Matthew Hughes</Author>
			<Title>Bad news: KeyWe Smart Lock is easily bypassed and can't be fixed</Title>
			<Publication_Year>2019</Publication_Year>
			<Publication_Month>--12</Publication_Month>
			<Publication_Day>---11</Publication_Day>
			<URL>https://www.theregister.com/2019/12/11/f_secure_keywe/</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1096">
			<Author>Alex Scroxton</Author>
			<Title>Alarm bells ring, the IoT is listening</Title>
			<URL>https://www.computerweekly.com/news/252475324/Alarm-bells-ring-the-IoT-is-listening</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1097">
			<Author>Brian Krebs</Author>
			<Title>Zyxel Flaw Powers New Mirai IoT Botnet Strain</Title>
			<Publication_Year>2020</Publication_Year>
			<Publication_Month>--03</Publication_Month>
			<Publication_Day>---20</Publication_Day>
			<URL>https://krebsonsecurity.com/2020/03/zxyel-flaw-powers-new-mirai-iot-botnet-strain/</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1100">
			<Author>Christopher Domas</Author>
			<Title>The Memory Sinkhole</Title>
			<Publication_Year>2015</Publication_Year>
			<Publication_Month>--07</Publication_Month>
			<Publication_Day>---20</Publication_Day>
			<URL>https://github.com/xoreaxeaxeax/sinkhole/blob/master/us-15-Domas-TheMemorySinkhole-wp.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1101">
			<Author>Anders B. Wilhelmsen</Author>
			<Author>Eivind S. Kristiansen</Author>
			<Author>Marie Moe</Author>
			<Title>The Hard-coded Key to my Heart - Hacking a Pacemaker Programmer</Title>
			<Publication_Year>2019</Publication_Year>
			<Publication_Month>--08</Publication_Month>
			<Publication_Day>---10</Publication_Day>
			<URL>https://anderbw.github.io/2019-08-10-DC27-Biohacking-pacemaker-programmer.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1103">
			<Author>Lucian Armasu</Author>
			<Title>Intel ME's Undocumented Manufacturing Mode Suggests CPU Hacking Risks</Title>
			<Publication_Year>2018</Publication_Year>
			<Publication_Month>--10</Publication_Month>
			<Publication_Day>---03</Publication_Day>
			<URL>https://www.tomshardware.com/news/intel-me-cpu-undocumented-manufacturing-mode,37883.html</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1107">
			<Author>Intel Corporation</Author>
			<Title>PCIe Device Measurement Requirements</Title>
			<Publication_Year>2018</Publication_Year>
			<Publication_Month>--09</Publication_Month>
			<URL>https://www.intel.com/content/dam/www/public/us/en/documents/reference-guides/pcie-device-security-enhancements.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1108">
			<Author>Intel Corporation</Author>
			<Title>Deep Dive: Retpoline: A Branch Target Injection Mitigation</Title>
			<URL>https://software.intel.com/security-software-guidance/insights/deep-dive-retpoline-branch-target-injection-mitigation</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1112">
			<Title>Android Security Bulletin—December 2018</Title>
			<URL>https://source.android.com/security/bulletin/2018-12-01.html</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1113">
			<Author>Muhammad Yasin</Author>
			<Author>Abhrajit  Sengupta</Author>
			<Author>Mohammed Thari Nabeel</Author>
			<Author>Mohammed  Ashraf</Author>
			<Author>Jeyavijayan (JV) Rajendran</Author>
			<Author>Ozgur  Sinanoglu</Author>
			<Title>Provably-Secure Logic Locking: From Theory To Practice</Title>
			<URL>https://dl.acm.org/doi/10.1145/3133956.3133985</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1114">
			<Author>Muhammad Yasin</Author>
			<Author>Jeyavijayan (JV) Rajendran</Author>
			<Author>Ozgur  Sinanoglu</Author>
			<Title>Trustworthy Hardware Design: Combinational Logic Locking Techniques</Title>
			<URL>https://link.springer.com/book/10.1007/978-3-030-15334-2</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1115">
			<Author>Meher Krishna Patel</Author>
			<Title>FPGA designs with Verilog (section 7.4 Glitches)</Title>
			<URL>https://verilogguide.readthedocs.io/en/latest/verilog/fsm.html</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1116">
			<Author>Clifford E. Cummings</Author>
			<Title>Non-Blocking Assignments in Verilog Synthesis, Coding Styles that Kill!</Title>
			<Publication_Year>2000</Publication_Year>
			<URL>http://www.sunburst-design.com/papers/CummingsSNUG2000SJ_NBA.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1117">
			<Author>Paul Kocher</Author>
			<Author>Joshua Jaffe</Author>
			<Author>Benjamin Jun</Author>
			<Title>Introduction to differential power analysis and related attacks</Title>
			<Publication_Year>1998</Publication_Year>
			<URL>https://www.rambus.com/wp-content/uploads/2015/08/DPATechInfo.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1118">
			<Author>Dakshi Agrawal</Author>
			<Author>Bruce Archambeault</Author>
			<Author>Josyula R. Rao</Author>
			<Author>Pankaj Rohatgi</Author>
			<Title>The EM Side-Channel(s)</Title>
			<Publication_Year>2007</Publication_Year>
			<Publication_Month>--08</Publication_Month>
			<Publication_Day>---24</Publication_Day>
			<URL>https://link.springer.com/content/pdf/10.1007%2F3-540-36400-5_4.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1119">
			<Author>Daniel Genkin</Author>
			<Author>Adi Shamir</Author>
			<Author>Eran Tromer</Author>
			<Title>RSA key extraction via low-bandwidth acoustic cryptanalysis</Title>
			<Publication_Year>2014</Publication_Year>
			<Publication_Month>--06</Publication_Month>
			<Publication_Day>---13</Publication_Day>
			<URL>https://www.iacr.org/archive/crypto2014/86160149/86160149.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1120">
			<Author>Colin O’Flynn</Author>
			<Title>Power Analysis for Cheapskates</Title>
			<Publication_Year>2013</Publication_Year>
			<Publication_Month>--01</Publication_Month>
			<Publication_Day>---24</Publication_Day>
			<URL>https://media.blackhat.com/eu-13/briefings/OFlynn/bh-eu-13-for-cheapstakes-oflynn-wp.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1121">
			<Author>Moritz Lipp</Author>
			<Author>Michael Schwarz</Author>
			<Author>Daniel Gruss</Author>
			<Author>Thomas Prescher</Author>
			<Author>Werner Haas</Author>
			<Author>Anders Fogh</Author>
			<Author>Jann Horn</Author>
			<Author>Stegfan Mangard</Author>
			<Author>Paul Kocher</Author>
			<Author>Daniel Genkin</Author>
			<Author>Yuval Yarom</Author>
			<Author>Mike Hamberg</Author>
			<Title>Meltdown: Reading Kernel Memory from User Space</Title>
			<Publication_Year>2018</Publication_Year>
			<Publication_Month>--01</Publication_Month>
			<Publication_Day>---03</Publication_Day>
			<URL>https://meltdownattack.com/meltdown.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1122">
			<Author>Moritz Lipp</Author>
			<Author>Michael Schwarz</Author>
			<Author>Daniel Gruss</Author>
			<Author>Thomas Prescher</Author>
			<Author>Werner Haas</Author>
			<Author>Anders Fogh</Author>
			<Author>Jann Horn</Author>
			<Author>Stegfan Mangard</Author>
			<Author>Paul Kocher</Author>
			<Author>Daniel Genkin</Author>
			<Author>Yuval Yarom</Author>
			<Author>Mike Hamberg</Author>
			<Title>Spectre Attacks: Exploiting Speculative Execution</Title>
			<Publication_Year>2018</Publication_Year>
			<Publication_Month>--01</Publication_Month>
			<Publication_Day>---03</Publication_Day>
			<URL>https://spectreattack.com/spectre.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1123">
			<Author>Dmitry Evtyushkin</Author>
			<Author>Dmitry Ponomarev</Author>
			<Author>Nael Abu-Ghazaleh</Author>
			<Title>Jump Over ASLR: Attacking Branch Predictors to Bypass ASLR</Title>
			<Publication_Year>2016</Publication_Year>
			<Publication_Month>--10</Publication_Month>
			<Publication_Day>---19</Publication_Day>
			<URL>https://ieeexplore.ieee.org/abstract/document/7783743/</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1124">
			<Author>Qian Ge</Author>
			<Author>Yuval Yarom</Author>
			<Author>David Cock</Author>
			<Author>Gernot Heiser</Author>
			<Title>A Survey of Microarchitectural Timing Attacks and Countermeasures on Contemporary Hardware</Title>
			<Publication_Year>2016</Publication_Year>
			<Publication_Month>--10</Publication_Month>
			<Publication_Day>---24</Publication_Day>
			<URL>https://eprint.iacr.org/2016/613.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1125">
			<Author>moparisthebest</Author>
			<Title>Validation Vulnerabilities</Title>
			<Publication_Year>2015</Publication_Year>
			<Publication_Month>--06</Publication_Month>
			<Publication_Day>---05</Publication_Day>
			<URL>https://mailarchive.ietf.org/arch/msg/acme/s6Q5PdJP48LEUwgzrVuw_XPKCsM/</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1129">
			<Author>Christopher Tarnovsky</Author>
			<Title>Security Failures In Secure Devices</Title>
			<Publication_Year>2008</Publication_Year>
			<Publication_Month>--02</Publication_Month>
			<Publication_Day>---21</Publication_Day>
			<URL>https://www.blackhat.com/presentations/bh-dc-08/Tarnovsky/Presentation/bh-dc-08-tarnovsky.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1130">
			<Author>Mark Ermolov, Positive Technologies</Author>
			<Title>Intel x86 Root of Trust: loss of trust</Title>
			<Publication_Year>2020</Publication_Year>
			<Publication_Month>--03</Publication_Month>
			<Publication_Day>---05</Publication_Day>
			<URL>https://blog.ptsecurity.com/2020/03/intelx86-root-of-trust-loss-of-trust.html</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1131">
			<Author>John Butterworth</Author>
			<Author>Cory Kallenberg</Author>
			<Author>Xeno Kovah</Author>
			<Title>BIOS Chronomancy: Fixing the Core Root of Trust for Measurement</Title>
			<Publication_Year>2013</Publication_Year>
			<Publication_Month>--07</Publication_Month>
			<Publication_Day>---31</Publication_Day>
			<URL>https://media.blackhat.com/us-13/US-13-Butterworth-BIOS-Security-Slides.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1134">
			<Author>Taku Izumi, Fujitsu Limited</Author>
			<Title>Address Range Memory Mirroring</Title>
			<Publication_Year>2016</Publication_Year>
			<URL>https://www.fujitsu.com/jp/documents/products/software/os/linux/catalog/LinuxConJapan2016-Izumi.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1135">
			<Author>Benoit Morgan, Eric Alata, Vincent Nicomette, Mohamed Kaaniche</Author>
			<Title>Bypassing IOMMU Protection against I/O Attacks</Title>
			<Publication_Year>2016</Publication_Year>
			<URL>https://hal.archives-ouvertes.fr/hal-01419962/document</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1136">
			<Author>Colin L. Rothwell</Author>
			<Title>Exploitation from malicious PCI Express peripherals</Title>
			<Publication_Year>2019</Publication_Year>
			<URL>https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-934.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1137">
			<Author>Yuriy Bulygin, Oleksandr Bazhaniuk, Andrew Furtak, John Loucaides, Mikhail Gorobets</Author>
			<Title>BARing the System – New vulnerabilities in Coreboot &amp; UEFI-based Systems</Title>
			<Publication_Year>2017</Publication_Year>
			<URL>https://www.c7zero.info/stuff/REConBrussels2017_BARing_the_system.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1138">
			<Author>Stewart Smith</Author>
			<Title>CVE-2019-6260: Gaining control of BMC from the host processor</Title>
			<Publication_Year>2019</Publication_Year>
			<URL>https://www.flamingspork.com/blog/2019/01/23/cve-2019-6260:-gaining-control-of-bmc-from-the-host-processor/</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1139">
			<Author>ARM</Author>
			<Title>AMBA APB Protocol Specification, Version 2.0</Title>
			<Publication_Year>2010</Publication_Year>
			<URL>https://www.eecs.umich.edu/courses/eecs373/readings/IHI0024C_amba_apb_protocol_spec.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1140">
			<Author>OCP-IP</Author>
			<Title>Open Core Protocol Specification, Release 2.2</Title>
			<Publication_Year>2006</Publication_Year>
			<URL>http://read.pudn.com/downloads95/doc/388103/OCPSpecification%202.2.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1141">
			<Author>Marc Witteman</Author>
			<Title>Secure Application Programming in the presence of Side Channel Attacks</Title>
			<Publication_Year>2017</Publication_Year>
			<URL>https://www.riscure.com/uploads/2018/11/201708_Riscure_Whitepaper_Side_Channel_Patterns.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1142">
			<Author>A. Dehbaoui, J. M. Dutertre, B. Robisson, P. Orsatelli, P. Maurine, A. Tria</Author>
			<Title>Injection of transient faults using electromagnetic pulses. Practical results on a cryptographic system</Title>
			<Publication_Year>2012</Publication_Year>
			<URL>https://eprint.iacr.org/2012/123.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1143">
			<Author>A. Menu, S. Bhasin, J. M. Dutertre, J. B. Rigaud, J. Danger</Author>
			<Title>Precise Spatio-Temporal Electromagnetic Fault Injections on Data Transfers</Title>
			<Publication_Year>2019</Publication_Year>
			<URL>https://hal.telecom-paris.fr/hal-02338456/document</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1144">
			<Author>Colin O'Flynn</Author>
			<Title>BAM BAM!! On Reliability of EMFI for in-situ Automotive ECU Attacks</Title>
			<URL>https://eprint.iacr.org/2020/937.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1145">
			<Author>J. Balasch, D. Arumí, S. Manich</Author>
			<Title>Design and Validation of a Platform for Electromagnetic Fault Injection</Title>
			<URL>https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8311630</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1146">
			<Author>M. Gay, B. Karp, O. Keren, I. Polian</Author>
			<Title>Error control scheme for malicious and natural faults in cryptographic modules</Title>
			<Publication_Year>2019</Publication_Year>
			<URL>https://link.springer.com/content/pdf/10.1007/s13389-020-00234-7.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1147">
			<Author>M. L. Akkar, L. Goubin, O. Ly</Author>
			<Title>Automatic Integration of Counter-Measures Against Fault Injection Attacks</Title>
			<URL>https://www.labri.fr/perso/ly/publications/cfed.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1150">
			<Author>Jerry Backer</Author>
			<Author>David Hely</Author>
			<Author>Ramesh Karri</Author>
			<Title>Secure design-for-debug for Systems-on-Chip</Title>
			<Publication_Year>2015</Publication_Year>
			<Publication_Month>--10</Publication_Month>
			<Publication_Day>---06</Publication_Day>
			<URL>https://ieeexplore.ieee.org/document/7342418</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1151">
			<Author>Jerry Backer</Author>
			<Author>David Hely</Author>
			<Author>Ramesh Karri</Author>
			<Title>Secure and Flexible Trace-Based Debugging of Systems-on-Chip</Title>
			<Publication_Year>2016</Publication_Year>
			<Publication_Month>--12</Publication_Month>
			<URL>https://dl.acm.org/doi/pdf/10.1145/2994601</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1152">
			<Author>Trusted Computing Group</Author>
			<Title>TCG Roots of Trust Specification</Title>
			<Publication_Year>2018</Publication_Year>
			<Publication_Month>--07</Publication_Month>
			<URL>https://trustedcomputinggroup.org/wp-content/uploads/TCG_Roots_of_Trust_Specification_v0p20_PUBLIC_REVIEW.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1153">
			<Author>GlobalPlatform Security Task Force</Author>
			<Title>Root of Trust Definitions and Requirements</Title>
			<Publication_Year>2017</Publication_Year>
			<Publication_Month>--03</Publication_Month>
			<URL>https://globalplatform.org/wp-content/uploads/2018/06/GP_RoT_Definitions_and_Requirements_v1.0.1_PublicRelease_CC.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1154">
			<Author>National Institute of Standards and Technology</Author>
			<Title>NIST Special Publication 800-88 Revision 1: Guidelines for Media Sanitization</Title>
			<Publication_Year>2014</Publication_Year>
			<Publication_Month>--12</Publication_Month>
			<URL>https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-88r1.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1155">
			<Author>Hassan M. G. Wassel, Ying Gao, Jason K. Oberg, Tedd Huffmire, Ryan Kastner, Frederic T. Chong, Timothy Sherwood</Author>
			<Title>SurfNoC: A Low Latency and Provably Non-Interfering Approach to Secure Networks-On-Chip</Title>
			<Publication_Year>2013</Publication_Year>
			<URL>http://cseweb.ucsd.edu/~kastner/papers/isca13-surfNOC.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1156">
			<Author>Leonid Grustniy</Author>
			<Title>Loapi--This Trojan is hot!</Title>
			<Publication_Year>2017</Publication_Year>
			<Publication_Month>--12</Publication_Month>
			<URL>https://www.kaspersky.com/blog/loapi-trojan/20510/ </URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1160">
			<Author>Niek Timmers</Author>
			<Author>Albert Spruyt</Author>
			<Author>Marc Witteman</Author>
			<Title>Controlling PC on ARM Using Fault Injection</Title>
			<Publication>2016 Workshop on Fault Diagnosis and Tolerance in Cryptography (FDTC)</Publication>
			<Publication_Year>2016</Publication_Year>
			<Publication_Month>--08</Publication_Month>
			<Publication_Day>---16</Publication_Day>
			<URL>https://dl.acm.org/doi/10.1109/ICSE.2019.00033</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1161">
		  <Author>Josep Balasch</Author>
		  <Author>Benedikt Gierlichs</Author>
		  <Author>Ingrid Verbauwhede</Author>
			<Title>An In-depth and Black-box Characterization of the Effects of Clock Glitches on 8-bit MCUs</Title>
			<Publication>2011 Workshop on Fault Diagnosis and Tolerance in Cryptography (IEEE)</Publication>
			<Publication_Year>2011</Publication_Year>
			<Publication_Month>--09</Publication_Month>
            <URL>https://ieeexplore.ieee.org/document/6076473</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1181">
			<Author>Nikolaos Athanasios Anagnostopoulos </Author>
			<Author>Tolga Arul </Author>
			<Author>Markus Rosenstihl </Author>
			<Author>André Schaller </Author>
			<Author>Sebastian Gabmeyer </Author>
			<Author>Stefan Katzenbeisser </Author>
			<Title>Low-Temperature Data Remnanence ATtacks Against Intrinsic SRAM PUFs</Title>
			<Publication_Year>2018</Publication_Year>
			<Publication_Month>--10</Publication_Month>
			<Publication_Day>---15</Publication_Day>
			<URL>https://ieeexplore.ieee.org/abstract/document/8491873/</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1182">
			<Author>Yuan Cao </Author>
			<Author>Yunyi Guo </Author>
			<Author>Benyu Liu </Author>
			<Author>Wei Ge </Author>
			<Author>Min Zhu </Author>
			<Author>Chip-Hong Chang </Author>
			<Title>A Fully Digital Physical Unclonable Function Based Temperature Sensor for Secure Remote Sensing</Title>
			<Publication_Year>2018</Publication_Year>
			<Publication_Month>--10</Publication_Month>
			<Publication_Day>---11</Publication_Day>
			<URL>https://ieeexplore.ieee.org/abstract/document/8487347/</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1183">
			<Author> Urbi Chatterjee </Author>
			<Author> Soumi Chatterjee </Author>
			<Author> Debdeep Mukhopadhyay </Author>
			<Author> Rajat Subhra Chakraborty </Author>
			<Title>Machine Learning Assisted PUF Calibration for Trustworthy Proof of Sensor Data in IoT</Title>
			<Publication_Year>2020</Publication_Year>
			<Publication_Month>--06</Publication_Month>
			<URL>https://dl.acm.org/doi/abs/10.1145/3393628</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1184">
			<Author>Wikipedia</Author>
			<Title>Power Analysis</Title>
			<URL>https://en.wikipedia.org/wiki/Power_analysis</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1192">
			<Author>Information Technology Laboratory, National Institute of Standards and Technology</Author>
			<Title>FIPS PUB 140-3: SECURITY REQUIREMENTS FOR CRYPTOGRAPHIC MODULES</Title>
			<Publication_Year>2019</Publication_Year>
			<Publication_Month>--03</Publication_Month>
			<Publication_Day>---22</Publication_Day>
			<URL>https://csrc.nist.gov/publications/detail/fips/140/3/final</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1202">
			<Author>Jo Van Bulck, Daniel Moghimi, Michael Schwarz, Moritz Lipp, Marina Minkin, Daniel Genkin, Yuval Yarom, Berk Sunar, Daniel Gruss, and Frank Piessens</Author>
			<Title>LVI - Hijacking Transient Execution with Load Value Injection</Title>
			<Publication_Year>2020</Publication_Year>
			<URL>https://lviattack.eu/</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1203">
			<Author>Jo Van Bulck, Daniel Moghimi, Michael Schwarz, Moritz Lipp, Marina Minkin, Daniel Genkin, Yuval Yarom, Berk Sunar, Daniel Gruss, and Frank Piessens</Author>
			<Title>LVI: Hijacking Transient Execution through Microarchitectural Load Value Injection</Title>
			<Publication_Year>2020</Publication_Year>
			<Publication_Month>--01</Publication_Month>
			<Publication_Day>---09</Publication_Day>
			<URL>https://lviattack.eu/lvi.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1204">
			<Title>Hijacking Transient Execution through Microarchitectural Load Value Injection</Title>
			<Publication_Year>2020</Publication_Year>
			<Publication_Month>--05</Publication_Month>
			<Publication_Day>---18</Publication_Day>
			<URL>https://www.youtube.com/watch?v=99kVz-YGi6Y</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1205">
			<Author>Stephan van Schaik, Marina Minkin, Andrew Kwong, Daniel Genkin, Yuval Yarom</Author>
			<Title>CacheOut: Leaking Data on Intel CPUs via Cache Evictions</Title>
			<Publication_Year>2020</Publication_Year>
			<Publication_Month>--12</Publication_Month>
			<Publication_Day>---28</Publication_Day>
			<URL>https://cacheoutattack.com/files/CacheOut.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1217">
		  <Author>Ross Anderson</Author>
		  <Title>Security Engineering</Title>
			<Publication_Year>2001</Publication_Year>
			<URL>https://www.cl.cam.ac.uk/~rja14/musicfiles/manuscripts/SEv1.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1218">
		  <Author>Graham Cluley</Author>
		  <Title>This Black Box Can Brute Force Crack iPhone PIN Passcodes</Title>
			<Publication>The Mac Security Blog</Publication>
			<Publication_Year>2015</Publication_Year>
			<Publication_Month>--03</Publication_Month>
			<Publication_Day>---16</Publication_Day>
			<URL>https://www.intego.com/mac-security-blog/iphone-pin-pass-code/</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1219">
			<Author>Monodeep Kar</Author>
			<Author>Arvind Singh</Author>
			<Author>Santosh Ghosh</Author>
			<Author>Sanu Mathew</Author>
			<Author>Anand Rajan</Author>
			<Author>Vivek De</Author>
			<Author>Raheem Beyah</Author>
			<Author>Saibal Mukhopadhyay</Author>
			<Title>Blindsight: Blinding EM Side-Channel Leakage using Built-In Fully Integrated Inductive Voltage Regulator</Title>
			<Publication_Year>2018</Publication_Year>
			<Publication_Month>--02</Publication_Month>
			<URL>https://www.researchgate.net/publication/323411019_Blindsight_Blinding_EM_Side-Channel_Leakage_using_Built-In_Fully_Integrated_Inductive_Voltage_Regulator</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1220">
		  <Author>Zhenyu Ning</Author>
		  <Author>Fengwei Zhang</Author>
		  <Title>Understanding the Security of ARM Debugging Features</Title>
		  <Publication>2019 IEEE Symposium on Security and Privacy (SP)</Publication>
		  <Publication_Year>2019</Publication_Year>
		  <Publication_Month>--05</Publication_Month>
		  <Publication_Day>---22</Publication_Day>
		  <URL>https://www.computer.org/csdl/proceedings-article/sp/2019/666000b156/19skgcwSgsE</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1221">
		  <Author>Victor Lomne</Author>
		  <Author>Thomas Roche</Author>
		  <Title>A Side Journey to Titan</Title>
		  <Publication_Year>2021</Publication_Year>
		  <Publication_Month>--01</Publication_Month>
		  <Publication_Day>---07</Publication_Day>
		  <URL>https://ninjalab.io/wp-content/uploads/2021/01/a_side_journey_to_titan.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1222">
		  <Author>Alexandre Menu</Author>
		  <Author>Jean-Max Dutertre</Author>
		  <Author>Olivier Potin</Author>
		  <Author>Jean-Baptiste Rigaud</Author>
		  <Title>Experimental Analysis of the Electromagnetic Instruction Skip Fault Model</Title>
		  <Publication>IEEE Xplore</Publication>
		  <Publication_Year>2020</Publication_Year>
		  <Publication_Month>--04</Publication_Month>
		  <Publication_Day>---30</Publication_Day>
		  <URL>https://ieeexplore.ieee.org/document/9081261</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1223">
		  <Author>Niek Timmers</Author>
		  <Author>Albert Spruyt</Author>
		  <Author>Marc Witteman</Author>
		  <Title>Controlling PC on ARM using Fault Injection</Title>
		  <Publication_Year>2016</Publication_Year>
		  <Publication_Month>--06</Publication_Month>
		  <Publication_Day>---11</Publication_Day>
		  <URL>https://www.riscure.com/uploads/2017/09/Controlling-PC-on-ARM-using-Fault-Injection.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1224">
		  <Author>Colin O'Flynn</Author>
		  <Title>Attacking USB Gear with EMFI</Title>
		  <Publication>Circuit Cellar</Publication>
		  <Publication_Year>2019</Publication_Year>
		  <Publication_Month>--05</Publication_Month>
		  <URL>https://www.totalphase.com/media/pdf/whitepapers/Circuit_Cellar_TP.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1225">
			<Author>Project Zero</Author>
			<Title>Exploiting the DRAM rowhammer bug to gain kernel privileges</Title>
			<Publication_Year>2015</Publication_Year>
			<Publication_Month>--03</Publication_Month>
			<Publication_Day>---09</Publication_Day>
			<URL>https://googleprojectzero.blogspot.com/2015/03/exploiting-dram-rowhammer-bug-to-gain.html</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1226">
			<Author>Information Technology Laboratory, National Institute of Standards and Technology</Author>
			<Title>FIPS PUB 140-2: SECURITY REQUIREMENTS FOR CRYPTOGRAPHIC MODULES</Title>
			<Publication_Year>2001</Publication_Year>
			<Publication_Month>--05</Publication_Month>
			<Publication_Day>---25</Publication_Day>
			<URL>https://csrc.nist.gov/publications/detail/fips/140/2/final</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1227">
		  <Author>Wikipedia</Author>
		  <Title>Cryptographic primitive</Title>
		  <URL>https://en.wikipedia.org/wiki/Cryptographic_primitive</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1228">
		  <Author>Gilbert Goodwill</Author>
		  <Author>Benjamin Jun</Author>
		  <Author>Josh Jaffe</Author>
		  <Author>Pankaj Rohatgi</Author>
		  <Title>A testing methodology for side-channel resistance validation</Title>
		  <Publication_Year>2011</Publication_Year>
		  <URL>https://csrc.nist.gov/csrc/media/events/non-invasive-attack-testing-workshop/documents/08_goodwill.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1229">
		  <Author>ISO/IEC</Author>
		  <Title>ISO/IEC 17825:2016: Testing methods for the mitigation of non-invasive attack classes against cryptographic modules</Title>
		  <Publication_Year>2016</Publication_Year>
		  <URL>https://www.iso.org/standard/60612.html</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1230">
		  <Author>Cryptography Research Inc.</Author>
		  <Title>Test Vector Leakage Assessment (TVLA) Derived Test Requirements (DTR) with AES</Title>
		  <Publication_Year>2015</Publication_Year>
		  <Publication_Month>--08</Publication_Month>
		  <URL>https://www.rambus.com/wp-content/uploads/2015/08/TVLA-DTR-with-AES.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1231">
		  <Author>Danilo Šijaˇci´c</Author>
		  <Author>Josep Balasch</Author>
		  <Author>Bohan Yang</Author>
		  <Author>Santosh Ghosh</Author>
		  <Author>Ingrid Verbauwhede</Author>
		  <Title>Towards efficient and automated side-channel evaluations at design time</Title>
		  <Publication>Journal of Cryptographic Engineering, 10(4)</Publication>
		  <Publication_Year>2020</Publication_Year>
		  <URL>https://www.esat.kuleuven.be/cosic/publications/article-3204.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1232">
		  <Author>Amit Kumar</Author>
		  <Author>Cody Scarborough</Author>
		  <Author>Ali Yilmaz</Author>
		  <Author>Michael Orshansky</Author>
		  <Title>Efficient simulation of EM side-channel attack resilience</Title>
		  <Publication>IEEE/ACM International Conference on Computer-Aided Design (ICCAD)</Publication>
		  <Publication_Year>2017</Publication_Year>
		  <URL>https://dl.acm.org/doi/pdf/10.5555/3199700.3199717</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1233">
		  <Author>Yuan Yao</Author>
		  <Author>Tuna Tufan</Author>
		  <Author>Tarun Kathuria</Author>
		  <Author>Baris Ege</Author>
		  <Author>Ulkuhan Guler</Author>
		  <Author>Patrick Schaumont</Author>
		  <Title>Pre-silicon Architecture Correlation Analysis (PACA): Identifying and Mitigating the Source of Side-channel Leakage at Gate-level</Title>
		  <Publication_Year>2021</Publication_Year>
		  <Publication_Month>--04</Publication_Month>
		  <Publication_Day>---21</Publication_Day>
		  <Publisher>IACR Cryptology ePrint Archive</Publisher>
		  <URL>https://eprint.iacr.org/2021/530.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1234">
		  <Author>Elisabeth Oswald</Author>
		  <Author>Thomas Popp</Author>
		  <Author>Stefan Mangard</Author>
		  <Title>Power Analysis Attacks - Revealing the Secrets of Smart Cards</Title>
		  <Publication_Year>2007</Publication_Year>
		  <URL>https://www.springer.com/gp/book/9780387308579</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1235">
		  <Author>David Oswald</Author>
		  <Author>Bastian Richter</Author>
		  <Author>Christof Paar</Author>
		  <Title>Side-Channel Attacks on the Yubikey 2 One-Time Password Generator</Title>
		  <Publication_Year>2013</Publication_Year>
		  <Publication_Month>--06</Publication_Month>
		  <Publication_Day>---14</Publication_Day>
		  <URL>https://www.emsec.ruhr-uni-bochum.de/media/crypto/veroeffentlichungen/2014/02/04/paper_yubikey_sca.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1236">
		  <Author>NIST</Author>
		  <Title>CAVP Testing: Individual Component Testing</Title>
		  <URL>https://csrc.nist.gov/projects/cryptographic-algorithm-validation-program/component-testing</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1237">
		  <Author>CERT Coordination Center</Author>
		  <Title>Intel BIOS locking mechanism contains race condition that enables write protection bypass</Title>
		  <Publication_Year>2015</Publication_Year>
		  <Publication_Month>--01</Publication_Month>
		  <Publication_Day>---05</Publication_Day>
		  <URL>https://www.kb.cert.org/vuls/id/766164/</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1239">
		  <Author>François-Xavier Standaert</Author>
		  <Title>How (not) to Use Welch's T-test in Side-Channel Security Evaluations</Title>
		  <Publication_Year>2017</Publication_Year>
		  <Publication_Month>--02</Publication_Month>
		  <Publication_Day>---15</Publication_Day>
		  <Publisher>IACR Cryptology ePrint Archive</Publisher>
		  <URL>https://eprint.iacr.org/2017/138.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1240">
		  <Author>Carolyn Whitnall</Author>
		  <Author>Elisabeth Oswald</Author>
		  <Title>A Critical Analysis of ISO 17825 ('Testing methods for the mitigation of non-invasive attack classes against cryptographic modules')</Title>
		  <Publication_Year>2019</Publication_Year>
		  <Publication_Month>--09</Publication_Month>
		  <Publication_Day>---10</Publication_Day>
		  <Publisher>IACR Cryptology ePrint Archive</Publisher>
		  <URL>https://eprint.iacr.org/2019/1013.pdf</URL>
		</External_Reference>
      <External_Reference Reference_ID="REF-1241">
		  <Author>Wikipedia</Author>
		  <Title>Network on a chip</Title>
		  <URL>https://en.wikipedia.org/wiki/Network_on_a_chip</URL>
		  <URL_Date>2021-10-24</URL_Date>
		</External_Reference>
      <External_Reference Reference_ID="REF-1242">
		  <Author>Subodha Charles</Author>
		  <Author>Prabhat Mishra</Author>
		  <Title>A Survey of Network-on-Chip Security Attacks and Countermeasures</Title>
		  <Publication>ACM Computing Surveys</Publication>
		  <Publication_Year>2021</Publication_Year>
		  <Publication_Month>--05</Publication_Month>
		  <URL>https://dl.acm.org/doi/fullHtml/10.1145/3450964</URL>
		  <URL_Date>2021-10-24</URL_Date>
		</External_Reference>
   </External_References>
</Weakness_Catalog>